{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root paths\n",
    "data_dir = '/jukebox/ntb/projects/sketchloop02/data'\n",
    "SAVE_PATH = '/jukebox/ntb/projects/sketchloop02/data/searchlight_output/'\n",
    "\n",
    "# global params\n",
    "sl_rad = 5\n",
    "iv = 'time_point'\n",
    "normalize_on = True\n",
    "logged = True\n",
    "\n",
    "# affine to save each image with\n",
    "affine = np.array([[-1.996683955192566, -0.026332620531320572, -0.11206881701946259, 91.78023529052734],\n",
    "                   [-0.026291240006685257, 1.9998265504837036, -0.0014756681630387902, -125.46440124511719],\n",
    "                   [-0.11207851767539978, 7.630718279472148e-09, 1.9968571662902832, -120.91204833984375],\n",
    "                   [0.0, 0.0, 0.0, 1.0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper functions\n",
    "rewritten to help optimize searchlight runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_recog_data(subject):\n",
    "    features = np.load('/jukebox/ntb/projects/sketchloop02/data/feature_matrices_and_metadata/' +\n",
    "                       subject + '_12_featurematrix.npy')\n",
    "    return features\n",
    "\n",
    "def load_recog_metadata(subject):\n",
    "    metadata = pd.read_csv(\n",
    "        '/jukebox/ntb/projects/sketchloop02/data/feature_matrices_and_metadata/metadata_' +\n",
    "        subject + '_V1_12.csv')\n",
    "    return metadata\n",
    "\n",
    "def load_draw_metadata(subject):\n",
    "    metadata = pd.read_csv(\n",
    "        '/jukebox/ntb/projects/sketchloop02/data/feature_matrices_and_metadata/metadata_' +\n",
    "        subject + '_drawing.csv')\n",
    "    return metadata\n",
    "\n",
    "def load_draw_data(subject):\n",
    "    features = np.load('/jukebox/ntb/projects/sketchloop02/data/feature_matrices_and_metadata/' +\n",
    "                       subject + '_featurematrix.npy')\n",
    "    return features\n",
    "\n",
    "def makemask(coordinates):\n",
    "    dims = np.shape(coordinates)\n",
    "    mask = np.ma.make_mask_none((88, 128, 128))\n",
    "    for x, y, z in itertools.product(range(dims[0]), range(dims[1]), range(dims[2])):\n",
    "        a, b, c = coordinates[x, y, z]\n",
    "        mask[a, b, c] = True\n",
    "    return mask\n",
    "\n",
    "def maskfeatures(mask, features):\n",
    "    x = [0] * features.shape[0]\n",
    "    for i, n in enumerate(f[mask] for f in features):\n",
    "        x[i] = n\n",
    "    x = np.array(x)\n",
    "    return x\n",
    "    return np.array([f[mask] for f in features])\n",
    "\n",
    "# z-score normalization to de-mean & standardize variances within-voxel\n",
    "def normalize(X):\n",
    "    X = X - X.mean(0)\n",
    "    X = X / np.maximum(X.std(0), 1e-5)\n",
    "    return X\n",
    "\n",
    "def nan_if(arr, value):\n",
    "    return np.where(arr == value, np.nan, arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis / Data Collection\n",
    "How searchlight works with brainiak:\n",
    "\n",
    "1. Initiate a searchlight object, articulating certain parameters (e.g., searchlight shape, radius, max edge length, in voxels, of the 3D block(?)).\n",
    "2. Distribute data to be searched to the searchlight object, sorting between MPI ranks (idk what MPI ranks are tbh).\n",
    "3. Broadcast data, i.e., define other variables to be available for each execution of the searchlight function.\n",
    "4. Run the searchlight, this time articulating as a parameter the function to be applied at each searchlight location.\n",
    "\n",
    "We want to perform searchlight again, but this time the objective is to perform a version of helpers.make_drawing_predictions on each searchlight mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_drawing_predictions(subject_data):\n",
    "    # format the train/test split\n",
    "    t1, t2 = trained_objs\n",
    "    subject_data = subject_data.transpose((3, 0, 1, 2))\n",
    "    X_train = subject_data[920:,:].reshape((160, -1))\n",
    "    X_test = subject_data[:920,:].reshape((920, -1))\n",
    "    y_train = RM.label.values\n",
    "    y_test = DM.label.values\n",
    "    \n",
    "    # normalize if we want\n",
    "    if normalize_on:\n",
    "        X_train = normalize(X_train)\n",
    "        X_test = normalize(X_test)\n",
    "\n",
    "    # single train/test split\n",
    "    clf = linear_model.LogisticRegression(penalty='l2',C=1).fit(X_train, y_train)\n",
    "    \n",
    "    ## add prediction probabilities to metadata matrix\n",
    "    ## must sort so that trained are first, and control is last\n",
    "    ## also save out new columns in the same order\n",
    "    cats = list(clf.classes_)\n",
    "    _ordering = np.argsort(np.hstack((trained_objs,control_objs))) ## e.g., [chair table bench bed] ==> [3 2 0 1]\n",
    "    ordering = np.argsort(_ordering) ## get indices that sort from alphabetical to (trained_objs, control_objs)\n",
    "    probs = (np.log(clf.predict_proba(X_test)) if logged else clf.predict_proba(X_test))\n",
    "    \n",
    "    out = probs[:,ordering]\n",
    "    DM['t1_prob'] = out[:,0]\n",
    "    DM['t2_prob'] = out[:,1]\n",
    "    DM['c1_prob'] = out[:,2]\n",
    "    DM['c2_prob'] = out[:,3]\n",
    "    DM['bed_prob'] = probs[:,0]\n",
    "    DM['bench_prob'] = probs[:,1]\n",
    "    DM['chair_prob'] = probs[:,2]\n",
    "    DM['table_prob'] = probs[:,3]\n",
    "    \n",
    "    target = np.vstack((DM[DM.label==t1].groupby(iv)['t1_prob'].mean().values,\n",
    "                       DM[DM.label==t2].groupby(iv)['t2_prob'].mean().values)).mean(0)\n",
    "    foil = np.vstack((DM[DM.label==t1].groupby(iv)['t2_prob'].mean().values,\n",
    "                       DM[DM.label==t2].groupby(iv)['t1_prob'].mean().values)).mean(0)\n",
    "    \n",
    "    return np.mean(target-foil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that sets up and organizes searchlight over a set of subjects\n",
    "def searchlight_over_each(subjects):\n",
    "    \n",
    "    for s in subjects:\n",
    "        sub = s\n",
    "        \n",
    "        # set up an relevant objects for searchlight\n",
    "        result = np.zeros(((88, 128, 128)))\n",
    "        \n",
    "        # arrange data to be distributed to searchlight\n",
    "        ### load subject data in\n",
    "        RM, DM = load_recog_metadata(s),  load_draw_metadata(s)\n",
    "        CF = np.concatenate((load_draw_data(s), load_recog_data(s).transpose((1, 0, 2, 3))), axis=0).transpose((1, 2, 3, 0))\n",
    "        \n",
    "        ### identify control objects;\n",
    "        ### we wil train one classifier with\n",
    "        trained_objs = np.unique(DM.label.values)\n",
    "        control_objs = [i for i in ['bed','bench','chair','table'] if i not in trained_objs]\n",
    "        \n",
    "        # distribute and broadcast needed data to searchlight\n",
    "        counter = 0\n",
    "        for x, y, z in tqdm(itertools.product(range(88), range(128), range(128))):\n",
    "            if y == 0:\n",
    "                counter += 1\n",
    "                nib.save(nib.Nifti1Image(result.astype(np.float32), affine), SAVE_PATH + s + 'clf_searchlight.nii.gz')\n",
    "            result[x, y, z] = make_drawing_predictions(CF[x-sl_rad if x-sl_rad > 0 else 0:x+sl_rad if x+sl_rad < 88 else 88,\n",
    "                                                          y-sl_rad if y-sl_rad > 0 else 0:y+sl_rad if y+sl_rad < 128 else 128,\n",
    "                                                          z-sl_rad if z-sl_rad > 0 else 0:z+sl_rad if z+sl_rad < 128 else 128,\n",
    "                                                          :])\n",
    "        \n",
    "        # store output for this subject\n",
    "        nib.save(nib.Nifti1Image(result.astype(np.float32), affine),\n",
    "                 SAVE_PATH + s + 'clf_searchlight.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "438115it [19:16:37,  1.63it/s]"
     ]
    }
   ],
   "source": [
    "# run searchlight over all subjects and print time to compute results\n",
    "searchlight_over_each(sub_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
