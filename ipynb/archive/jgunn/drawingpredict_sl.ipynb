{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "from sklearn import linear_model\n",
    "from brainiak.searchlight.searchlight import Searchlight\n",
    "from brainiak.searchlight.searchlight import Cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root paths\n",
    "data_dir = '/jukebox/ntb/projects/sketchloop02/data'\n",
    "SAVE_PATH = '/jukebox/ntb/projects/sketchloop02/data/searchlight_output/'\n",
    "\n",
    "# global params\n",
    "sl_rad = 3\n",
    "iv = 'time_point'\n",
    "normalize_on = True\n",
    "logged = True\n",
    "\n",
    "# affine to save each image with\n",
    "affine = np.array([[-1.996683955192566, -0.026332620531320572, -0.11206881701946259, 91.78023529052734],\n",
    "                   [-0.026291240006685257, 1.9998265504837036, -0.0014756681630387902, -125.46440124511719],\n",
    "                   [-0.11207851767539978, 7.630718279472148e-09, 1.9968571662902832, -120.91204833984375],\n",
    "                   [0.0, 0.0, 0.0, 1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_list = ['0110171', '0110172', '0111171', '0112171', '0112172', '0112173',\n",
    "       '0113171', '0115174', '0117171', '0118171', '0118172', '0119171',\n",
    "       '0119172', '0119173', '0119174', '0120171', '0120172', '0120173',\n",
    "       '0123171', '0123173', '0124171', '0125171', '0125172', '1121161',\n",
    "       '1130161', '1202161', '1203161', '1206161', '1206162', '1206163',\n",
    "       '1207162']\n",
    "\n",
    "iv = 'time_point'\n",
    "normalize_on = True\n",
    "logged = True\n",
    "data_dir = '/jukebox/ntb/projects/sketchloop02/data'\n",
    "SAVE_PATH = '/jukebox/ntb/projects/sketchloop02/data/searchlight_output/'\n",
    "RM, RF, DM, DF, trained_objs, control_objs, sub = None, None, None, None, None, None, None\n",
    "\n",
    "affine = np.array([[-1.996683955192566, -0.026332620531320572, -0.11206881701946259, 91.78023529052734],\n",
    "[-0.026291240006685257, 1.9998265504837036, -0.0014756681630387902, -125.46440124511719],\n",
    "[-0.11207851767539978, 7.630718279472148e-09, 1.9968571662902832, -120.91204833984375],\n",
    "[0.0, 0.0, 0.0, 1.0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper functions\n",
    "rewritten to help optimize searchlight runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_recog_data(subject):\n",
    "    features = np.load('/jukebox/ntb/projects/sketchloop02/data/feature_matrices_and_metadata/' +\n",
    "                       subject + '_12_featurematrix.npy')\n",
    "    return features\n",
    "\n",
    "def load_recog_metadata(subject):\n",
    "    metadata = pd.read_csv(\n",
    "        '/jukebox/ntb/projects/sketchloop02/data/feature_matrices_and_metadata/metadata_' +\n",
    "        subject + '_V1_12.csv')\n",
    "    return metadata\n",
    "\n",
    "def load_draw_metadata(subject):\n",
    "    metadata = pd.read_csv(\n",
    "        '/jukebox/ntb/projects/sketchloop02/data/feature_matrices_and_metadata/metadata_' +\n",
    "        subject + '_drawing.csv')\n",
    "    return metadata\n",
    "\n",
    "def load_draw_data(subject):\n",
    "    features = np.load('/jukebox/ntb/projects/sketchloop02/data/feature_matrices_and_metadata/{}_featurematrix.npy'.format(subject))\n",
    "    return features\n",
    "\n",
    "def load_classifier_features(subject):\n",
    "    features = np.load('/jukebox/ntb/projects/sketchloop02/data/feature_matrices_and_metadata/CF_{}.npy'.format(subject),\n",
    "                      mmap_mode='r')\n",
    "    return features\n",
    "\n",
    "def makemask(coordinates):\n",
    "    dims = np.shape(coordinates)\n",
    "    mask = np.ma.make_mask_none((88, 128, 128))\n",
    "    for x, y, z in itertools.product(range(dims[0]), range(dims[1]), range(dims[2])):\n",
    "        a, b, c = coordinates[x, y, z]\n",
    "        mask[a, b, c] = True\n",
    "    return mask\n",
    "\n",
    "def maskfeatures(mask, features):\n",
    "    x = [0] * features.shape[0]\n",
    "    for i, n in enumerate(f[mask] for f in features):\n",
    "        x[i] = n\n",
    "    x = np.array(x)\n",
    "    return x\n",
    "    return np.array([f[mask] for f in features])\n",
    "\n",
    "# z-score normalization to de-mean & standardize variances within-voxel\n",
    "def normalize(X):\n",
    "    X = X - X.mean(0)\n",
    "    X = X / np.maximum(X.std(0), 1e-5)\n",
    "    return X\n",
    "\n",
    "def nan_if(arr, value):\n",
    "    return np.where(arr == value, np.nan, arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis / Data Collection\n",
    "How searchlight works with brainiak:\n",
    "\n",
    "1. Initiate a searchlight object, articulating certain parameters (e.g., searchlight shape, radius, max edge length, in voxels, of the 3D block(?)).\n",
    "2. Distribute data to be searched to the searchlight object, sorting between MPI ranks (idk what MPI ranks are tbh).\n",
    "3. Broadcast data, i.e., define other variables to be available for each execution of the searchlight function.\n",
    "4. Run the searchlight, this time articulating as a parameter the function to be applied at each searchlight location.\n",
    "\n",
    "We want to perform searchlight again, but this time the objective is to perform a version of helpers.make_drawing_predictions on each searchlight mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_drawing_predictions(subject_data):\n",
    "    # format the train/test split\n",
    "    t1, t2 = trained_objs\n",
    "    subject_data = subject_data.transpose((3, 0, 1, 2))\n",
    "    X_train = subject_data[920:,:].reshape((160, -1))\n",
    "    X_test = subject_data[:920,:].reshape((920, -1))\n",
    "    y_train = RM.label.values\n",
    "    y_test = DM.label.values\n",
    "    \n",
    "    # normalize if we want\n",
    "    if normalize_on:\n",
    "        X_train = normalize(X_train)\n",
    "        X_test = normalize(X_test)\n",
    "\n",
    "    # single train/test split\n",
    "    clf = linear_model.LogisticRegression(penalty='l2',C=1).fit(X_train, y_train)\n",
    "    \n",
    "    ## add prediction probabilities to metadata matrix\n",
    "    ## must sort so that trained are first, and control is last\n",
    "    ## also save out new columns in the same order\n",
    "    cats = list(clf.classes_)\n",
    "    _ordering = np.argsort(np.hstack((trained_objs,control_objs))) ## e.g., [chair table bench bed] ==> [3 2 0 1]\n",
    "    ordering = np.argsort(_ordering) ## get indices that sort from alphabetical to (trained_objs, control_objs)\n",
    "    probs = (np.log(clf.predict_proba(X_test)) if logged else clf.predict_proba(X_test))\n",
    "    \n",
    "    out = probs[:,ordering]\n",
    "    DM['t1_prob'] = out[:,0]\n",
    "    DM['t2_prob'] = out[:,1]\n",
    "    DM['c1_prob'] = out[:,2]\n",
    "    DM['c2_prob'] = out[:,3]\n",
    "    RM['t1_max'] = pd.Series(np.logical_and(np.logical_and(out[:,0] > out[:,1], out[:,0] > out[:,2]), out[:,0] > out[:,3]))\n",
    "    RM['t2_max'] = pd.Series(np.logical_and(np.logical_and(out[:,1] > out[:,0], out[:,1] > out[:,2]), out[:,1] > out[:,3]))\n",
    "    \n",
    "    # return proportion of times target > others\n",
    "    if RM[RM.label==t2].shape[0] + RM[RM.label==t1].shape[0]:\n",
    "        return (RM[(RM.label==t2) & (RM['t2_max'])].shape[0] + RM[(RM.label==t1) & (RM['t1_max'])].shape[0])/(\n",
    "            RM[RM.label==t2].shape[0] + RM[RM.label==t1].shape[0])\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_classifier_features():\n",
    "    for s in list(reversed(sub_list))[5:]:\n",
    "        print(s)\n",
    "        sub = s\n",
    "\n",
    "        # set up an relevant objects for searchlight\n",
    "        result = np.zeros(((88, 128, 128)))\n",
    "\n",
    "        # arrange data to be distributed to searchlight\n",
    "        ### load subject data in\n",
    "        CF = np.concatenate((load_draw_data(s), load_recog_data(s).transpose((1, 0, 2, 3))), axis=0).transpose((1, 2, 3, 0))\n",
    "        np.save('/jukebox/ntb/projects/sketchloop02/data/feature_matrices_and_metadata/CF_' +\n",
    "        sub, CF)\n",
    "\n",
    "#generate_classifier_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that sets up and organizes searchlight over a set of subjects\n",
    "for s in sub_list:\n",
    "    sub = s\n",
    "\n",
    "    # set up an relevant objects for searchlight\n",
    "    result = np.zeros(((88, 128, 128)))\n",
    "\n",
    "    # arrange data to be distributed to searchlight\n",
    "    ### load subject data in\n",
    "    RM, DM = load_recog_metadata(s),  load_draw_metadata(s)\n",
    "    CF = load_classifier_features(s)\n",
    "\n",
    "    ### identify control objects;\n",
    "    ### we wil train one classifier with\n",
    "    trained_objs = np.unique(DM.label.values)\n",
    "    control_objs = [i for i in ['bed','bench','chair','table'] if i not in trained_objs]\n",
    "\n",
    "    # distribute and broadcast needed data to searchlight\n",
    "    counter = 0\n",
    "    for x, y, z in tqdm(itertools.product(range(88), range(128), range(128))):\n",
    "        if y == 0 and z == 0:\n",
    "            print(counter)\n",
    "            counter += 1\n",
    "            nib.save(nib.Nifti1Image(result.astype(np.float32), affine), SAVE_PATH + s + 'acc_searchlight.nii.gz')\n",
    "        result[x, y, z] = make_drawing_predictions(CF[x-sl_rad if x-sl_rad > 0 else 0:x+sl_rad if x+sl_rad < 88 else 88,\n",
    "                                                      y-sl_rad if y-sl_rad > 0 else 0:y+sl_rad if y+sl_rad < 128 else 128,\n",
    "                                                      z-sl_rad if z-sl_rad > 0 else 0:z+sl_rad if z+sl_rad < 128 else 128,\n",
    "                                                      :])\n",
    "\n",
    "    # store output for this subject\n",
    "    nib.save(nib.Nifti1Image(result.astype(np.float32), affine),\n",
    "             SAVE_PATH + s + 'acc_searchlight.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
