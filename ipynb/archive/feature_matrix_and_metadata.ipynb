{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loosely to Very Relevant Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# packages i might use\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from nilearn import image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from scipy import stats\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0110171_neurosketch', '0110172_neurosketch', '0111171_neurosketch', '0112171_neurosketch', '0112172_neurosketch', '0112173_neurosketch', '0113171_neurosketch', '0115172_neurosketch', '0115174_neurosketch', '0117171_neurosketch', '0118171_neurosketch', '0118172_neurosketch', '0119171_neurosketch', '0119172_neurosketch', '0119173_neurosketch', '0119174_neurosketch', '0120171_neurosketch', '0120172_neurosketch', '0120173_neurosketch', '0123171_neurosketch', '0123173_neurosketch', '0124171_neurosketch', '0125171_neurosketch', '0125172_neurosketch', '1121161_neurosketch', '1130161_neurosketch', '1202161_neurosketch', '1203161_neurosketch', '1206161_neurosketch', '1206162_neurosketch', '1206163_neurosketch', '1207162_neurosketch']\n",
      "32 subjects\n"
     ]
    }
   ],
   "source": [
    "## get list of subject directories\n",
    "proj_dir = '/home/jefan/sketchloop02/'\n",
    "contents_dir = os.listdir(proj_dir)\n",
    "\n",
    "sub_dirs = []\n",
    "for i in contents_dir:\n",
    "    try:\n",
    "        if i.split('_')[1]=='neurosketch':\n",
    "            sub_dirs.append(i)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "sub_dirs = sorted(sub_dirs)\n",
    "\n",
    "# issue with 1207161\n",
    "sub_dirs = [s for s in sub_dirs if s != '1207161_neurosketch']\n",
    "\n",
    "# issue with 1201161\n",
    "sub_dirs = [s for s in sub_dirs if s != '1201161_neurosketch']\n",
    "\n",
    "print(sub_dirs)\n",
    "print(str(len(sub_dirs)) + ' subjects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# analysis helper functions i might use\n",
    "def get_mask_array(mask_path):\n",
    "    # loads mask applied to nifty (.nii.gz) file\n",
    "    # mask selects voxels to be included/discarded\n",
    "    mask_img = image.load_img(mask_path)\n",
    "    mask_data = mask_img.get_data()\n",
    "    num_brain_voxels = sum(sum(sum(mask_data==1)))\n",
    "    return mask_data, num_brain_voxels\n",
    "\n",
    "def load_roi_mask_combined(subj,run_num,roi):\n",
    "    if run_num in [1,2]:\n",
    "        phase_num = '12' \n",
    "    elif run_num in [3,4]:\n",
    "        phase_num = '34'\n",
    "    elif run_num in [5,6]:\n",
    "        phase_num = '56'\n",
    "    mask_path = proj_dir + '/' + subj +'/analysis/firstlevel/rois/' + roi + '_func_combined_' + phase_num + '_binarized.nii.gz'        \n",
    "    mask_data, nv = get_mask_array(mask_path)\n",
    "    return mask_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Feature Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want 160 x num_voxels feature array saved as .npy for each subject, focused on occitemp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "occitemp\n",
      "0110171_neurosketch\n",
      "0110172_neurosketch\n",
      "0111171_neurosketch\n",
      "0112171_neurosketch\n",
      "0112172_neurosketch\n",
      "0112173_neurosketch\n",
      "0113171_neurosketch\n",
      "0115172_neurosketch\n",
      "0115174_neurosketch\n",
      "0117171_neurosketch\n",
      "0118171_neurosketch\n",
      "0118172_neurosketch\n",
      "0119171_neurosketch\n",
      "0119172_neurosketch\n",
      "0119173_neurosketch\n",
      "0119174_neurosketch\n",
      "0120171_neurosketch\n",
      "0120172_neurosketch\n",
      "0120173_neurosketch\n",
      "0123171_neurosketch\n",
      "0123173_neurosketch\n",
      "0124171_neurosketch\n",
      "0125171_neurosketch\n",
      "0125172_neurosketch\n",
      "1121161_neurosketch\n",
      "1130161_neurosketch\n",
      "1202161_neurosketch\n",
      "1203161_neurosketch\n",
      "1206161_neurosketch\n",
      "1206162_neurosketch\n",
      "1206163_neurosketch\n",
      "1207162_neurosketch\n"
     ]
    }
   ],
   "source": [
    "ROIs = ['occitemp']\n",
    "\n",
    "for roi in ROIs:\n",
    "    print(roi)\n",
    "    \n",
    "    for subject in sub_dirs:\n",
    "        print(subject)\n",
    "        \n",
    "        subj = [subject[:7]] * 160\n",
    "        label = []\n",
    "        run_num = [1]*80 + [2]*80\n",
    "        TR_num = []\n",
    "        features = []\n",
    "        \n",
    "        roi_mask = load_roi_mask_combined(subject, 1, roi)\n",
    "        for run in [1, 2]:\n",
    "            \n",
    "            # load subject's time series for this run\n",
    "            timeseries = image.load_img(proj_dir + subject + '/analysis/firstlevel/preproc_recognition_run_' +\n",
    "                                                 str(run) + '.feat/filtered_func_data.nii.gz')\n",
    "            timeseries = timeseries.get_data().transpose((3, 0, 1, 2))\n",
    "            \n",
    "            # use information in regressor/run_x folder to make hasImage vector\n",
    "            # associated TR is just the hasImage index, converted to a float if needed\n",
    "            hasImage = [0]*240\n",
    "            for cope in ['bed', 'bench', 'chair', 'table']:\n",
    "                with open('/home/jgunn/neurosketch/timepoints/' + subject[:7] + '_' + str(run) + '_' + cope + '.txt') as f:\n",
    "                    times = [line.split(' ')[0] for line in f.read().split('\\n')[:-1]]\n",
    "                    for t in times:\n",
    "                        tr = float(t)/1.5\n",
    "                        if cope == 'bed':\n",
    "                            hasImage[int(tr)] = 1\n",
    "                        elif cope == 'bench':\n",
    "                            hasImage[int(tr)] = 2\n",
    "                        elif cope == 'chair':\n",
    "                            hasImage[int(tr)] = 3\n",
    "                        elif cope == 'table':\n",
    "                            hasImage[int(tr)] = 4\n",
    "            \n",
    "            # wherever hasImage, we want the features\n",
    "            for i, has in enumerate(hasImage): # 80 times\n",
    "                if has != 0:\n",
    "                    features.append(timeseries[i+3][roi_mask==1])\n",
    "                    \n",
    "            # gotta track label and TR_num\n",
    "            for index, value in enumerate(hasImage):\n",
    "                if value != 0:\n",
    "                    TR_num.append(float(index))\n",
    "                    if value == 1:\n",
    "                        label.append('bed')\n",
    "                    elif value == 2:\n",
    "                        label.append('bench')\n",
    "                    elif value == 3:\n",
    "                        label.append('chair')\n",
    "                    elif value == 4:\n",
    "                        label.append('table')\n",
    "        \n",
    "        features = np.stack(features,axis=1)\n",
    "        np.save(file='/home/jgunn/neurosketch/matrices/' + subject[:7] + '_featurematrix.npy', arr=features)\n",
    "        \n",
    "        x = pd.DataFrame([subj, label, run_num, TR_num]) # where each of those variables are lists of the same length\n",
    "        x = x.transpose()\n",
    "        x.columns = ['subj','label','run_num', 'TR_num']\n",
    "        x.to_csv('/home/jgunn/neurosketch/matrices/metadata_{}.csv'.format(subject[:7])) # in a notebook, you can look at x by evaluating it by itself in its own cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train on run 1, test on run 2 using SVM or 4-way softmax (logistic regression classifier)\n",
    "# how to define training set?\n",
    "# get the 80 cope maps for run 1 per subject\n",
    "# i'll do it for the whole brain and then with ROI masks applied, compare results\n",
    "\n",
    "# this time, we only pick one instead of (presumably at +3, maybe +2) \n",
    "ROIs = ['V1','fusiform','IT','LOC', 'occitemp']\n",
    "roiscores = []\n",
    "\n",
    "for roi in ROIs:\n",
    "    print(roi)\n",
    "    actual = []\n",
    "    predicted = []\n",
    "    for subject in sub_dirs:\n",
    "        print(subject)\n",
    "        trainingX = []\n",
    "        trainingY = []\n",
    "        testX = []\n",
    "        testY = []\n",
    "        roi_mask = load_roi_mask_combined(subject, 1, roi)\n",
    "        for run in [1, 2]:\n",
    "\n",
    "            # load subject's time series for this run\n",
    "            timeseries = image.load_img(proj_dir + subject + '/analysis/firstlevel/preproc_recognition_run_' +\n",
    "                                                 str(run) + '.feat/filtered_func_data.nii.gz')\n",
    "            timeseries = timeseries.get_data().transpose((3, 0, 1, 2))\n",
    "            #timeseries = stats.zscore(timeseries, axis=0)\n",
    "            #timeseries[np.isnan(timeseries)] = 0\n",
    "            \n",
    "            # use information in regressor/run_x folder to make hasImage vector\n",
    "            hasImage = [0]*240\n",
    "            for cope in ['bed', 'bench', 'chair', 'table']:\n",
    "                with open('/home/jgunn/neurosketch/timepoints/' + subject[:7] + '_' + str(run) + '_' + cope + '.txt') as f:\n",
    "                    times = [line.split(' ')[0] for line in f.read().split('\\n')[:-1]]\n",
    "                    for t in times:\n",
    "                        tr = float(t)/1.5\n",
    "                        if cope == 'bed':\n",
    "                            hasImage[int(tr)] = 1\n",
    "                        elif cope == 'bench':\n",
    "                            hasImage[int(tr)] = 2\n",
    "                        elif cope == 'chair':\n",
    "                            hasImage[int(tr)] = 3\n",
    "                        elif cope == 'table':\n",
    "                            hasImage[int(tr)] = 4\n",
    "\n",
    "            # wherever hasImage, get associated volume and flatten it for training\n",
    "            for i, has in enumerate(hasImage): # 80 times\n",
    "                if has > 0:\n",
    "                    if run == 1:\n",
    "                        trainingX.append(timeseries[i+3][roi_mask==1])\n",
    "                        trainingY.append(has-1)\n",
    "                    else:\n",
    "                        testX.append(timeseries[i+3][roi_mask==1])\n",
    "                        testY.append(has-1)\n",
    "\n",
    "        lin_clf = LogisticRegression()\n",
    "        lin_clf.fit(trainingX, trainingY)\n",
    "        predicted = predicted + lin_clf.predict(testX).tolist()\n",
    "        actual = actual + testY\n",
    "        #scores = scores + [np.mean(cross_val_score(lin_clf, trainingX, trainingY).tolist())]\n",
    "    roiscores.append(np.mean(np.equal(actual, predicted)))\n",
    "    \n",
    "roiscores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
