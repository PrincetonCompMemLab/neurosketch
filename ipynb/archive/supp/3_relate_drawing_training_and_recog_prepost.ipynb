{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn import linear_model, datasets, neighbors\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import svm\n",
    "\n",
    "%matplotlib inline\n",
    "from scipy.misc import imread, imresize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "colors = sns.color_palette(\"cubehelix\", 5)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm, linregress\n",
    "import sklearn\n",
    "# from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define project paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## relative root paths\n",
    "curr_dir = os.getcwd()\n",
    "proj_dir = os.path.abspath(os.path.join(curr_dir,'..','..')) ## use relative paths\n",
    "data_dir = os.path.abspath(os.path.join(curr_dir,'..','..','data')) ## use relative paths 'D:\\\\data'\n",
    "results_dir = os.path.join(proj_dir, 'csv')\n",
    "nb_name = '3_relate_drawing_training_and_recog_prepost'\n",
    "\n",
    "## add helpers to python path\n",
    "import sys\n",
    "if os.path.join(proj_dir, 'python') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir, 'python'))\n",
    "\n",
    "## module definitions\n",
    "import utils \n",
    "reload(utils)\n",
    "utils.data_dir = data_dir\n",
    "utils.path_to_recog = os.path.join(data_dir, 'features/recog')\n",
    "utils.path_to_draw = os.path.join(data_dir, 'features/drawing')\n",
    "utils.roi_list_draw = np.array(['V1Draw', 'V2Draw', 'LOCDraw', 'InsulaDraw', 'postCentralDraw',\n",
    "                            'preCentralDraw', 'ParietalDraw', 'FrontalDraw', 'smgDraw'])\n",
    "utils.roi_list_recog = np.array(['V1', 'V2', 'LOC', 'fusiform','parahippo','IT','ento','PRC','hipp'])\n",
    "roi_list = ['V1', 'V2', 'LOC', 'IT', 'fusiform', 'parahippo', 'PRC', 'ento', 'hipp']\n",
    "roi_list_formatted = ['V1', 'V2', 'LOC', 'FUS', 'PHC', 'IT', 'ENT', 'PRC', 'HC']\n",
    "roi_formatter = dict(zip(roi_list,roi_list_formatted))\n",
    "roi_list_recog = utils.roi_list_recog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### relate individual differences in overall target selectivity (log odds of target vs. foil) to prepost differentiation\n",
    "\n",
    "This plots the raw correlations between classifer evidence for target - foil, and prepost differentiation between trained objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = '4way'\n",
    "target_selection = pd.read_csv(os.path.join(proj_dir,'csv/object_classifier_logodds_production.csv'))\n",
    "target_selection['roi_formatted'] = target_selection['roi'].apply(lambda x: roi_formatter[x])\n",
    "target_selection = target_selection.drop('roi',axis=1)\n",
    "target_selection = target_selection.rename(columns={'roi_formatted':'roi'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load in version of prepost that has probs \n",
    "_prepost = pd.read_csv(os.path.join(results_dir,'object_classifier_prepost_rawprobs.csv'))\n",
    "## define new dataframe which just has the goods\n",
    "_prepost = postprocess_prepost_rawprobs(_prepost)\n",
    "prepost = _prepost[['roi_formatted_pre','subj_pre','target_rawprob_postpre','target_logodds_postpre','target_logodds_postpre']]\n",
    "prepost.columns = ['roi','sub','logodds','rawdiff','targetpostpre']  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## join the prepost recognition and production phase dataframes\n",
    "prepost = prepost.sort_values(['roi','sub'])\n",
    "target_selection = target_selection.sort_values(['roi','sub']).reset_index(drop=True)\n",
    "joined = target_selection.join(prepost,rsuffix='_recog',lsuffix='_draw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "colors = sns.color_palette('deep',5)\n",
    "g = sns.FacetGrid(joined, \n",
    "                  col='roi_recog',\n",
    "                  col_order=roi_list_formatted,\n",
    "                  aspect=1,\n",
    "                  height=5,\n",
    "                  col_wrap=3)\n",
    "g.map(sns.regplot,'target-foil','logodds',fit_reg=False,color=(colors[0]))\n",
    "\n",
    "axes = g.axes.flatten()\n",
    "for ind,ax in enumerate(axes):\n",
    "    ax.set_title(roi_list_formatted[ind])\n",
    "    ax.set_xlabel('production')\n",
    "    ax.set_ylabel('recognition')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "print 'Strength of correlation between target selection during production and change in target selection from pre-post'\n",
    "print '============================'\n",
    "for name,group in joined.groupby('roi_recog'):\n",
    "    print '{} |  r = {}'.format(name, utils.get_corr(group['target-foil'],group['logodds']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plots correlations across phase and roi.\n",
    "\n",
    "For example, does foil inhibition in one roi predict differentiation in another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do you want to (roughly) exclude non significant correlations in plot?\n",
    "exclude_ns = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats.pearsonr(draws[0],recogs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altogether = np.vstack((draws,recogs))\n",
    "corrs = np.corrcoef(altogether)\n",
    "derp = (corrs > -0.36) & (corrs < 0.36)\n",
    "corrs2 = np.copy(corrs)\n",
    "if exclude_ns:\n",
    "    np.place(corrs2, derp, np.nan)\n",
    "    fig, ax = plt.subplots(figsize=(15,15))\n",
    "im = ax.matshow(corrs2)\n",
    "ax.set_xticks(np.arange(len(roi_labels)))\n",
    "ax.set_xticklabels(roi_labels, fontsize=8)\n",
    "ax.set_yticks(np.arange(len(roi_labels)))\n",
    "ax.set_yticklabels(roi_labels, fontsize=8)\n",
    "ax.set_ylabel('pre-post differentiation                        target selection')\n",
    "ax.set_xlabel('target selection                        pre-post differentiation')\n",
    "ax.xaxis.set_label_position('top')\n",
    "ax.xaxis.tick_top()\n",
    "plt.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some observations:\n",
    "* ROIs where we see positive relationship are: *V1*, *V2*. That is, individuals with GREATER target selectivity during drawing in these regions also show GREATER prepost differentiation.\n",
    "* ROIs where we see negative relationship are: *fusiform*, *mOFC* (maybe PRC?) That is, individuals with LESS target selectivity during drawing in these regions also show GREATER prepost differentiation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When does the relationship between target selectivity and differentiation emerge in these ROIs?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial parameters\n",
    "version = '4way'\n",
    "logged = True\n",
    "tag = 'logged' if logged else 'raw'\n",
    "ALLDM = pd.read_csv(os.path.join(results_dir,'logistic_timeseries_drawing_neural_{}_{}.csv'.format(version,tag)))\n",
    "ALLDM = h.cleanup_df(ALLDM)\n",
    "\n",
    "roi_list = roi_list_recog\n",
    "subs = np.unique(ALLDM.subj.values)\n",
    "ivs = ['trial_num'] # ['run_num','trial_num','time_point']\n",
    "takeDiffDifference = True ## compare trained object differentiation vs. control object differentiation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = ('logged' if logged else 'raw')\n",
    "for this_iv in ivs:\n",
    "    for k,this_roi in enumerate(roi_list):\n",
    "        # 1. Generate a subject-by-trial_num matrix where each cell is either `t`, `f`, or `t-f` from the \n",
    "        # output of `analysis_helpers.get_prob_timecourse` for the associated trial and subject (and roi) pairing. \n",
    "        scores = []\n",
    "        for si,sub in enumerate(subs):\n",
    "            print 'Analyzing | {} {} | {} {} '.format(si+1,sub,k+1,this_roi)\n",
    "            clear_output(wait=True)                        \n",
    "            inds = (ALLDM['roi']==this_roi) & (ALLDM['subj']==sub)\n",
    "            t,f,c = h.get_prob_timecourse(this_iv,ALLDM[inds],version=version)\n",
    "\n",
    "            if len(scores)==0:\n",
    "                scores = t-f\n",
    "            else:\n",
    "                scores = np.vstack((scores,t-f))\n",
    "\n",
    "        # 2. Generate a subject_num length vector consisting of each subject's pre-post change measure \n",
    "        # in the same order as they are in the matrix.\n",
    "        recog = (prepost[(prepost['condition']=='difference') & (prepost['roi']==roi_dict[this_roi])]['prepost_diff']).values\n",
    "\n",
    "        # 3. The vector defined by taking the `stats.pearsonr()` between each column of the subject-by-trial_num matrix\n",
    "        # and the prepost change vector is the time course we're looking to understand for this ROI.\n",
    "        if this_roi == 'Frontal':\n",
    "            ## SEE HERE: lets decide what to do with classifier output == 0 in rare cases, ignore missing? \n",
    "            ## or add 1e-6 or smallest number in dataset so we can avoid having this catch here\n",
    "            trial_corrs = [pd.DataFrame([scores[:,i], recog]).transpose().corr()[0][1] for i in range(np.shape(scores)[1])]\n",
    "        else:\n",
    "            trial_corrs = [stats.pearsonr(scores[:,i],recog)[0] for i in range(np.shape(scores)[1])]\n",
    "\n",
    "        bootstrap = [h.corrbootstrapCI(scores[:,i], recog, 1000) for i in range(np.shape(scores)[1])]\n",
    "        lower_bound, upper_bound = [b[1] for b in bootstrap], [b[2] for b in bootstrap]                 \n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8,4))\n",
    "        ax.plot(trial_corrs, 'ro', label='data')\n",
    "        plt.axhline(y=0.0,linestyle='dashed')\n",
    "        plt.ylim((-1,1))\n",
    "        plt.ylabel('Correlation (t-c / prepost)')\n",
    "        plt.xlabel(this_iv)\n",
    "        plt.title('ROI: {}'.format(this_roi))\n",
    "        plt.fill_between(np.arange(len(trial_corrs)), lower_bound, upper_bound, alpha=.2)\n",
    "\n",
    "        if not os.path.exists(os.path.join(proj_dir,'plots/{}/'.format(nb_name))):\n",
    "            os.makedirs(os.path.join(proj_dir,'plots/{}/'.format(nb_name)))\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(proj_dir,'plots/{}/trial_corrs_{}_{}_{}.pdf'.format(nb_name, this_roi, *specs)))\n",
    "        plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create summary barplot of either mean correlation across subjects, or mean slope.\n",
    "\n",
    "Choose any number of possible plots\n",
    "\n",
    "NOTE: the full set of plots for 'mean' will create 32 plots and take ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data and set some initial parameters\n",
    "\n",
    "ALLDM = pd.read_csv(os.path.join(results_dir,'logistic_timeseries_drawing_neural_{}_{}.csv'.format(version,'logged' if logged else 'raw')))\n",
    "prepost = pd.read_csv(os.path.join(str(results_dir),'neural_changes_by_surfroi_and_subject_longform.csv'))\n",
    "\n",
    "\n",
    "takeDiffDifference = True\n",
    "\n",
    "# Choose what measure to plot\n",
    "plotting = 'mean' # ['mean', 'slope']\n",
    "\n",
    "# choose which unit of time to iterate over\n",
    "ivlist = ['run_num'] # ['run_num', 'trial_num', 'time_point']\n",
    "\n",
    "# Choose whether to log or not\n",
    "loglist = [True] # [True, False]\n",
    "\n",
    "# Choose the critical measure for classifier output\n",
    "measurelist = ['t-f'] # ['t','f','t-f','txf']\n",
    "\n",
    "# ROI list\n",
    "roi_list = np.array(['V1','V2','LOC','IT','fusiform','parahippo', 'PRC', 'ento','hipp'])\n",
    "\n",
    "\n",
    "units_dict = {'run_num': 4, 'trial_num': 20, 'time_point': 23}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through the plots, based on parameters above\n",
    "for this_iv in ivlist:\n",
    "    units = units_dict[this_iv]\n",
    "    for logged in loglist:\n",
    "        for clfmeasure in measurelist:\n",
    "            print('logged: {}; clf: {}; iv: {}'.format(logged, clfmeasure, this_iv))            \n",
    "            specs = ('logged' if logged else 'raw')\n",
    "            subs = np.unique(ALLDM.subj.values)\n",
    "\n",
    "            columns = []\n",
    "            for this_roi in roi_list:\n",
    "                _scores = np.array([h.get_prob_timecourse(this_iv,ALLDM[(ALLDM['roi']==this_roi) & (ALLDM['subj']==sub)]) for sub in subs])\n",
    "                scores = [h.compute_clf_measure(_scores[i,0,:], _scores[i,1,:], clfmeasure) for i in range(_scores.shape[0])]\n",
    "                objs = [str(np.unique(ALLDM[(ALLDM['subj']==sub)].label.values)) for sub in subs]                \n",
    "                recog = (prepost[(prepost['condition']=='difference') & (prepost['roi']==roi_dict[this_roi])]['prepost_diff']).values                        \n",
    "                columns.append([{'clf':scores[i], 'diff':recog[i], 'objs':objs[i]} for i in range(len(scores))])\n",
    "            bardf = pd.DataFrame(columns).transpose()\n",
    "            bardf.columns = roi_list\n",
    "\n",
    "            if plotting == 'mean':\n",
    "\n",
    "                # derive from bardf the df we want to plot and the error bars we want\n",
    "                meandf = pd.DataFrame([h.scoreVSdiff(np.array(bardf)[:,i], roi_list[i]) for i in range(len(roi_list))]).transpose()\n",
    "                meandf.columns = roi_list\n",
    "                error = [h.custom_bootstrapCI(np.array(bardf)[:,i], h.scoreVSdiff, 1000, roi_list[i])[1:3] for i in range(len(roi_list))]\n",
    "                title = 'Subjectwise Relationship B/t Mean({}) & PrePost Diff'.format(clfmeasure)\n",
    "                ylab = 'Average Correlation'\n",
    "                outfig = 'mean_{}_{}_{}_{}.png'.format(this_iv, clfmeasure, *specs)\n",
    "\n",
    "            else:\n",
    "\n",
    "                # derive from bardf the df we want to plot and the error bars we want\n",
    "                meandf = pd.DataFrame([h.slope_scoreVSdiff(np.array(bardf)[:,i], roi_list[i], units) for i in range(len(roi_list))]).transpose()\n",
    "                meandf.columns = roi_list\n",
    "                error = [h.custom_bootstrapCI(np.array(bardf)[:,i], h.slope_scoreVSdiff, 1000, roi_list[i], units)[1:3] for i in range(len(roi_list))]\n",
    "                title = 'Slope over Timepoints of Subjectwise Relationship B/t {} & Prepost Diff'.format(clfmeasure)\n",
    "                ylab = 'Average Slope'\n",
    "                outfig = 'slope_{}_{}_{}_{}.png'.format(this_iv, clfmeasure, *specs)\n",
    "\n",
    "            fig = plt.figure(figsize=(17,6))\n",
    "            sns.barplot(data=meandf,palette='husl',ci=None)\n",
    "            plt.xlabel('ROIs')\n",
    "            plt.title(title) \n",
    "            plt.ylabel(ylab) \n",
    "            for i in range(len(roi_list)):\n",
    "                plt.vlines(i, error[i][0], error[i][1])\n",
    "            if not os.path.exists(os.path.join(proj_dir,'plots/{}/'.format(nb_name))):\n",
    "                os.makedirs(os.path.join(proj_dir,'plots/{}/'.format(nb_name)))\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(proj_dir,'plots/{}/'.format(nb_name), outfig))\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
