{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design and Goal\n",
    "There are four objects (bed, bench, chair, table). Participants viewed each object 20 times per run.\n",
    "- Runs 1 & 2 -- reserved to conduct searchlight\n",
    "- Runs 3 & 4 -- pretest phase \n",
    "- Four training runs involving practice drawing two of the trained objects. \n",
    "- Runs 5 & 6 -- posttest phase\n",
    "\n",
    "Our goal is to understand the change in the similarity between representations of trained (vs control) objects in several anatomically-defined ROIs before and after training.\n",
    "\n",
    "## Approach\n",
    "#### Unanchored Pre-Post Representational Differentiation\n",
    "Define 'representation' as cope maps generated upon fitting GLM to each object for each run. Start by building an object x voxel matrix (4xK) for each run and vertically concatenate the two runs in each phase. Using this, compute a correlation matrix. \n",
    "\n",
    "Consider M = off-diagonal 4x4 block [:4,4:8] of this matrix; ensure the rows are sorted such that the first two are the Trained, and the last two are the Control objects. Now take the the top-left 2x2 matrix within M and let's call it M-trained. The bottom-right 2x2 = M-control. The diagonal elements of M-trained (A,D depicted below) reflect the representational similarity for the *same* object between runs. The off diagonal elements of M-trained (B,C) reflect the similarity between different objects across runs. Mean of (B,C) - Mean(A,D) = Representational distance between objects in this phase.  \n",
    "| __ A __ | __ B __ |  \n",
    "| __ C __ | __ D __ |  \n",
    "Do the above for the pretest, then for the posttest; the difference between the resulting values is an *unanchored* measure of how differentiated the the object representations have become between the pre and post-training phases:\n",
    "\n",
    "*Unanchored Differentiation = (Post-Phase Representational Distance) - (Pre-Phase Representational Distance)*\n",
    "\n",
    "By computing this measure of prepost differentiation again for the control objects and taking the difference between Trained Prepost Differentiation and Control Prepost Differentiation, we attempt to identify the amount of prepost differentiation that occurred specifically as a result of training. \n",
    "\n",
    "#### Anchored Pre-Post Representational Differentiation [deprecated]\n",
    "Another approach to calculating prepost differentiation is to take the mean of the representational distances between different-phase trained object representations (eg the distance between the pre-phase representation of object 1 and the post-phase representation of object 2, and the distance between the pre-phase representation of object 2 and the post-phase representation of object 1) and then subtracting from this mean the representational distance between pre-phase trained object representations (the distance between the pre-phase representations of object 1 and object 2).\n",
    "\n",
    "In terms of matrix computations, the key difference here from the unanchored measure is beginning with three matrices, and for the first two vertically concatenating corresponding runs of distinct phases (runs 3 and 5, and runs 4 and 6) instead of runs of the same phase. The third matrix is produced the same way the pre-phase object&run-by-voxel matrix is produced for measuring unanchored differentiation. Once representational distance is computed from each of these matrices, anchored prepost representational differentiation is found from the formula:  \n",
    "\n",
    "*Anchored Differentation = mean((Runs 3&5 Representational Distance), (Runs 4&6 Representational Distance)) - (Pre-Phase Representational Distance)*\n",
    "\n",
    "As for unanchored differentiation, computing this measure of prepost differentiation again for the control objects and taking the difference between Trained Prepost Differentiation and Control Prepost Differentiation, we attempt to identify the amount of prepost differentiation that occurred specifically as a result of training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import shape\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## root paths\n",
    "curr_dir = os.getcwd()\n",
    "os.path.abspath(os.path.join(curr_dir,'..','..'))\n",
    "\n",
    "proj_dir = os.path.abspath(os.path.join(curr_dir,'..','..')) ## use relative paths\n",
    "data_dir = os.path.abspath(os.path.join(curr_dir,'..','..','data')) ## use relative paths 'D:\\\\data'\n",
    "results_dir = os.path.join(proj_dir, 'csv')\n",
    "nb_name = '1_recog_prepost_RSA'\n",
    "\n",
    "## add helpers to python path\n",
    "import sys\n",
    "if os.path.join(proj_dir, 'python') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir, 'python'))\n",
    "\n",
    "## module definitions\n",
    "import analysis_helpers as helpers\n",
    "core_ROIs = ['V1','V2','LOC','IT','fusiform','parahippo','PRC','ento','hipp']\n",
    "other_ROIs = ['mOFC','Frontal','Parietal','supraMarginal','Insula','postCentral','preCentral']\n",
    "ROIs = core_ROIs\n",
    "all_ROIs = core_ROIs + other_ROIs\n",
    "core_ROIs_formatted = [\"V1\", \"V2\", \"LOC\", \"IT\", \"FUS\", \"PHC\",  \"PRC\",  \"ENT\", \"HC\"]\n",
    "other_ROIs_formatted = ['mOFC','Frontal', 'Parietal', 'supra\\nmarginal', 'Insula', 'post\\nCentral', 'preCentral']\n",
    "ROIs_formatted = core_ROIs_formatted \n",
    "all_ROIs_formatted = core_ROIs_formatted + other_ROIs_formatted\n",
    "roi_dir = os.path.join(data_dir, 'copes','roi')\n",
    "cope_dir = os.path.join(data_dir, 'copes','recog','objectGLM')\n",
    "sub_dirs = sorted(os.listdir(roi_dir))\n",
    "helpers.roi_dir, helpers.cope_dir = roi_dir, cope_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate estimate representational differentiation for each subject and each ROI and each condition, outputting a subject-by-roi arrays for each configuration of condition and differentiation measurement approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Tradiffpre, Condiffpre, Tradiffpost, Condiffpost = [], [], [], []\n",
    "\n",
    "for roi_ind, roi in enumerate(ROIs):\n",
    "    _Tradiffpre, _Condiffpre, _Tradiffpost, _Condiffpost = [], [], [], []\n",
    "        \n",
    "    for s_ind, s in enumerate(sub_dirs):\n",
    "        print 'Analyzing participant {} | {} of {} in ROI {} | {} of {}'.format(s, s_ind+1, len(sub_dirs), roi, roi_ind+1, len(ROIs))\n",
    "        clear_output(wait=True)\n",
    "        trawit_mean_pre, conwit_mean_pre, trabtw_mean_pre, conbtw_mean_pre = \\\n",
    "        helpers.compare_btw_wit_cond_similarity_across_runs(s,'pre',roi)\n",
    "        trawit_mean_post, conwit_mean_post, trabtw_mean_post, conbtw_mean_post = \\\n",
    "        helpers.compare_btw_wit_cond_similarity_across_runs(s,'post',roi)\n",
    "        \n",
    "        trawit_mean_on, conwit_mean_on, trabtw_mean_on, conbtw_mean_on = \\\n",
    "        helpers.compare_btw_wit_cond_similarity_across_runs(s,'35',roi)\n",
    "        trawit_mean_off, conwit_mean_off, trabtw_mean_off, conbtw_mean_off = \\\n",
    "        helpers.compare_btw_wit_cond_similarity_across_runs(s,'46',roi)\n",
    "        \n",
    "        _Tradiffpre.append(trabtw_mean_pre - trawit_mean_pre)\n",
    "        _Condiffpre.append(conbtw_mean_pre - conwit_mean_pre)\n",
    "        \n",
    "        _Tradiffpost.append(trabtw_mean_post - trawit_mean_post)\n",
    "        _Condiffpost.append(conbtw_mean_post - conwit_mean_post)\n",
    "\n",
    "    _Tradiffpre,_Condiffpre, _Tradiffpost,_Condiffpost= \\\n",
    "    map(np.array, [_Tradiffpre,_Condiffpre,_Tradiffpost,_Condiffpost])\n",
    "    \n",
    "    if len(Tradiffpre)==0:\n",
    "        Tradiffpre = _Tradiffpre\n",
    "        Condiffpre = _Condiffpre\n",
    "        Tradiffpost = _Tradiffpost\n",
    "        Condiffpost = _Condiffpost\n",
    "    else:\n",
    "        Tradiffpre = np.vstack((Tradiffpre,_Tradiffpre))\n",
    "        Condiffpre = np.vstack((Condiffpre,_Condiffpre))\n",
    "        Tradiffpost = np.vstack((Tradiffpost,_Tradiffpost))\n",
    "        Condiffpost = np.vstack((Condiffpost,_Condiffpost))\n",
    "        \n",
    "TrainedDiff = Tradiffpost-Tradiffpre\n",
    "ControlDiff = Condiffpost-Condiffpre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save out the differentiation measures as a DataFrame inside a csv."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### longform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## construct \"longform\" pandas dataframe with the labels spread out across columns (code could be cleaned up more)\n",
    "\n",
    "# trained\n",
    "UTD = pd.DataFrame(TrainedDiff.transpose())\n",
    "UTD.columns = core_ROIs_formatted\n",
    "UTD = UTD.assign(condition = pd.Series(np.tile('trained',len(UTD))))\n",
    "\n",
    "# control\n",
    "UCD = pd.DataFrame(ControlDiff.transpose())\n",
    "UCD.columns = core_ROIs_formatted\n",
    "UCD = UCD.assign(condition = pd.Series(np.tile('control',len(UCD))))\n",
    "\n",
    "## get trained vs. control differences\n",
    "UD = UTD[core_ROIs_formatted].sub(UCD[core_ROIs_formatted])\n",
    "UD = UD.assign(anchoring = pd.Series(np.zeros(len(UD)), dtype=bool)) \n",
    "UD = UD.assign(condition = pd.Series(np.tile('difference',len(UD))))\n",
    "\n",
    "## concatenate into single dataframe\n",
    "D = pd.concat((UTD,UCD,UD),axis=0,ignore_index=True)\n",
    "\n",
    "## sanity checks\n",
    "assert D[D['condition']=='control'].shape[0] == len(UTD)\n",
    "\n",
    "## melt into long-form dataframe\n",
    "D = pd.melt(D, \n",
    "            id_vars=['condition'], \n",
    "            var_name='roi',\n",
    "            value_vars=core_ROIs_formatted, \n",
    "            value_name='prepost_diff')\n",
    "\n",
    "## add subject column\n",
    "unique_subs = [i.split('_')[0] for i in sub_dirs]\n",
    "flat_sub_list = helpers.flatten([unique_subs]*(len(ROIs)*3))\n",
    "D = D.assign(sub=pd.Series(flat_sub_list))\n",
    "\n",
    "## save out (note: \"anchoring\" designation is deprecated)\n",
    "D.to_csv(os.path.join(results_dir, 'neural_changes_by_surfroi_and_subject_longform.csv'),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning-related changes in representational distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot prepost representational differentiation for each ROI.  \n",
    "One plot (4 total) for each possible configuration of these parameters drawn:\n",
    "- Representational differentiation measure\n",
    "- Here we plot the relative change in correlation distance between Trained and Control conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load differentation scores back in\n",
    "D = pd.read_csv(os.path.join(results_dir, 'neural_changes_by_surfroi_and_subject_longform.csv'))\n",
    "\n",
    "## subset to only differences between trained and control conditions\n",
    "D = D[D['condition']=='difference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Effect of Training on Representational DISTANCE:\n",
    "## Are representational distances between object categories after training compared to our control?\n",
    "## Change in Representational DISTANCE: YES if Trained reliably more positive than Control\n",
    "\n",
    "import scipy\n",
    "def trimmean(x,prop_cut = 0.1):\n",
    "    return scipy.stats.trim_mean(x,prop_cut)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.set_context('talk')\n",
    "sns.set_style('ticks')\n",
    "\n",
    "p = sns.stripplot(x=\"roi\", \n",
    "                    y=\"prepost_diff\", \n",
    "                    palette='husl',\n",
    "                    data=D)\n",
    "\n",
    "b = sns.barplot(x='roi',\n",
    "            y='prepost_diff',\n",
    "            palette='husl',\n",
    "            estimator=trimmean,\n",
    "            ci=95,\n",
    "            data=D)\n",
    "\n",
    "plt.ylabel('change in correlation distance',fontsize=20)\n",
    "plt.xlabel('')\n",
    "plt.ylim(-0.3,0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(proj_dir, 'plots', nb_name, \n",
    "                         'prepost_differentiation_by_roi_condition.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
