{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design and Goal\n",
    "There are four objects (bed, bench, chair, table). Participants viewed each object 20 times per run.\n",
    "- Runs 1 & 2 -- reserved to conduct searchlight\n",
    "- Runs 3 & 4 -- pretest phase \n",
    "- Four training runs involving practice drawing two of the trained objects. \n",
    "- Runs 5 & 6 -- posttest phase\n",
    "\n",
    "Our goal is to understand the change in the similarity between representations of trained (vs control) objects in several anatomically-defined ROIs before and after training.\n",
    "\n",
    "## Approach\n",
    "#### Unanchored Pre-Post Representational Differentiation\n",
    "Define 'representation' as cope maps generated upon fitting GLM to each object for each run. Start by building an object x voxel matrix (4xK) for each run and vertically concatenate the two runs in each phase. Using this, compute a correlation matrix. \n",
    "\n",
    "Consider M = off-diagonal 4x4 block [:4,4:8] of this matrix; ensure the rows are sorted such that the first two are the Trained, and the last two are the Control objects. Now take the the top-left 2x2 matrix within M and let's call it M-trained. The bottom-right 2x2 = M-control. The diagonal elements of M-trained (A,D depicted below) reflect the representational similarity for the *same* object between runs. The off diagonal elements of M-trained (B,C) reflect the similarity between different objects across runs. Mean of (B,C) - Mean(A,D) = Representational distance between objects in this phase.  \n",
    "|__ A __|__ B __|  \n",
    "|__ C __|__ D __|  \n",
    "Do the above for the pretest, then for the posttest; the difference between the resulting values is an *unanchored* measure of how differentiated the the object representations have become between the pre and post-training phases:\n",
    "\n",
    "*Unanchored Differentiation = (Post-Phase Representational Distance) - (Pre-Phase Representational Distance)*\n",
    "\n",
    "By computing this measure of prepost differentiation again for the control objects and taking the difference between Trained Prepost Differentiation and Control Prepost Differentiation, we attempt to identify the amount of prepost differentiation that occurred specifically as a result of training. \n",
    "\n",
    "#### Anchored Pre-Post Representational Differentiation\n",
    "Another approach to calculating prepost differentiation is to take the mean of the representational distances between different-phase trained object representations (eg the distance between the pre-phase representation of object 1 and the post-phase representation of object 2, and the distance between the pre-phase representation of object 2 and the post-phase representation of object 1) and then subtracting from this mean the representational distance between pre-phase trained object representations (the distance between the pre-phase representations of object 1 and object 2).\n",
    "\n",
    "In terms of matrix computations, the key difference here from the unanchored measure is beginning with three matrices, and for the first two vertically concatenating corresponding runs of distinct phases (runs 3 and 5, and runs 4 and 6) instead of runs of the same phase. The third matrix is produced the same way the pre-phase object&run-by-voxel matrix is produced for measuring unanchored differentiation. Once representational distance is computed from each of these matrices, anchored prepost representational differentiation is found from the formula:  \n",
    "\n",
    "*Anchored Differentation = mean((Runs 3&5 Representational Distance), (Runs 4&6 Representational Distance)) - (Pre-Phase Representational Distance)*\n",
    "\n",
    "As for unanchored differentiation, computing this measure of prepost differentiation again for the control objects and taking the difference between Trained Prepost Differentiation and Control Prepost Differentiation, we attempt to identify the amount of prepost differentiation that occurred specifically as a result of training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import shape\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add helpers to python path\n",
    "import sys\n",
    "if 'D:\\\\neurosketch-master\\\\python' not in sys.path:\n",
    "    sys.path.append('D:\\\\neurosketch-master\\\\python')\n",
    "\n",
    "## root paths\n",
    "curr_dir = os.getcwd()\n",
    "data_dir = 'D:\\\\data'\n",
    "proj_dir = 'D:\\\\neurosketch-master'\n",
    "results_dir = 'D:\\\\neurosketch-master\\\\csv'\n",
    "nb_name = '1_recog_prepost_RSA.ipynb'\n",
    "\n",
    "## module definitions\n",
    "import analysis_helpers as helpers\n",
    "ROIs = ['V1','V2','LOC','IT','fusiform','parahippo','PRC','ento','hipp','mOFC',\n",
    "        'Frontal','Parietal','supraMarginal','Insula','postCentral','preCentral']\n",
    "ROIs_formatted = [\"V1\", \"V2\", \"LOC\", \"IT\", \"fusiform\", \"para\\nhippo\",  \"PRC\",  \"ento\", \"hipp\", 'mOFC',\n",
    "                 'Frontal', 'Parietal', 'supra\\nmarginal', 'Insula', 'post\\nCentral', 'preCentral']\n",
    "roi_dir = os.path.join(data_dir, 'copes\\\\roi')\n",
    "cope_dir = os.path.join(data_dir, 'copes\\\\recog\\\\objectGLM')\n",
    "sub_dirs = sorted(os.listdir(roi_dir))\n",
    "helpers.roi_dir, helpers.cope_dir = roi_dir, cope_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce anchored and unanchored measures of representational differentiation for each subject and each ROI and each condition, outputting a subject-by-roi arrays for each configuration of condition and differentiation measurement approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Tradiffpre, Condiffpre, Tradiffpost, Condiffpost = [], [], [], []\n",
    "AnchoredTrainedDiff, AnchoredControlDiff = [], []\n",
    "\n",
    "for roi in ROIs:\n",
    "    _Tradiffpre, _Condiffpre, _Tradiffpost, _Condiffpost = [], [], [], []\n",
    "    _AnchoredTrained, _AnchoredControl = [], []\n",
    "        \n",
    "    for s in sub_dirs:\n",
    "        trawit_mean_pre, conwit_mean_pre, trabtw_mean_pre, conbtw_mean_pre = \\\n",
    "        helpers.compare_btw_wit_cond_similarity_across_runs(s,'pre',roi)\n",
    "        trawit_mean_post, conwit_mean_post, trabtw_mean_post, conbtw_mean_post = \\\n",
    "        helpers.compare_btw_wit_cond_similarity_across_runs(s,'post',roi)\n",
    "        \n",
    "        trawit_mean_on, conwit_mean_on, trabtw_mean_on, conbtw_mean_on = \\\n",
    "        helpers.compare_btw_wit_cond_similarity_across_runs(s,'35',roi)\n",
    "        trawit_mean_off, conwit_mean_off, trabtw_mean_off, conbtw_mean_off = \\\n",
    "        helpers.compare_btw_wit_cond_similarity_across_runs(s,'46',roi)\n",
    "        \n",
    "        _Tradiffpre.append(trabtw_mean_pre - trawit_mean_pre)\n",
    "        _Condiffpre.append(conbtw_mean_pre - conwit_mean_pre)\n",
    "        \n",
    "        _Tradiffpost.append(trabtw_mean_post - trawit_mean_post)\n",
    "        _Condiffpost.append(conbtw_mean_post - conwit_mean_post)\n",
    "    \n",
    "        _AnchoredTrained.append(\n",
    "            np.mean([(trabtw_mean_on - trawit_mean_on), (trabtw_mean_off - trawit_mean_off)]) -\n",
    "            (trabtw_mean_pre - trawit_mean_pre))\n",
    "        _AnchoredControl.append(\n",
    "            np.mean([(conbtw_mean_on - conwit_mean_on), (conbtw_mean_off - conwit_mean_off)]) -\n",
    "            (conbtw_mean_pre - conwit_mean_pre))\n",
    "        \n",
    "    _Tradiffpre,_Condiffpre, _Tradiffpost,_Condiffpost, _AnchoredTrained, _AnchoredControl = \\\n",
    "    map(np.array, [_Tradiffpre,_Condiffpre,_Tradiffpost,_Condiffpost, _AnchoredTrained, _AnchoredControl])\n",
    "    \n",
    "    if len(Tradiffpre)==0:\n",
    "        Tradiffpre = _Tradiffpre\n",
    "        Condiffpre = _Condiffpre\n",
    "        Tradiffpost = _Tradiffpost\n",
    "        Condiffpost = _Condiffpost\n",
    "        AnchoredTrainedDiff = _AnchoredTrained\n",
    "        AnchoredControlDiff = _AnchoredControl\n",
    "    else:\n",
    "        Tradiffpre = np.vstack((Tradiffpre,_Tradiffpre))\n",
    "        Condiffpre = np.vstack((Condiffpre,_Condiffpre))\n",
    "        AnchoredTrainedDiff = np.vstack((AnchoredTrainedDiff,_AnchoredTrained))\n",
    "        AnchoredControlDiff = np.vstack((AnchoredControlDiff,_AnchoredControl))\n",
    "        Tradiffpost = np.vstack((Tradiffpost,_Tradiffpost))\n",
    "        Condiffpost = np.vstack((Condiffpost,_Condiffpost))\n",
    "        \n",
    "UnanchoredTrainedDiff = Tradiffpost-Tradiffpre\n",
    "UnanchoredControlDiff = Condiffpost-Condiffpre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save out the differentiation measures as a DataFrame inside a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.DataFrame(data=sub_dirs, columns = ['IDs'])\n",
    "MAT = np.hstack((AnchoredTrainedDiff.transpose(),AnchoredControlDiff.transpose(),\n",
    "                 UnanchoredTrainedDiff.transpose(), UnanchoredControlDiff.transpose()))\n",
    "\n",
    "CONDS = ['AnchoredTrainedDiff', 'AnchoredControlDiff',\n",
    "         'UnanchoredTrainedDiff', 'UnanchoredControlDiff']\n",
    "headers = []\n",
    "for cond in CONDS:\n",
    "    for roi in ROIs:\n",
    "        headers.append('{}_{}'.format(cond,roi))\n",
    "        \n",
    "df = pd.DataFrame(data=MAT, columns = headers)\n",
    "ids = pd.DataFrame(np.array(sub_dirs), columns = ['IDs'])\n",
    "df = pd.concat([ids, df], axis = 1)\n",
    "df.to_csv(os.path.join(results_dir, 'neural_changes_by_surfroi_and_subject.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity to measuring differences between object representations separately in each phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure that in each ROI and each phase the off-diagonal minus on-diagonal elements (btw-within) in each ROI > 0.  \n",
    "This is a critical sanity check, as it indicates that the correlation distance between representations of *different* objects is larger than the correlation distance between the *same* object.  \n",
    "This needs to be the case for looking at learning to make sense. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "sns.set_context('poster')\n",
    "\n",
    "tmp = np.dstack((Tradiffpre,Condiffpre))\n",
    "Diffpre = np.nanmean(tmp, axis=2)\n",
    "tmp = np.dstack((Tradiffpost,Condiffpost))\n",
    "Diffpost = np.nanmean(tmp, axis=2)\n",
    "\n",
    "means_pre = np.nanmean(Diffpre, axis=1)\n",
    "std_pre = np.nanstd(Diffpre, axis=1)/np.sqrt(shape(Diffpre)[1])\n",
    "\n",
    "means_post = np.nanmean(Diffpost, axis=1)\n",
    "std_post = np.nanstd(Diffpost, axis=1)/np.sqrt(shape(Diffpost)[1])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(len(ROIs),6))\n",
    "\n",
    "n_groups = len(ROIs) # num ROIs\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35\n",
    "\n",
    "opacity = 0.8\n",
    "error_config = {'ecolor': '0.3'}\n",
    "\n",
    "## plot means as bars\n",
    "tcolor = (0.4,0.4,0.4)\n",
    "rects1 = plt.bar(index, means_pre, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color=(0.4,0.4,0.4),\n",
    "                 yerr=std_pre,\n",
    "                 error_kw=error_config,\n",
    "                 label='Pre')\n",
    "\n",
    "ccolor = (0.7,0.7,0.7)\n",
    "rects2 = plt.bar(index + bar_width, means_post, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color=(0.7,0.7,0.7),\n",
    "                 yerr=std_post,\n",
    "                 error_kw=error_config,\n",
    "                 label='Post')\n",
    "\n",
    "\n",
    "plt.xlabel('ROIs')\n",
    "plt.ylabel('Btw vs. W/in-Obj Distance')\n",
    "plt.title('Sensitivity to differences between object representations')\n",
    "plt.xticks(index + bar_width / 2, ROIs_formatted)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('./plots/sensitivity_to_measuring_distances.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning-related changes in representational distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot prepost representational differentiation for each ROI.  \n",
    "One plot (4 total) for each possible configuration of these parameters drawn:\n",
    "- Anchored vs Unanchored representational differentiation measure\n",
    "- Separate results by condition vs plot the difference between conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unanchored Representational Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot prepost representational differentiation for each ROI, **separating results by condition**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate summary plot (main analysis; old distance measure)\n",
    "\n",
    "plot_indiv_subs = 0\n",
    "\n",
    "sns.set_style('white')\n",
    "sns.set_context('poster')\n",
    "\n",
    "means_trained = np.nanmean(UnanchoredTrainedDiff, axis=1)\n",
    "std_trained = np.nanstd(UnanchoredTrainedDiff, axis=1)/np.sqrt(shape(UnanchoredTrainedDiff)[1])\n",
    "\n",
    "means_control = np.nanmean(UnanchoredControlDiff, axis=1)\n",
    "std_control = np.nanstd(UnanchoredControlDiff, axis=1)/np.sqrt(shape(UnanchoredControlDiff)[1])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(len(ROIs),6))\n",
    "\n",
    "n_groups = len(ROIs) # num ROIs\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35\n",
    "\n",
    "opacity = 0.8\n",
    "error_config = {'ecolor': '0.3'}\n",
    "\n",
    "## plot means as bars\n",
    "tcolor = (0.8,0.4,0.4)\n",
    "rects1 = plt.bar(index, means_trained, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color=(0.8,0.4,0.4),\n",
    "                 yerr=std_trained,\n",
    "                 error_kw=error_config,\n",
    "                 label='Trained')\n",
    "\n",
    "ccolor = (0.4,0.4,0.4)\n",
    "rects2 = plt.bar(index + bar_width, means_control, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color=(0.4,0.4,0.4),\n",
    "                 yerr=std_control,\n",
    "                 error_kw=error_config,\n",
    "                 label='Control')\n",
    "\n",
    "if plot_indiv_subs:\n",
    "    ## now plot individual subjects as dots\n",
    "    def generate_concat_tiled(array,reps):        \n",
    "        inds = []\n",
    "        for i in index:\n",
    "            inds.append(np.tile(i,reps))\n",
    "        return np.reshape(np.array(inds),(1,reps*len(array)))\n",
    "\n",
    "    tindex = generate_concat_tiled(index,len(UnanchoredTrainedDiff[0]))\n",
    "    tsubdists = np.reshape(UnanchoredTrainedDiff,(1,shape(UnanchoredTrainedDiff)[0]*shape(UnanchoredTrainedDiff)[1]))\n",
    "    plt.scatter(tindex,tsubdists,s=25,alpha=0.2,color=tcolor)\n",
    "\n",
    "    cindex = generate_concat_tiled(index,len(UnanchoredControlDiff[0]))+bar_width\n",
    "    csubdists = np.reshape(UnanchoredControlDiff,(1,shape(UnanchoredControlDiff)[0]*shape(UnanchoredControlDiff)[1]))\n",
    "    plt.scatter(cindex,csubdists,s=25,alpha=0.2,color=ccolor)\n",
    "\n",
    "plt.xlabel('ROIs')\n",
    "plt.ylabel('Change in Representational DISTANCE\\n(YES if Trained reliably more positive than Control)')\n",
    "plt.title('Effect of Training on Representational DISTANCE:\\n\"Are representational distances between object categories\\nHIGHER after training compared to our control?\"')\n",
    "plt.xticks(index + bar_width / 2, ROIs_formatted)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('./plots/unanchored_differentiation_by_roicondition.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot prepost representational differentiation for each ROI, ** now taking the difference between conditions**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate summary plot (main analysis; old distance measure)\n",
    "plot_indiv_subs = 0\n",
    "\n",
    "sns.set_style('white')\n",
    "sns.set_context('poster')\n",
    "diffdiff = UnanchoredTrainedDiff-UnanchoredControlDiff\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(len(ROIs),6))\n",
    "\n",
    "n_groups = len(ROIs) # num ROIs\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35\n",
    "\n",
    "opacity = 0.8\n",
    "error_config = {'ecolor': '0.3'}\n",
    "\n",
    "## plot means as bars\n",
    "tcolor = (0.8,0.4,0.4)\n",
    "rects1 = plt.bar(index, means_trained-means_control, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color=(0.8,0.4,0.4),\n",
    "                 yerr=np.nanstd(diffdiff, axis=1)/np.sqrt(shape(diffdiff)[1]),\n",
    "                 error_kw=error_config,\n",
    "                 label='Trained')\n",
    "\n",
    "ccolor = (0.4,0.4,0.4)\n",
    "\n",
    "if plot_indiv_subs:\n",
    "    ## now plot individual subjects as dots\n",
    "    def generate_concat_tiled(array,reps):        \n",
    "        inds = []\n",
    "        for i in index:\n",
    "            inds.append(np.tile(i,reps))\n",
    "        return np.reshape(np.array(inds),(1,reps*len(array)))\n",
    "\n",
    "    tindex = generate_concat_tiled(index,len(UnanchoredTrainedDiff[0]))\n",
    "    tsubdists = np.reshape(UnanchoredTrainedDiff,(1,shape(UnanchoredTrainedDiff)[0]*shape(UnanchoredTrainedDiff)[1]))\n",
    "    plt.scatter(tindex,tsubdists,s=25,alpha=0.2,color=tcolor)\n",
    "\n",
    "    cindex = generate_concat_tiled(index,len(UnanchoredControlDiff[0]))+bar_width\n",
    "    csubdists = np.reshape(UnanchoredControlDiff,(1,shape(UnanchoredControlDiff)[0]*shape(UnanchoredControlDiff)[1]))\n",
    "    plt.scatter(cindex,csubdists,s=25,alpha=0.2,color=ccolor)\n",
    "\n",
    "plt.xlabel('ROIs')\n",
    "plt.title('(Unanchored) Effect of Training on Representational DISTANCE:\\n\"Are representational distances between object categories\\nHIGHER after training compared to our control?\"')\n",
    "plt.ylabel('Difference Between Trained and Control Condition\\nChange in Representational DISTANCE\\n(YES if Positive)')\n",
    "plt.xticks(index + bar_width / 2,  ROIs_formatted)\n",
    "plt.savefig('./plots/unanchored_differentiation_by_roi.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anchored Representational Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot prepost representational differentiation for each ROI, **separating results by condition**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate summary plot (main analysis; old distance measure)\n",
    "plot_indiv_subs = 0\n",
    "\n",
    "sns.set_style('white')\n",
    "sns.set_context('poster')\n",
    "\n",
    "means_trained = np.nanmean(AnchoredTrainedDiff, axis=1)\n",
    "std_trained = np.nanstd(AnchoredTrainedDiff, axis=1)/np.sqrt(shape(AnchoredTrainedDiff)[1])\n",
    "\n",
    "means_control = np.nanmean(AnchoredControlDiff, axis=1)\n",
    "std_control = np.nanstd(AnchoredControlDiff, axis=1)/np.sqrt(shape(AnchoredControlDiff)[1])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(len(ROIs),6))\n",
    "\n",
    "n_groups = len(ROIs)\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35\n",
    "\n",
    "opacity = 0.8\n",
    "error_config = {'ecolor': '0.3'}\n",
    "\n",
    "## plot means as bars\n",
    "tcolor = (0.8,0.4,0.4)\n",
    "rects1 = plt.bar(index, means_trained, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color=(0.8,0.4,0.4),\n",
    "                 yerr=std_trained,\n",
    "                 error_kw=error_config,\n",
    "                 label='Trained')\n",
    "\n",
    "ccolor = (0.4,0.4,0.4)\n",
    "rects2 = plt.bar(index + bar_width, means_control, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color=(0.4,0.4,0.4),\n",
    "                 yerr=std_control,\n",
    "                 error_kw=error_config,\n",
    "                 label='Control')\n",
    "\n",
    "if plot_indiv_subs:\n",
    "    ## now plot individual subjects as dots\n",
    "    def generate_concat_tiled(array,reps):        \n",
    "        inds = []\n",
    "        for i in index:\n",
    "            inds.append(np.tile(i,reps))\n",
    "        return np.reshape(np.array(inds),(1,reps*len(array)))\n",
    "\n",
    "    tindex = generate_concat_tiled(index,len(Trained[0]))\n",
    "    tsubdists = np.reshape(Trained,(1,shape(Trained)[0]*shape(Trained)[1]))\n",
    "    plt.scatter(tindex,tsubdists,s=25,alpha=0.2,color=tcolor)\n",
    "\n",
    "    cindex = generate_concat_tiled(index,len(Control[0]))+bar_width\n",
    "    csubdists = np.reshape(Control,(1,shape(Control)[0]*shape(Control)[1]))\n",
    "    plt.scatter(cindex,csubdists,s=25,alpha=0.2,color=ccolor)\n",
    "\n",
    "plt.xlabel('ROIs')\n",
    "plt.ylabel('Change in Representational DISTANCE\\n(YES if Trained reliably more positive than Control)')\n",
    "plt.title('Effect of Training on Representational DISTANCE:\\n\"Are representational distances between object categories\\nHIGHER after training compared to our control?\"')\n",
    "plt.xticks(index + bar_width / 2, ROIs_formatted)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('./plots/anchored_differentiation_by_roicondition.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot prepost representational differentiation for each ROI, ** now taking the difference between conditions**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate summary plot (main analysis)\n",
    "plot_indiv_subs = 0\n",
    "\n",
    "sns.set_style('white')\n",
    "sns.set_context('poster')\n",
    "\n",
    "diffdiff = AnchoredTrainedDiff - AnchoredControlDiff\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(len(ROIs),6))\n",
    "\n",
    "n_groups = len(ROIs)\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35\n",
    "\n",
    "opacity = 0.8\n",
    "error_config = {'ecolor': '0.3'}\n",
    "\n",
    "## plot means as bars\n",
    "tcolor = (0.8,0.4,0.4)\n",
    "rects1 = plt.bar(index, means_trained-means_control, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color=(0.8,0.4,0.4),\n",
    "                 yerr=np.nanstd(diffdiff, axis=1)/np.sqrt(shape(diffdiff)[1]),\n",
    "                 error_kw=error_config,\n",
    "                 label='Trained')\n",
    "\n",
    "ccolor = (0.4,0.4,0.4)\n",
    "\n",
    "if plot_indiv_subs:\n",
    "    ## now plot individual subjects as dots\n",
    "    def generate_concat_tiled(array,reps):        \n",
    "        inds = []\n",
    "        for i in index:\n",
    "            inds.append(np.tile(i,reps))\n",
    "        return np.reshape(np.array(inds),(1,reps*len(array)))\n",
    "\n",
    "    tindex = generate_concat_tiled(index,len(Trained[0]))\n",
    "    tsubdists = np.reshape(Trained,(1,shape(Trained)[0]*shape(Trained)[1]))\n",
    "    plt.scatter(tindex,tsubdists,s=25,alpha=0.2,color=tcolor)\n",
    "\n",
    "    cindex = generate_concat_tiled(index,len(Control[0]))+bar_width\n",
    "    csubdists = np.reshape(Control,(1,shape(Control)[0]*shape(Control)[1]))\n",
    "    plt.scatter(cindex,csubdists,s=25,alpha=0.2,color=ccolor)\n",
    "\n",
    "plt.xlabel('ROIs')\n",
    "plt.title('(Anchored) Effect of Training on Representational DISTANCE:\\n\"Are representational distances between object categories\\nHIGHER after training compared to our control?\"')\n",
    "plt.ylabel('Difference Between Trained and Control Condition\\nChange in Representational DISTANCE\\n(YES if Positive)')\n",
    "plt.xticks(index + bar_width / 2,  ROIs_formatted)\n",
    "plt.savefig('./plots/anchored_differentiation_by_roi.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
