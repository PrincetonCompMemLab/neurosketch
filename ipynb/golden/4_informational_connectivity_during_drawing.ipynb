{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import imageio\n",
    "import warnings\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.stats import norm\n",
    "from IPython.display import clear_output\n",
    "from PIL import Image\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do you want to show figures in the notebook?\n",
    "#### Do you want to save them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_fig = False\n",
    "save_fig = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign project directory\n",
    "main_dir = '/Users/jeffwammes/Working/neurosketch/'\n",
    "\n",
    "# Assign paths where features can be found\n",
    "data_dir = '/Volumes/ntb/projects/sketchloop02/data'\n",
    "path_to_recog = str(data_dir) + '/features/recog'\n",
    "path_to_draw = str(data_dir) + '/features/drawing'\n",
    "\n",
    "#Where to put plots\n",
    "put_plots = str(main_dir) + 'plots/4_informational_connectivity_during_drawing/'\n",
    "\n",
    "roi_list = np.array(['V1Draw', 'V2Draw', 'LOCDraw', 'ParietalDraw', \n",
    "                     'smgDraw', 'postCentralDraw', 'preCentralDraw', 'FrontalDraw'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## add helpers to python path\n",
    "import sys\n",
    "if str(main_dir)+'python' not in sys.path:\n",
    "    sys.path.append(str(main_dir)+'python')\n",
    "    \n",
    "# Suppress warnings to avoid output\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign variables within imported analysis helpers\n",
    "import analysis_helpers\n",
    "from importlib import reload\n",
    "reload(analysis_helpers)\n",
    "\n",
    "analysis_helpers.path_to_recog = path_to_recog\n",
    "analysis_helpers.path_to_draw = path_to_draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Helper data loader functions\n",
    "\n",
    "def preprocess_recog(RECOG_METAS, RECOG_FEATS):\n",
    "    M = [i for i in RECOG_METAS if len(i.split('.')[0].split('_'))==4]\n",
    "    F = [i for i in RECOG_FEATS if len(i.split('.')[0].split('_'))==4]\n",
    "    return M,F\n",
    "\n",
    "def extract_good_sessions(DRAW_METAS,DRAW_FEATS):\n",
    "    _DRAW_METAS = [i for i in DRAW_METAS if i.split('_')[1] in sub_list]\n",
    "    _DRAW_FEATS = [i for i in DRAW_FEATS if i.split('_')[0] in sub_list]\n",
    "    return _DRAW_METAS, _DRAW_FEATS\n",
    "\n",
    "def cleanup_df(df):    \n",
    "    surplus = [i for i in df.columns if 'Unnamed' in i]\n",
    "    df = df.drop(surplus,axis=1)\n",
    "    return df\n",
    "\n",
    "def load_draw_meta(this_sub):\n",
    "    this_file = 'metadata_{}_drawing.csv'.format(this_sub)\n",
    "    x = pd.read_csv(os.path.join(path_to_draw,this_file))\n",
    "    x = cleanup_df(x)\n",
    "    x['trial_num'] = np.repeat(np.arange(40),23)        \n",
    "    return x\n",
    "    \n",
    "def load_draw_feats(this_sub,this_roi):\n",
    "    this_file = '{}_{}_featurematrix.npy'.format(this_sub,this_roi)\n",
    "    y = np.load(os.path.join(path_to_draw,this_file))\n",
    "    y = y.transpose()\n",
    "    return y\n",
    "\n",
    "def load_draw_data(this_sub,this_roi):\n",
    "    x = load_draw_meta(this_sub)\n",
    "    y = load_draw_feats(this_sub,this_roi)\n",
    "    assert y.shape[0] == x.shape[0]    \n",
    "    return x,y\n",
    "\n",
    "    \n",
    "def objects(sub_list):\n",
    "    sub_obj = pd.DataFrame(columns=['objects', 'subject'])\n",
    "    for this_sub in sub_list:\n",
    "        DM, DF = load_draw_data(this_sub,'V1Draw')\n",
    "        trained_objs = np.unique(DM.label.values)\n",
    "        sub_obj = sub_obj.append({'objects': str(trained_objs[0])+str(trained_objs[1]), \n",
    "                                  'subject': this_sub}, ignore_index=True)\n",
    "    return sub_obj  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LOAD FILE LIST FOR RECOGNITION RUNS\n",
    "RECOG_METAS = sorted([i for i in os.listdir(path_to_recog) if i.split('.')[-1]=='csv'])\n",
    "RECOG_FEATS = sorted([i for i in os.listdir(path_to_recog) if i.split('.')[-1]=='npy'])\n",
    "RECOG_SUBS = np.array([i.split('_')[0] for i in RECOG_FEATS])\n",
    "\n",
    "recog_sub_list = np.unique(RECOG_SUBS)\n",
    "\n",
    "RECOG_METAS, RECOG_FEATS = preprocess_recog(RECOG_METAS, RECOG_FEATS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LOAD FILE LIST FOR DRAWING RUNS\n",
    "DRAW_METAS = sorted([i for i in os.listdir(path_to_draw) if i.split('.')[-1]=='csv'])\n",
    "DRAW_FEATS = sorted([i for i in os.listdir(path_to_draw) if i.split('.')[-1]=='npy'])\n",
    "DRAW_SUBS = np.array([i.split('_')[0] for i in DRAW_FEATS])\n",
    "draw_sub_list = np.unique(DRAW_SUBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## get subject ID's that have complete datasets from all phases of experiment\n",
    "sub_list = draw_sub_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## filter file list so only contains the sessions that have full datasets\n",
    "\n",
    "DRAW_METAS,DRAW_FEATS =  \\\n",
    "extract_good_sessions(DRAW_METAS,DRAW_FEATS)\n",
    "\n",
    "DRAW_SUBS = np.array([i.split('_')[0]+'_neurosketch' for i in DRAW_FEATS])\n",
    "DRAW_ROIS = np.array([i.split('_')[1] for i in DRAW_FEATS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## general plotting params\n",
    "sns.set_context('poster')\n",
    "colors = sns.color_palette(\"cubehelix\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# derive lists of subjects depending on which two items they drew. Currently unused but may prove useful later\n",
    "sub_obj = objects(sub_list)\n",
    "\n",
    "bedbench = np.array(sub_obj[sub_obj['objects']=='bedbench']['subject'])\n",
    "bedchair = np.array(sub_obj[sub_obj['objects']=='bedchair']['subject'])\n",
    "bedtable = np.array(sub_obj[sub_obj['objects']=='bedtable']['subject'])\n",
    "benchchair = np.array(sub_obj[sub_obj['objects']=='benchchair']['subject'])\n",
    "benchtable = np.array(sub_obj[sub_obj['objects']=='benchtable']['subject'])\n",
    "chairtable = np.array(sub_obj[sub_obj['objects']=='chairtable']['subject'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUILD MATRIX CONTAINING CLASSIFIER PROBABILITIES FOR ALL SUBJECTS, ROIS, DRAWING RUNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set some initial parameters\n",
    "logged = [True]\n",
    "versions = ['2wayDraw']\n",
    "\n",
    "really_run = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if really_run:\n",
    "    for l in logged:\n",
    "        tag = 'logged' if l else 'raw'\n",
    "        for version in versions:\n",
    "            roi_list_short = roi_list\n",
    "            sub_list_short = sub_list\n",
    "            ALLDM, Acc = analysis_helpers.make_drawing_predictions(sub_list_short,roi_list_short,version=version,logged=l)\n",
    "            ALLDM.to_csv(str(main_dir)+'csv/logistic_timeseries_drawing_neural_{}_{}.csv'.format(version,tag)) ## train recog, test drawing run    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn accuracy into array\n",
    "Acc_array = np.array(Acc)\n",
    "x = pd.DataFrame(Acc_array.transpose())\n",
    "\n",
    "# Remove draw suffix\n",
    "acc_plot_names = ['V1', 'V2', 'LOC', 'Par', 'SMG', 'Sens', 'Mot', 'Front']\n",
    "roi_reduce = [roi[:-4] for roi in roi_list_short]\n",
    "x.columns = acc_plot_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.set_style({'font.family': [u'sans-serif'], 'font.sans-serif': [u'Arial'], \"axes.facecolor\": \"1\"})\n",
    "colmap = sns.light_palette((0, 99, 80), input=\"husl\", n_colors=8)[::-1]\n",
    "#colmap = sns.cubehelix_palette(12, start=i, rot=j, dark=0.2, light=.95, reverse=True)\n",
    "sns.barplot(data=x, palette=colmap[:], ci=95, linewidth=1.5, edgecolor=colmap[0])\n",
    "chance_dict = {'4way':0.25,'3way':0.33,'2way':0.5,'2wayDraw':0.5}\n",
    "plt.axhline(chance_dict[version],linestyle=':',color='k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Intersect of Drawing Task Map and ROI')\n",
    "#plt.tight_layout()\n",
    "plt.gcf().subplots_adjust(bottom=0.15)\n",
    "plt.savefig(str(put_plots)+'drawing_accuracy.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot raw classifier accuracy\n",
    "sns.set_context('talk')\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(data=x,palette='Set2',ci=95)\n",
    "chance_dict = {'4way':0.25,'3way':0.33,'2way':0.5, '2wayDraw': 0.5}\n",
    "plt.axhline(chance_dict[version],linestyle=':',color='k')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Intersect of Drawing Task Map and ROI')\n",
    "plt.tight_layout()\n",
    "plt.title('Object Classification during Drawing Runs')\n",
    "if save_fig:\n",
    "    plt.savefig(str(put_plots)+'drawing_classification.pdf')\n",
    "plt.show() if show_fig else plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORT AND PREPROCESS VGG PROBABILITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "types = ['bedbench', 'bedchair', 'bedtable', 'benchchair', 'benchtable', 'chairtable']\n",
    "subs = [bedbench, bedchair, bedtable, benchchair, benchtable, chairtable]\n",
    "objects = [['bed','bench'], ['bed','chair'], ['bed','table'], ['bench','chair'], ['bench','table'], ['chair','table']]\n",
    "obdict = dict(zip(types, objects))\n",
    "subdict = dict(zip(types, subs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logged = False\n",
    "baseline_correct = True\n",
    "bc = 'basecorr' if baseline_correct else ''\n",
    "tag = 'logged' if logged else 'raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload(analysis_helpers)\n",
    "\n",
    "VGG_feat = pd.read_csv(str(main_dir)+'csv/partial_sketch_full.csv')\n",
    "VGG_feat['time_point'] = VGG_feat['numSketch'] + 1\n",
    "VGG_feat['trial_num'] = VGG_feat['trial'] - 320\n",
    "VGG_feat['subj'] = [x.split('_')[0] for x in VGG_feat['wID']]\n",
    "VGG_feat['roi'] = 'VGG'\n",
    "VGG_feat['label'] = VGG_feat['target']\n",
    "VGG_feat['run_num'] = np.ceil((VGG_feat['trial_num']+1)/10)\n",
    "VGG_processed = []\n",
    "for subject in sub_list:\n",
    "    sub_only = VGG_feat[VGG_feat['subj']==subject]\n",
    "    for typer in types:\n",
    "        if subject in subdict[typer]:\n",
    "            t1, t2 = obdict[typer]\n",
    "            c1, c2 = [i for i in ['bed', 'bench', 'chair', 'table'] if i not in [t1, t2]]\n",
    "    sub_only['t1'] = t1\n",
    "    sub_only['t2'] = t2\n",
    "    sub_only['c1'] = c1\n",
    "    sub_only['c2'] = c2\n",
    "    _t1 = np.log(sub_only[t1]) if logged else np.array(sub_only[t1])\n",
    "    _t2 = np.log(sub_only[t2]) if logged else np.array(sub_only[t2])\n",
    "    _c1 = np.log(sub_only[c1]) if logged else np.array(sub_only[c1])\n",
    "    _c2 = np.log(sub_only[c2]) if logged else np.array(sub_only[c2])\n",
    "    sub_only['t1_prob'] = _t1 - _t1[0] if baseline_correct else _t1\n",
    "    sub_only['t2_prob'] = _t2 - _t2[0] if baseline_correct else _t2\n",
    "    sub_only['c1_prob'] = _c1 - _c1[0] if baseline_correct else _c1\n",
    "    sub_only['c2_prob'] = _c2 - _c2[0] if baseline_correct else _c2\n",
    "    \n",
    "\n",
    "    \n",
    "    if len(VGG_processed) == 0:\n",
    "        VGG_processed = sub_only\n",
    "    else:\n",
    "        VGG_processed = pd.concat((VGG_processed, sub_only))\n",
    "VGG_processed.to_csv(str(main_dir)+'csv/VGG_{}_{}.csv'.format(tag, bc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot correspondence between probabilities across regions - all time points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose whether you want a plot for every subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do you want to plot this subject-wise?\n",
    "plot_subs = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cycle through subjects, and compute the correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLDM = pd.read_csv(str(main_dir)+'csv/logistic_timeseries_drawing_neural_2wayDraw_logged.csv')\n",
    "VGG = pd.read_csv(str(main_dir)+'csv/VGG_{}_{}.csv'.format(tag, bc))\n",
    "\n",
    "\n",
    "_sub_list = np.unique(ALLDM['subj'])\n",
    "_roi_list = ['V1Draw','V2Draw', 'LOCDraw', 'ParietalDraw', 'smgDraw', \n",
    "             'postCentralDraw', 'preCentralDraw', 'FrontalDraw', 'VGG']\n",
    "roi_name = ['V1', 'V2', 'LOC', 'Par', 'SMG', 'Sens', 'Mot', 'Front', 'VGG']\n",
    "\n",
    "images = []\n",
    "all_subs_all_rois = []\n",
    "all_corrs = []\n",
    "\n",
    "for sub in _sub_list:\n",
    "    \n",
    "    # reduce the dataframes to contain only the relevant subject and roi\n",
    "    sub_out = str(sub) if len(str(sub)) == 7 else str('0')+str(sub)\n",
    "    sub_only = ALLDM[ALLDM['subj']==sub]\n",
    "    sub_only_vgg = VGG[VGG['subj']==sub]\n",
    "    drawpreds = []\n",
    "    for roi in _roi_list:\n",
    "        if roi == 'VGG':\n",
    "            roi_only = sub_only_vgg\n",
    "        else:\n",
    "            roi_only = sub_only[sub_only['roi']==roi]\n",
    "        t1 = np.array(roi_only['t1_prob'])\n",
    "        t2 = np.array(roi_only['t2_prob'])\n",
    "        assert t1.shape == t2.shape\n",
    "        trained = np.hstack((t1,t2))\n",
    "        drawpreds.append(trained)\n",
    "    drawpreds = np.array(drawpreds)\n",
    "    \n",
    "    #correlation across all regions for one subject\n",
    "    corrs = np.corrcoef(drawpreds)\n",
    "    \n",
    "    #stack subjects\n",
    "    all_corrs = corrs if len(all_corrs) == 0 else np.dstack((all_corrs, corrs))\n",
    "    \n",
    "    if plot_subs:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        # omit diagonal\n",
    "        np.place(corrs, corrs>0.9, np.nan)\n",
    "        fig, ax = plt.subplots(figsize=(10,10))\n",
    "        im = ax.matshow(corrs, vmin = -0.15, vmax = 0.65)\n",
    "        ax.set_xticklabels(['']+roi_name)\n",
    "        ax.set_yticklabels(['']+roi_name)\n",
    "        plt.colorbar(im)\n",
    "        plt.title(str(sub), y=1.08)\n",
    "        plt.tight_layout()\n",
    "        if save_fig:\n",
    "            plt.savefig(str(put_plots)+str(sub_out)+'.png')\n",
    "            currIm = Image.open(str(put_plots)+str(sub_out) + '.png')\n",
    "            images.append(currIm)\n",
    "        plt.show() if show_fig else plt.close()\n",
    "all_corrs = np.array(all_corrs)\n",
    "t, p = stats.ttest_1samp(all_corrs, 0, axis=2)\n",
    "    \n",
    "# giffify results\n",
    "if plot_subs and save_fig:\n",
    "    images = [np.array(image) for image in images]\n",
    "    imageio.mimsave(str(put_plots)+'all_mats_subs.gif', images, duration=1)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the average across subjects, first as a matrix, then as a barplot with 95 CI error bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot matrices showing average across subjects\n",
    "\n",
    "all_mean = np.mean(all_corrs, axis=2)\n",
    "all_std = (np.std(all_corrs, axis=2)/np.sqrt(len(_sub_list)))*1.96\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "im = ax.matshow(np.absolute(all_mean), vmin=0, vmax = 0.5)\n",
    "ax.set_xticklabels(['']+roi_name)\n",
    "ax.set_yticklabels(['']+roi_name)\n",
    "plt.colorbar(im)\n",
    "colours = im.cmap(im.norm(all_mean))\n",
    "if save_fig:\n",
    "    plt.savefig(str(put_plots)+'all_subjects.png')\n",
    "plt.show() if show_fig else plt.close()\n",
    "\n",
    "\n",
    "# Plot average across subjects as barplot with error bars\n",
    "\n",
    "indices = np.arange(0,9)\n",
    "fig, axes = plt.subplots(9,1,figsize=(10,10), sharey=True, sharex=True)\n",
    "for i in range(all_mean.shape[0]):\n",
    "    ax = axes[i]\n",
    "    means = all_mean[i,:]\n",
    "    sterr = all_std[i,:]\n",
    "    ax.bar(indices, means, 1, color=colours[i], yerr=sterr, zorder=-1, edgecolor='black', lw=2, \n",
    "           ecolor='red', error_kw=dict(lw=2, capsize=2.5, capthick=1))\n",
    "    ax.set_facecolor('white')\n",
    "    ax.set_xticks(indices)\n",
    "    ax.set_xticklabels(roi_name)\n",
    "    ax.text(9.5, 0.25, roi_name[i], fontsize=17, fontname=\"Arial\", verticalalignment='center', \n",
    "            horizontalalignment='center')\n",
    "    ax.set_ylim([-0.05,0.5])\n",
    "    plt.errorbar\n",
    "plt.tight_layout()\n",
    "if save_fig:\n",
    "    plt.savefig(str(put_plots)+'all_subjects_bar.png')\n",
    "plt.show() if show_fig else plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot correspondence between probabilities across regions - by timepoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose what time unit to plot by, and whether you want a moving window, or to plot every unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do you want to plot by trial number (trial_num), or by TR (time_point)    \n",
    "by = 'trial_num'\n",
    "\n",
    "# Do you want to plot as a moving window, or (if False) by each unit of time. \n",
    "moving = True\n",
    "\n",
    "# Choose the size of the moving window\n",
    "windowsize = 5\n",
    "\n",
    "# Choose whether you want the windows to be discrete (i.e. non-overlapping/binned)\n",
    "discrete = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This cell will create the actual plots, and giffify if you so choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ALLDM = pd.read_csv(str(main_dir)+'csv/logistic_timeseries_drawing_neural_2wayDraw_logged.csv')\n",
    "VGG = pd.read_csv(str(main_dir)+'csv/VGG_{}_{}.csv'.format(tag, bc))\n",
    "\n",
    "# if you decided to use moving window, default step size is 1, unless you want them discrete / binned\n",
    "# If you decided to use individual time points, then step and windowsize are both 1.\n",
    "if moving:\n",
    "    step = 1\n",
    "    if discrete:\n",
    "        step = windowsize\n",
    "else:\n",
    "    step = 1\n",
    "    windowsize = 1\n",
    "\n",
    "# depending on your chosen unit, the parameters for the looping change    \n",
    "if by == 'trial_num':\n",
    "    by_out = 'trial'\n",
    "    low = 0\n",
    "    high = 40\n",
    "elif by == 'time_point':\n",
    "    by_out = 'TR'\n",
    "    low = 1\n",
    "    high = 24\n",
    "\n",
    "_sub_list = np.unique(ALLDM['subj'])\n",
    "_roi_list = ['V1Draw','V2Draw', 'LOCDraw', 'ParietalDraw', 'smgDraw', \n",
    "             'postCentralDraw', 'preCentralDraw', 'FrontalDraw', 'VGG']\n",
    "roi_name = ['V1', 'V2', 'LOC', 'Par', 'SMG', 'Sens', 'Mot', 'Front', 'VGG']\n",
    "images = []\n",
    "all_all = []\n",
    "\n",
    "# Depending on choices made in prior cell, this will step through your chosen time interval\n",
    "for point in range(low,high-windowsize+1,step):\n",
    "    bottom = point\n",
    "    top = point + windowsize\n",
    "    # reduce to only data in relevant range for this loop\n",
    "    _ALLDM = ALLDM[ALLDM[by]>=bottom]\n",
    "    __ALLDM = _ALLDM[_ALLDM[by]<top]\n",
    "    _VGG = VGG[VGG[by]>=bottom]\n",
    "    __VGG = _VGG[_VGG[by]<top]\n",
    "    all_corrs = []\n",
    "    for sub in _sub_list:\n",
    "        \n",
    "        # reduce to only relevant subject\n",
    "        sub_only = __ALLDM[__ALLDM['subj']==sub]\n",
    "        sub_only_vgg = __VGG[__VGG['subj']==sub]\n",
    "        drawpreds = []\n",
    "        for roi in _roi_list:\n",
    "            # reduce to onyl relevant roi\n",
    "            if roi == 'VGG':\n",
    "                roi_only = sub_only_vgg\n",
    "            else:\n",
    "                roi_only = sub_only[sub_only['roi']==roi]\n",
    "            t1 = np.array(roi_only['t1_prob'])\n",
    "            t2 = np.array(roi_only['t2_prob'])\n",
    "            assert t1.shape == t2.shape\n",
    "            trained = np.hstack((t1,t2))\n",
    "            drawpreds.append(trained)\n",
    "        drawpreds = np.array(drawpreds)\n",
    "        corrs = np.corrcoef(drawpreds)\n",
    "        # stack correlations from each subject\n",
    "        all_corrs = corrs if len(all_corrs) == 0 else np.dstack((all_corrs, corrs))\n",
    "    all_corrs = np.array(all_corrs)\n",
    "    # do one sample t test for each\n",
    "    t, p = stats.ttest_1samp(all_corrs, 0, axis=2)\n",
    "    clear_output(wait=True)\n",
    "    all_collapse = np.mean(all_corrs, axis=2)\n",
    "    np.place(all_collapse, all_collapse>0.9, np.nan)\n",
    "    # plot the output for each time point\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    im = ax.matshow(all_collapse, vmin = 0, vmax = 0.5)\n",
    "    ax.set_xticklabels(['']+roi_name)\n",
    "    ax.set_yticklabels(['']+roi_name)\n",
    "    plt.colorbar(im)\n",
    "    smoothing = ', win_size = {}'.format(windowsize) if windowsize > 1 else ''\n",
    "    plt.title(str(by) + ': '+ str(point) + str(smoothing), y=1.08)\n",
    "    plt.tight_layout()\n",
    "    if save_fig:\n",
    "        plt.savefig(str(put_plots)+str(by_out)+'_'+str(point)+'.png')\n",
    "        currIm = Image.open(str(put_plots)+str(by_out)+'_'+str(point) + '.png')\n",
    "        images.append(currIm)\n",
    "    plt.show() if show_fig else plt.close()\n",
    "\n",
    "# giffify results\n",
    "if save_fig:\n",
    "    images = [np.array(image) for image in images]\n",
    "    imageio.mimsave(str(put_plots)+'all_mats_' + str(by_out) + '.gif', images, duration=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Fuzzy C Means clustering analysis\n",
    " \n",
    " https://pythonhosted.org/scikit-fuzzy/api/skfuzzy.html#cmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import skfuzzy as fuzz\n",
    "\n",
    "# True if you want to include only neural data, false if you want to include VGG\n",
    "exclude_VGG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if exclude_VGG:\n",
    "    end = -1\n",
    "    all_mean_clust = all_mean[:-1,:-1]\n",
    "    num = 8\n",
    "else:\n",
    "    end = None\n",
    "    all_mean_clust = all_mean\n",
    "    num = 9\n",
    "\n",
    "\n",
    "# replace nans with 1 so it will run\n",
    "all_mean_clust[np.isnan(all_mean_clust)]=1\n",
    "fpcs = []\n",
    "which_clusters = []\n",
    "# explore the number of clusters, likely want to compare 2, 3, and 4. 5 clusters for 8 ROIs is too many\n",
    "for ncenters in range(2,5):\n",
    "    # m is a fuzzification constant, high number is more fuzzification\n",
    "    cntr, u, u0, d, jm, p, fpc = fuzz.cluster.cmeans(all_mean_clust[:,:], \n",
    "                                                     ncenters, \n",
    "                                                     2, \n",
    "                                                     error=0.000000000000001, \n",
    "                                                     maxiter=100000000, \n",
    "                                                     init=None)\n",
    "    if ncenters == 2:\n",
    "        clusts = cntr\n",
    "    which_cluster = np.argmax(u, axis=0)\n",
    "    which_clusters = which_cluster if len(which_clusters) == 0 else np.vstack((which_clusters, which_cluster))\n",
    "    fpcs.append(fpc)  \n",
    "\n",
    "\n",
    "centers = np.expand_dims(np.arange(2,5),1)\n",
    "fpcs = np.expand_dims(np.array(fpcs),1)\n",
    "col_names = np.insert(roi_name[:end],0,'num_clusters')\n",
    "col_names = np.append(col_names,'fpc')\n",
    "results_frame = pd.DataFrame(np.hstack((centers,which_clusters, fpcs)), columns= col_names)\n",
    "\n",
    "print(results_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, two clusters will either come out as more or less the same as four, or much better.\n",
    "Also, the solution for 2 and 3 clusters is always the same, while the solution for 4, seems to have a few local minima, where the solution varies in whether ANY rois load maximally on a fourth factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "us = []\n",
    "for i in range((all_corrs.shape[2])):\n",
    "    all_mean_clust = all_corrs[:end,:end,i]\n",
    "    u, u0, d, jm, p, fpc = fuzz.cluster.cmeans_predict(all_mean_clust, clusts, 2, error=0.005, maxiter=1000)\n",
    "    which_cluster = np.argmax(u, axis=0)\n",
    "    us = np.array(u) if len(us)==0 else np.dstack((us,u))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "us_mean = np.mean(us, axis=2)\n",
    "us_std = np.std(us, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot barplot of cluster membership\n",
    "\n",
    "plt.clf()\n",
    "indices = np.arange(0,num)\n",
    "_colors = ['b']*5\n",
    "colors = ['y']*3\n",
    "colors.extend(_colors)\n",
    "fig, ax = plt.subplots(figsize = (12,7))\n",
    "series1 = ax.bar(indices, us_mean[0]-0.5, 0.75, color=colors, yerr=us_std[0], zorder=-1, capsize=2.5)\n",
    "ax.set_title('Cluster 1 Membership')\n",
    "ax.set_ylabel('Probability of Cluster')\n",
    "ax.set_xticks(indices)\n",
    "ax.axhline(lw=0.5, c=(0,0,0,0.6))\n",
    "ax.set_xticklabels(roi_name)\n",
    "ax.set_xlabel('ROI')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce bootstrap CIs for later plotting\n",
    "\n",
    "iters = 3000\n",
    "boot_means = []\n",
    "for i in np.arange(iters):\n",
    "    inds = np.random.RandomState(i).choice(us.shape[2],us.shape[2])\n",
    "    boot = us[...,inds]\n",
    "    boot_mean = np.mean(boot[0], axis=1) - 0.5\n",
    "    boot_means.append(boot_mean)\n",
    "U = np.mean(boot_means, axis=0)\n",
    "lb = np.percentile(boot_means, 2.5, axis=0)\n",
    "ub = np.percentile(boot_means, 97.5, axis=0)\n",
    "\n",
    "print(np.around(np.vstack((U,lb,ub)),3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a dataframe with the clustering strength\n",
    "\n",
    "_all_coefs = []\n",
    "for subj in range(us.shape[2]):\n",
    "    subject = _sub_list[subj]\n",
    "    cluster1 = np.around(np.mean((us[0,:3,subj]-0.5)),4)\n",
    "    cluster2 = np.around(np.mean((us[0,4:,subj]-0.5)),4)\n",
    "    clusters = np.around(np.absolute(cluster1) + np.absolute(cluster2) / 2,4)\n",
    "    parietal = np.around(us[0,3,subj]-0.5,4)\n",
    "    coefs = np.array((subject,cluster1, parietal, cluster2, clusters))\n",
    "    _all_coefs = coefs if len(_all_coefs) == 0 else np.vstack((_all_coefs,coefs))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_coefs = pd.DataFrame(_all_coefs, columns = ['subj', 'evc_clust', 'parietal', 'sm_clust', 'all_clust'])\n",
    "all_coefs.to_csv(str(main_dir)+'csv/drawing_clustering_strength.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creater boxplot for strength of cluster 1, cluster 2, and affiliation of parietal\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "boxer = ax.boxplot([np.array(all_coefs['evc_clust']), \n",
    "                    np.array(all_coefs['sm_clust']), \n",
    "                    np.array(all_coefs['parietal'])], \n",
    "                    positions=[0,1,2],\n",
    "                    patch_artist=True)\n",
    "colors = ['y','b','g']\n",
    "\n",
    "for patch, color in zip(boxer['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "ax.axhline(lw=0.5, color='black')\n",
    "ax.set_xticklabels(['cluster1', 'cluster2', 'parietal'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare first and second half clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "half1 = pd.read_csv(str(main_dir)+'csv/drawing_clustering_strength_half1.csv')\n",
    "half2 = pd.read_csv(str(main_dir)+'csv/drawing_clustering_strength_half2.csv')\n",
    "all_coefs = pd.read_csv(str(main_dir)+'csv/drawing_clustering_strength.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "change_with_time = pd.DataFrame(columns = ['subj', 'evc_clust', 'parietal', 'sm_clust', 'all_clust'])\n",
    "\n",
    "change_with_time['subj'] = half1['subj']\n",
    "for col in ['evc_clust', 'sm_clust', 'all_clust']:\n",
    "    change_with_time[col] = np.absolute(half2[col]) - np.absolute(half1[col]) \n",
    "change_with_time['parietal'] = half2['parietal'] - half1['parietal']\n",
    "\n",
    "change_with_time.to_csv(str(main_dir)+'csv/drawing_clustering_strength_change.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does the clustering strength change over time?\n",
    "#### Does the parietal lobe change 'allegiance' over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(10,4))\n",
    "boxer = axes[0].boxplot([np.array(change_with_time['evc_clust']), \n",
    "                    np.array(change_with_time['sm_clust']), \n",
    "                    np.array(change_with_time['all_clust'])], \n",
    "                    positions=[0,1,2],\n",
    "                    patch_artist=True)\n",
    "boxer2 = axes[1].boxplot(np.array(change_with_time['parietal']),  \n",
    "                    positions=[0],\n",
    "                    patch_artist=True)\n",
    "colors = ['y','b','g']\n",
    "        \n",
    "\n",
    "for patch, color in zip(boxer['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "boxer2['boxes'][0].set_color('orange') \n",
    "axes[0].axhline(lw=0.5, color='black')\n",
    "axes[1].axhline(lw=0.5, color='black')\n",
    "axes[0].set_xticklabels(['cluster1', 'cluster2', 'all_clust'])\n",
    "axes[1].set_xticklabels(['parietal'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute correlations with clustering strength change and pre/post differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepost = pd.read_csv(os.path.join(main_dir,'csv/neural_changes_by_surfroi_and_subject.csv'))\n",
    "roi_list = ['V1', 'V2', 'LOC', 'IT', 'fusiform', 'parahippo', 'PRC', 'ento','hipp', 'mOFC']\n",
    "roi_names = ['V1', 'V2', 'LOC', 'IT', 'Fus', 'PHC', 'PRC', 'EC','HC', 'mOFC']\n",
    "\n",
    "array = change_with_time\n",
    "\n",
    "corrslist = []\n",
    "for this_roi in roi_list:\n",
    "    recog = prepost['UnanchoredTrainedDiff_{}'.format(this_roi)].values-prepost['UnanchoredControlDiff_{}'.format(this_roi)].values\n",
    "    allstack = np.vstack((recog, array['evc_clust'], array['parietal'], array['sm_clust'], array['all_clust']))\n",
    "    int_corr = np.corrcoef(allstack)[1:,0]\n",
    "    corrslist = int_corr if len(corrslist) == 0 else np.vstack((corrslist, int_corr))\n",
    "fig, ax = plt.subplots(figsize=(8,4))\n",
    "im = ax.matshow(np.transpose(corrslist))\n",
    "ax.set_yticks(np.arange(4))\n",
    "ax.set_yticklabels(['EVC', 'Par', 'Prod', 'All'], fontsize=12)\n",
    "ax.set_xticks(np.arange(10))\n",
    "ax.set_xticklabels(roi_names, fontsize=12)\n",
    "ax.set_xlabel('differentiation', fontsize=16)\n",
    "ax.set_ylabel('cluster change', fontsize=16)\n",
    "ax.xaxis.set_label_position('top')\n",
    "ax.xaxis.tick_top()\n",
    "plt.colorbar(im)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working cell for agglomerative hierarchical clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range((all_corrs.shape[2])):\n",
    "    all_mean_clust = all_corrs[:,:,i]\n",
    "    all_mean_clust[np.isnan(all_mean_clust)]=1\n",
    "    clusters = AgglomerativeClustering(n_clusters=3, linkage='average')\n",
    "    fitted = clusters.fit(all_mean_clust)\n",
    "    print(fitted.labels_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
