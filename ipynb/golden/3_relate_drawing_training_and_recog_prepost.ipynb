{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn import linear_model, datasets, neighbors\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import svm\n",
    "\n",
    "%matplotlib inline\n",
    "from scipy.misc import imread, imresize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "colors = sns.color_palette(\"cubehelix\", 5)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm, linregress\n",
    "import sklearn\n",
    "# from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define project paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## relative root paths\n",
    "curr_dir = os.getcwd()\n",
    "proj_dir = os.path.abspath(os.path.join(curr_dir,'..','..')) ## use relative paths\n",
    "data_dir = os.path.abspath(os.path.join(curr_dir,'..','..','data')) ## use relative paths 'D:\\\\data'\n",
    "results_dir = os.path.join(proj_dir, 'csv')\n",
    "nb_name = '3_relate_drawing_training_and_recog_prepost'\n",
    "\n",
    "## add helpers to python path\n",
    "import sys\n",
    "if os.path.join(proj_dir, 'python') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir, 'python'))\n",
    "\n",
    "## module definitions\n",
    "import analysis_helpers as h\n",
    "reload(h)\n",
    "h.data_dir = data_dir\n",
    "h.path_to_recog = os.path.join(data_dir, 'features/recog')\n",
    "h.path_to_draw = os.path.join(data_dir, 'features/drawing')\n",
    "h.roi_list_draw = np.array(['V1Draw', 'V2Draw', 'LOCDraw', 'InsulaDraw', 'postCentralDraw',\n",
    "                            'preCentralDraw', 'ParietalDraw', 'FrontalDraw', 'smgDraw'])\n",
    "h.roi_list_recog = np.array(['V1', 'V2', 'LOC', 'fusiform','parahippo','IT','ento','PRC','hipp','mOFC'])\n",
    "roi_list_recog = h.roi_list_recog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### relate individual differences in overall target selectivity (log odds of target vs. foil) to prepost differentiation\n",
    "\n",
    "This plots the raw correlations between classifer evidence for target - foil, and prepost differentiation between trained objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set \n",
    "version = '4way'\n",
    "tag = 'log'\n",
    "d = pd.read_csv(os.path.join(proj_dir,'csv/difference_{}probs_{}.csv'.format(tag,version)))\n",
    "prepost = pd.read_csv(os.path.join(proj_dir,'csv/neural_changes_by_surfroi_and_subject_longform.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROI: V1  r = 0.37474  p = 0.03779 *\n",
      "ROI: V2  r = 0.46674  p = 0.00812 *\n",
      "ROI: LOC  r = -0.01184  p = 0.94961 \n",
      "ROI: IT  r = -0.10254  p = 0.58305 \n",
      "ROI: fusiform  r = -0.39503  p = 0.02785 *\n",
      "ROI: parahippo  r = 0.12824  p = 0.49174 \n",
      "ROI: PRC  r = -0.17196  p = 0.35495 \n",
      "ROI: ento  r = 0.08294  p = 0.65736 \n",
      "ROI: hipp  r = 0.06561  p = 0.72584 \n"
     ]
    }
   ],
   "source": [
    "## make dataframe to relate drawing contrast to recognition differentiation\n",
    "roi_list = ['V1', 'V2', 'LOC', 'IT', 'fusiform', 'parahippo', 'PRC', 'ento','hipp']\n",
    "roi_labels = list(prepost.roi.unique())*2\n",
    "roi_dict = dict(zip(roi_list,prepost.roi.unique()))\n",
    "\n",
    "draws, recogs = [], []\n",
    "for this_roi in roi_list:\n",
    "    draw = d[d['roi']==this_roi]['target-foil'].values\n",
    "    recog = (prepost[(prepost['condition']=='difference') & (prepost['roi']==roi_dict[this_roi])]['prepost_diff']).values\n",
    "\n",
    "    draws = np.array(draw) if len(draws)==0 else np.vstack((draws, np.array(draw)))\n",
    "    recogs = np.array(recog) if len(recogs)==0 else np.vstack((recogs, np.array(recog)))\n",
    "\n",
    "    z = pd.DataFrame([draw,recog])\n",
    "    z = z.transpose()\n",
    "    z.columns=['draw','recog']\n",
    "\n",
    "    ## plot \n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    sns.set_context('poster')\n",
    "    sns.regplot(x=\"draw\",\n",
    "                y =\"recog\",\n",
    "                data=z)\n",
    "    r,p = stats.pearsonr(draw,recog)\n",
    "    plt.title('ROI: {}  r={}  p={}'.format(this_roi,np.round(r,5),np.round(p,5)))\n",
    "    if np.round(p,5)<0.05:\n",
    "        accent = '*'\n",
    "    else:\n",
    "        accent = ''\n",
    "    print('ROI: {}  r = {}  p = {} {}'.format(this_roi,np.round(r,5),np.round(p,5),accent))\n",
    "    plt.xlabel('drawing: target vs. foil contrast') \n",
    "    plt.ylabel('recog: post-pre differentiation')\n",
    "    if not os.path.exists(os.path.join(proj_dir,'plots/{}/'.format(nb_name))):\n",
    "        os.makedirs(os.path.join(proj_dir,'plots/{}/'.format(nb_name)))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(proj_dir,'plots/{}/draw_recog_scatter_{}.pdf'.format(nb_name,this_roi)))\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plots correlations across phase and roi.\n",
    "\n",
    "For example, does foil inhibition in one roi predict differentiation in another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do you want to (roughly) exclude non significant correlations in plot?\n",
    "exclude_ns = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "altogether = np.vstack((draws,recogs))\n",
    "corrs = np.corrcoef(altogether)\n",
    "derp = (corrs > -0.36) & (corrs < 0.36)\n",
    "corrs2 = np.copy(corrs)\n",
    "if exclude_ns:\n",
    "    np.place(corrs2, derp, np.nan)\n",
    "    fig, ax = plt.subplots(figsize=(15,15))\n",
    "im = ax.matshow(corrs2)\n",
    "ax.set_xticks(np.arange(len(roi_labels)))\n",
    "ax.set_xticklabels(roi_labels, fontsize=8)\n",
    "ax.set_yticks(np.arange(len(roi_labels)))\n",
    "ax.set_yticklabels(roi_labels, fontsize=8)\n",
    "ax.set_ylabel('pre-post differentiation                        drawing suppression')\n",
    "ax.set_xlabel('drawing suppression                        pre-post differentiation')\n",
    "ax.xaxis.set_label_position('top')\n",
    "ax.xaxis.tick_top()\n",
    "plt.colorbar(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some observations:\n",
    "* ROIs where we see positive relationship are: *V1*, *V2*. That is, individuals with GREATER target selectivity during drawing in these regions also show GREATER prepost differentiation.\n",
    "* ROIs where we see negative relationship are: *fusiform*, *mOFC* (maybe PRC?) That is, individuals with LESS target selectivity during drawing in these regions also show GREATER prepost differentiation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When does the relationship between target selectivity and differentiation emerge in these ROIs?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial parameters\n",
    "version = '4way'\n",
    "logged = True\n",
    "tag = 'logged' if logged else 'raw'\n",
    "ALLDM = pd.read_csv(os.path.join(results_dir,'logistic_timeseries_drawing_neural_{}_{}.csv'.format(version,tag)))\n",
    "ALLDM = h.cleanup_df(ALLDM)\n",
    "\n",
    "roi_list = roi_list_recog\n",
    "subs = np.unique(ALLDM.subj.values)\n",
    "ivs = ['trial_num'] # ['run_num','trial_num','time_point']\n",
    "takeDiffDifference = True ## compare trained object differentiation vs. control object differentiation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for anchored in [True, False]:\n",
    "    specs = ('anchored' if anchored else 'unanchored', 'logged' if logged else 'raw')\n",
    "    for this_iv in ivs:\n",
    "        for this_roi in roi_list:\n",
    "            # 1. Generate a subject-by-trial_num matrix where each cell is either `t`, `f`, or `t-f` from the \n",
    "            # output of `analysis_helpers.get_prob_timecourse` for the associated trial and subject (and roi) pairing. \n",
    "            scores = []\n",
    "            for sub in subs:\n",
    "                inds = (ALLDM['roi']==this_roi) & (ALLDM['subj']==sub)\n",
    "                t,f,c = h.get_prob_timecourse(this_iv,ALLDM[inds],version=version)\n",
    "\n",
    "                if len(scores)==0:\n",
    "                    scores = t-f\n",
    "                else:\n",
    "                    scores = np.vstack((scores,t-f))\n",
    "\n",
    "            # 2. Generate a subject_num length vector consisting of each subject's pre-post change measure \n",
    "            # in the same order as they are in the matrix.\n",
    "            if anchored:\n",
    "                recog = prepost['AnchoredTrainedDiff_{}'.format(this_roi)].values\n",
    "                recog -= prepost['AnchoredControlDiff_{}'.format(this_roi)].values if takeDiffDifference else 0\n",
    "            else:\n",
    "                recog = prepost['UnanchoredTrainedDiff_{}'.format(this_roi)].values\n",
    "                recog -= prepost['UnanchoredControlDiff_{}'.format(this_roi)].values if takeDiffDifference else 0 \n",
    "\n",
    "            # 3. The vector defined by taking the `stats.pearsonr()` between each column of the subject-by-trial_num matrix\n",
    "            # and the prepost change vector is the time course we're looking to understand for this ROI.\n",
    "            if this_roi == 'Frontal':\n",
    "                ## SEE HERE: lets decide what to do with classifier output == 0 in rare cases, ignore missing? \n",
    "                ## or add 1e-6 or smallest number in dataset so we can avoid having this catch here\n",
    "                trial_corrs = [pd.DataFrame([scores[:,i], recog]).transpose().corr()[0][1] for i in range(np.shape(scores)[1])]\n",
    "            else:\n",
    "                trial_corrs = [stats.pearsonr(scores[:,i],recog)[0] for i in range(np.shape(scores)[1])]\n",
    "\n",
    "            bootstrap = [h.corrbootstrapCI(scores[:,i], recog, 1000) for i in range(np.shape(scores)[1])]\n",
    "            lower_bound, upper_bound = [b[1] for b in bootstrap], [b[2] for b in bootstrap]                 \n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=(8,4))\n",
    "            ax.plot(trial_corrs, 'ro', label='data')\n",
    "            plt.axhline(y=0.0,linestyle='dashed')\n",
    "            plt.ylim((-1,1))\n",
    "            plt.ylabel('Correlation (t-c / prepost)')\n",
    "            plt.xlabel(this_iv)\n",
    "            plt.title('ROI: {}'.format(this_roi))\n",
    "            plt.fill_between(np.arange(len(trial_corrs)), lower_bound, upper_bound, alpha=.2)\n",
    "        \n",
    "            if not os.path.exists(os.path.join(proj_dir,'plots/{}/'.format(nb_name))):\n",
    "                os.makedirs(os.path.join(proj_dir,'plots/{}/'.format(nb_name)))\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(proj_dir,'plots/{}/trial_corrs_{}_{}_{}.pdf'.format(nb_name, this_roi, *specs)))\n",
    "            plt.close(fig)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create summary barplot of either mean correlation across subjects, or mean slope.\n",
    "\n",
    "Choose any number of possible plots\n",
    "\n",
    "NOTE: the full set of plots for 'mean' will create 32 plots and take ages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data and set some initial parameters\n",
    "\n",
    "ALLDM = pd.read_csv(os.path.join(results_dir,'logistic_timeseries_drawing_neural_{}_{}.csv'.format(version,'logged' if logged else 'raw')))\n",
    "prepost = pd.read_csv(os.path.join(str(results_dir),'neural_changes_by_surfroi_and_subject.csv'))\n",
    "\n",
    "\n",
    "takeDiffDifference = True\n",
    "\n",
    "# Choose what measure to plot\n",
    "plotting = 'mean' # ['mean', 'slope']\n",
    "\n",
    "# choose which unit of time to iterate over\n",
    "ivlist = ['run_num'] # ['run_num', 'trial_num', 'time_point']\n",
    "\n",
    "# Choose whether to log or not\n",
    "loglist = [True] # [True, False]\n",
    "\n",
    "# Choose whether anchored or unanchored RSA\n",
    "anchorlist = [False] # [True, False]\n",
    "\n",
    "# Choose the critical measure for classifier output\n",
    "measurelist = ['t-f'] # ['t','f','t-f','txf']\n",
    "\n",
    "# ROI list\n",
    "roi_list = np.array(['V1','V2','LOC','IT','fusiform','parahippo', 'PRC', 'ento','hipp','mOFC'])\n",
    "\n",
    "\n",
    "units_dict = {'run_num': 4, 'trial_num': 20, 'time_point': 23}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through the plots, based on parameters above\n",
    "\n",
    "for this_iv in ivlist:\n",
    "    units = units_dict[this_iv]\n",
    "    for logged in loglist:\n",
    "        for anchored in anchorlist:\n",
    "            for clfmeasure in measurelist:\n",
    "                print('logged: {}; anchored: {}; clf: {}; iv: {}'.format(logged, anchored, clfmeasure, this_iv))\n",
    "                specs = ('anchored' if anchored else 'unanchored', 'logged' if logged else 'raw')\n",
    "                subs = np.unique(ALLDM.subj.values)\n",
    "\n",
    "                columns = []\n",
    "                for this_roi in roi_list:\n",
    "                    _scores = np.array([h.get_prob_timecourse(this_iv,ALLDM[(ALLDM['roi']==this_roi) & (ALLDM['subj']==sub)]) for sub in subs])\n",
    "                    scores = [h.compute_clf_measure(_scores[i,0,:], _scores[i,1,:], clfmeasure) for i in range(_scores.shape[0])]\n",
    "\n",
    "                    objs = [str(np.unique(ALLDM[(ALLDM['subj']==sub)].label.values)) for sub in subs]\n",
    "                    if anchored:\n",
    "                        recog = prepost['AnchoredTrainedDiff_{}'.format(this_roi)].values\n",
    "                        recog -= prepost['AnchoredControlDiff_{}'.format(this_roi)].values if takeDiffDifference else 0\n",
    "                        print(recog)\n",
    "                    else:\n",
    "                        recog = prepost['UnanchoredTrainedDiff_{}'.format(this_roi)].values\n",
    "                        recog -= prepost['UnanchoredControlDiff_{}'.format(this_roi)].values if takeDiffDifference else 0\n",
    "\n",
    "                    columns.append([{'clf':scores[i], 'diff':recog[i], 'objs':objs[i]} for i in range(len(scores))])\n",
    "                bardf = pd.DataFrame(columns).transpose()\n",
    "                bardf.columns = roi_list\n",
    "\n",
    "                if plotting == 'mean':\n",
    "\n",
    "                    # derive from bardf the df we want to plot and the error bars we want\n",
    "                    meandf = pd.DataFrame([h.scoreVSdiff(np.array(bardf)[:,i], roi_list[i]) for i in range(len(roi_list))]).transpose()\n",
    "                    meandf.columns = roi_list\n",
    "                    error = [h.custom_bootstrapCI(np.array(bardf)[:,i], h.scoreVSdiff, 1000, roi_list[i])[1:3] for i in range(len(roi_list))]\n",
    "                    title = 'Subjectwise Relationship B/t Mean({}) & PrePost Diff'.format(clfmeasure)\n",
    "                    ylab = 'Average Correlation'\n",
    "                    outfig = 'mean_{}_{}_{}_{}.png'.format(this_iv, clfmeasure, *specs)\n",
    "\n",
    "                else:\n",
    "\n",
    "                    # derive from bardf the df we want to plot and the error bars we want\n",
    "                    meandf = pd.DataFrame([h.slope_scoreVSdiff(np.array(bardf)[:,i], roi_list[i], units) for i in range(len(roi_list))]).transpose()\n",
    "                    meandf.columns = roi_list\n",
    "                    error = [h.custom_bootstrapCI(np.array(bardf)[:,i], h.slope_scoreVSdiff, 1000, roi_list[i], units)[1:3] for i in range(len(roi_list))]\n",
    "                    title = 'Slope over Timepoints of Subjectwise Relationship B/t {} & Prepost Diff'.format(clfmeasure)\n",
    "                    ylab = 'Average Slope'\n",
    "                    outfig = 'slope_{}_{}_{}_{}.png'.format(this_iv, clfmeasure, *specs)\n",
    "\n",
    "                fig = plt.figure(figsize=(17,6))\n",
    "                sns.barplot(data=meandf,palette='husl',ci=None)\n",
    "                plt.xlabel('ROIs')\n",
    "                plt.title(title) \n",
    "                plt.ylabel(ylab) \n",
    "                for i in range(len(roi_list)):\n",
    "                    plt.vlines(i, error[i][0], error[i][1])\n",
    "                plt.tight_layout()\n",
    "                if not os.path.exists(os.path.join(proj_dir,'plots/{}/'.format(nb_name))):\n",
    "                    os.makedirs(os.path.join(proj_dir,'plots/{}/'.format(nb_name)))\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(proj_dir,'plots/{}/'.format(nb_name), outfig))\n",
    "                plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
