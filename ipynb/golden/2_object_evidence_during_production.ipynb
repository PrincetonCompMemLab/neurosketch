{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from sklearn import linear_model, datasets, neighbors\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import svm\n",
    "\n",
    "%matplotlib inline\n",
    "from scipy.misc import imread, imresize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "colors = sns.color_palette(\"cubehelix\", 5)\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "import sklearn\n",
    "\n",
    "# from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define paths to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dir = os.getcwd()\n",
    "os.path.abspath(os.path.join(curr_dir,'..','..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## root paths\n",
    "curr_dir = os.getcwd()\n",
    "proj_dir = os.path.abspath(os.path.join(curr_dir,'..','..')) ## use relative paths\n",
    "data_dir = os.path.abspath(os.path.join(curr_dir,'..','..','data')) ## use relative paths 'D:\\\\data'\n",
    "results_dir = os.path.join(proj_dir, 'csv')\n",
    "nb_name = '2_object_evidence_during_production'\n",
    "\n",
    "## add helpers to python path\n",
    "import sys\n",
    "if os.path.join(proj_dir, 'python') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir, 'python'))\n",
    "\n",
    "## module definitions\n",
    "import object_evidence_analysis_helpers as utils\n",
    "reload(utils)\n",
    "utils.data_dir = data_dir\n",
    "utils.path_to_recog = os.path.join(data_dir, 'features/recog')\n",
    "utils.path_to_draw = os.path.join(data_dir, 'features/drawing')\n",
    "utils.roi_list_draw = np.array(['V1Draw', 'V2Draw', 'LOCDraw', 'InsulaDraw', 'postCentralDraw',\n",
    "                            'preCentralDraw', 'ParietalDraw', 'FrontalDraw', 'smgDraw'])\n",
    "utils.roi_list_recog = ['V1','V2','LOC','IT','fusiform','parahippo','PRC','ento','hipp']\n",
    "utils.roi_list_recog_formatted = np.array(['V1', 'V2', 'LOC', 'FUS','PHC','IT','ENT','PRC','HC']) \n",
    "roi_list_recog = utils.roi_list_recog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get file list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get raw file list for recognition runs\n",
    "path_to_recog = utils.path_to_recog\n",
    "\n",
    "RECOG_METAS = sorted([i for i in os.listdir(path_to_recog) if (i.split('.')[-1]=='csv') & (i.split('_')[2][-4:] != 'Draw')])\n",
    "RECOG_FEATS = sorted([i for i in os.listdir(path_to_recog) if (i.split('.')[-1]=='npy') & (i.split('_')[1][-4:] != 'Draw')])\n",
    "RECOG_SUBS = np.array([i.split('_')[0] for i in RECOG_FEATS])\n",
    "\n",
    "recog_sub_list = np.unique(RECOG_SUBS)\n",
    "\n",
    "def preprocess_recog(RECOG_METAS, RECOG_FEATS):\n",
    "    M = [i for i in RECOG_METAS if len(i.split('.')[0].split('_'))==4]\n",
    "    F = [i for i in RECOG_FEATS if len(i.split('.')[0].split('_'))==4]\n",
    "    return M,F\n",
    "\n",
    "RECOG_METAS, RECOG_FEATS = preprocess_recog(RECOG_METAS, RECOG_FEATS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get raw file list for drawing runs\n",
    "path_to_draw = utils.path_to_draw\n",
    "\n",
    "DRAW_METAS = sorted([i for i in os.listdir(path_to_draw) if (i.split('.')[-1]=='csv') & (i.split('_')[2][-4:] == 'Draw')])\n",
    "DRAW_FEATS = sorted([i for i in os.listdir(path_to_draw) if (i.split('.')[-1]=='npy') & (i.split('_')[1][-4:] == 'Draw')])\n",
    "DRAW_SUBS = np.array([i.split('_')[0] for i in DRAW_FEATS])\n",
    "draw_sub_list = np.unique(DRAW_SUBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get subject ID's that have complete datasets from all phases of experiment\n",
    "sub_list = np.intersect1d(recog_sub_list,draw_sub_list)\n",
    "#print('Number of subs: {}'.format(len(sub_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter file list so only contains the sessions that have full datasets\n",
    "def extract_good_sessions(DRAW_METAS,DRAW_FEATS,RECOG_METAS,RECOG_FEATS):\n",
    "    _DRAW_METAS = [i for i in DRAW_METAS if i.split('_')[1] in sub_list]\n",
    "    _DRAW_FEATS = [i for i in DRAW_FEATS if i.split('_')[0] in sub_list]\n",
    "    _RECOG_METAS = [i for i in RECOG_METAS if i.split('_')[1] in sub_list]\n",
    "    _RECOG_FEATS = [i for i in RECOG_FEATS if i.split('_')[0] in sub_list]\n",
    "    return _DRAW_METAS, _DRAW_FEATS, _RECOG_METAS, _RECOG_FEATS\n",
    "\n",
    "DRAW_METAS,DRAW_FEATS,RECOG_METAS,RECOG_FEATS =  \\\n",
    "extract_good_sessions(DRAW_METAS,DRAW_FEATS,RECOG_METAS,RECOG_FEATS)\n",
    "\n",
    "RECOG_SUBS = np.array([i.split('_')[0]+'_neurosketch' for i in RECOG_FEATS])\n",
    "RECOG_ROIS = np.array([i.split('_')[1] for i in RECOG_FEATS])\n",
    "\n",
    "DRAW_SUBS = np.array([i.split('_')[0]+'_neurosketch' for i in DRAW_FEATS])\n",
    "DRAW_ROIS = np.array([i.split('_')[1] for i in DRAW_FEATS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'We have data from {} subjects.'.format(len(sub_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRODUCTION: How well do we do at classifying the target during production runs when we train on initial recognition patterns only?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "version = '4way'\n",
    "logged = True\n",
    "\n",
    "really_run = 0\n",
    "if really_run:\n",
    "\n",
    "    ALLDM, Acc = utils.make_drawing_predictions(sub_list,roi_list_recog,\n",
    "                                            version=version,logged=logged)\n",
    "    ## save out ALLDM & Acc\n",
    "    Acc = np.array(Acc)\n",
    "    np.save(os.path.join(results_dir,'object_classifier_accuracy_production.npy'),Acc)\n",
    "    ALLDM.to_csv(os.path.join(results_dir,'object_classifier_logprobs_production.csv'),index=False)\n",
    "    \n",
    "else:\n",
    "    ## load in existing ALLDM & Acc \n",
    "    Acc = np.load(os.path.join(results_dir,'object_classifier_accuracy_production.npy'))\n",
    "    ALLDM = pd.read_csv(os.path.join(results_dir,'object_classifier_logprobs_production.csv'))\n",
    "    \n",
    "print 'Done!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### basic summary plot of classifier accuracy between ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_draw_decoding():\n",
    "\n",
    "    ## plot test accuracy on drawing runs; trained on recognition runs\n",
    "    from matplotlib import rc\n",
    "    hfont = {'fontname':'Helvetica'}    \n",
    "    Acc = np.load(os.path.join(results_dir,'object_classifier_accuracy_production.npy'))\n",
    "\n",
    "    Acc = np.array(Acc)\n",
    "    x = pd.DataFrame(Acc.transpose())\n",
    "    x.columns = roi_list_recog    \n",
    "    sns.set_context('talk')\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    fig = sns.barplot(data=x,palette='husl',ci=95,zorder=1)\n",
    "    x2 = x\n",
    "    plt.ylim(0,0.5)\n",
    "\n",
    "    ## melt into longform dataframe to be able to make stripplot for draw decoding accuracy \n",
    "    ## for each subject\n",
    "    x = x.assign(sub=sub_list)\n",
    "    xl = pd.melt(x, \n",
    "                id_vars=['sub'], \n",
    "                var_name='roi',\n",
    "                value_vars=roi_list_recog, \n",
    "                value_name='draw_acc')        \n",
    "    fig2 = sns.swarmplot(data=xl,x=\"roi\", \n",
    "                         y=\"draw_acc\", \n",
    "                         #color=(0.25,0.25,0.25),\n",
    "                         palette='husl',\n",
    "                         dodge=True,\n",
    "    #                      jitter=0.12,\n",
    "                         alpha=0.6,    \n",
    "                         size=6,\n",
    "                         edgecolor=(0.1,0.1,0.1),\n",
    "                         linewidth=1,\n",
    "                         zorder=2)    \n",
    "\n",
    "    fig3 = sns.barplot(data=x2,palette='husl',ci=95,alpha=0.1,zorder=3)\n",
    "    plt.xlabel('')\n",
    "\n",
    "    chance_dict = {'4way':0.25,'3way':0.33,'2way':0.5}\n",
    "    plt.axhline(chance_dict[version],linestyle=':',color='k')\n",
    "    plt.ylabel('object decoding accuracy',fontsize=20, **hfont)\n",
    "    plt.title('drawing', **hfont)\n",
    "    fig.set_xticklabels(utils.roi_list_recog_formatted,fontsize=16, **hfont)\n",
    "    out_path = os.path.join(proj_dir,'plots/{}/draw_decoding_accuracy.pdf'.format(nb_name))\n",
    "    plt.savefig(out_path,format='pdf')        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_draw_decoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make summary timecourse plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "# versions = ['2way','3way','4way', '4wayIndependent']\n",
    "versions = ['4way']\n",
    "tags = ['logged']\n",
    "# tags = ['logged', 'raw']\n",
    "iv_list = ['time_point','trial_num','run_num']\n",
    "\n",
    "reallyRun = 1\n",
    "if reallyRun:\n",
    "    for version in versions:\n",
    "        for tag in tags:\n",
    "            ALLDM = pd.read_csv(os.path.join(results_dir, 'object_classifier_logprobs_production.csv'))\n",
    "            try:\n",
    "                utils.plot_summary_timecourse(ALLDM,\n",
    "                                        this_iv='trial_num',\n",
    "                                        roi_list=roi_list_recog,\n",
    "                                        render_cond=1,\n",
    "                                        version = version,\n",
    "                                        proj_dir=proj_dir)\n",
    "            except KeyError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get subject-level index of contrast between objects during drawing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(utils)\n",
    "lookup = dict(zip(['trial_num','run_num','time_point'],['repetition','run','TR']))\n",
    "version = '4way'\n",
    "tag = 'logged'\n",
    "this_iv = 'time_point' ## other options 'run_num','trial_num','time_point'\n",
    "\n",
    "ALLDM = pd.read_csv(os.path.join(results_dir,'object_classifier_logprobs_production.csv'))\n",
    "d = utils.get_log_odds(ALLDM,\n",
    "               this_iv = this_iv,\n",
    "               roi_list = roi_list_recog,\n",
    "               phase = 'production',\n",
    "               version=version,\n",
    "               logged=True,\n",
    "               proj_dir=proj_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = ['target-foil','target-control','foil-control']\n",
    "for condition in conditions:\n",
    "    print('------- condition: {} -------'.format(condition))\n",
    "    for this_roi in roi_list_recog:\n",
    "        data = d[d['roi']==this_roi][condition].values\n",
    "        U,lb,ub,p1,p2 = utils.bootstrapCI(data,3000)\n",
    "        print('ROI = {} | mean = {}  95% CI: [{} {}] p(x<0)={} p(x>0)={}'.format(\n",
    "            this_roi,np.round(U,5),np.round(lb,3),np.round(ub,5),np.round(p1,5),np.round(p2,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
