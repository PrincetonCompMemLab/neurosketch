{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn import linear_model, datasets, neighbors\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import svm\n",
    "\n",
    "%matplotlib inline\n",
    "from scipy.misc import imread, imresize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "sns.set_context('poster')\n",
    "colors = sns.color_palette(\"cubehelix\", 5)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm, linregress\n",
    "import sklearn\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define project paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add helpers to python path\n",
    "import sys\n",
    "if '/Users/jeffwammes/Working/neurosketch/python' not in sys.path:\n",
    "    sys.path.append('/Users/jeffwammes/Working/neurosketch/python')\n",
    "\n",
    "## root paths    \n",
    "curr_dir = os.getcwd()\n",
    "data_dir = '/Volumes/ntb/projects/sketchloop02/data/'\n",
    "proj_dir = '../..'\n",
    "results_dir = '../../csv/'\n",
    "nb_name = '3_relate_drawing_training_and_recog_prepost'\n",
    "\n",
    "## module definitions\n",
    "import analysis_helpers as h\n",
    "reload(h)\n",
    "\n",
    "h.data_dir = data_dir\n",
    "h.path_to_recog = data_dir + 'features/recog'\n",
    "h.path_to_draw = data_dir + 'features/drawing'\n",
    "h.roi_list_draw = np.array(['V1Draw', 'V2Draw', 'LOCDraw', 'InsulaDraw', 'postCentralDraw',\n",
    "                            'preCentralDraw', 'ParietalDraw', 'FrontalDraw', 'smgDraw'])\n",
    "h.roi_list_recog = np.array(['V1', 'V2', 'LOC', 'fusiform','parahippo','IT','ento','PRC','hipp','mOFC'])\n",
    "roi_list_recog = h.roi_list_recog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### relate individual differences in overall target selectivity (log odds of target vs. foil) to prepost differentiation\n",
    "\n",
    "This plots the raw correlations between classifer evidence for target - foil, and prepost differentiation between trained objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set \n",
    "version = '4way'\n",
    "tag = 'log'\n",
    "d = pd.read_csv(os.path.join(proj_dir,'csv/difference_{}probs_{}.csv'.format(tag,version)))\n",
    "prepost = pd.read_csv(os.path.join(proj_dir,'csv/neural_changes_by_surfroi_and_subject.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROI: V1  r=0.37475  p=0.03779 *\n",
      "ROI: V2  r=0.46675  p=0.00812 *\n",
      "ROI: LOC  r=-0.01186  p=0.94953 \n",
      "ROI: IT  r=-0.10254  p=0.58306 \n",
      "ROI: fusiform  r=-0.39503  p=0.02785 *\n",
      "ROI: parahippo  r=0.12824  p=0.49175 \n",
      "ROI: PRC  r=-0.32176  p=0.07754 \n",
      "ROI: ento  r=0.08294  p=0.65734 \n",
      "ROI: hipp  r=0.06561  p=0.72584 \n",
      "ROI: mOFC  r=-0.37663  p=0.03676 *\n"
     ]
    }
   ],
   "source": [
    "## make dataframe to relate drawing contrast to recognition differentiation\n",
    "roi_list = ['V1', 'V2', 'LOC', 'IT', 'fusiform', 'parahippo', 'PRC', 'ento','hipp', 'mOFC']\n",
    "\n",
    "for this_roi in roi_list:\n",
    "    draw = d[d['roi']==this_roi]['target-foil'].values\n",
    "    recog = prepost['UnanchoredTrainedDiff_{}'.format(this_roi)].values-prepost['UnanchoredControlDiff_{}'.format(this_roi)].values\n",
    "\n",
    "    z = pd.DataFrame([draw,recog])\n",
    "    z = z.transpose()\n",
    "    z.columns=['draw','recog']\n",
    "\n",
    "    ## plot \n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "    sns.set_context('poster')\n",
    "    sns.regplot(x=\"draw\",\n",
    "                y =\"recog\",\n",
    "                data=z)\n",
    "    r,p = stats.pearsonr(draw,recog)\n",
    "    plt.title('ROI: {}  r={}  p={}'.format(this_roi,np.round(r,5),np.round(p,5)))\n",
    "    if np.round(p,5)<0.05:\n",
    "        accent = '*'\n",
    "    else:\n",
    "        accent = ''\n",
    "    print('ROI: {}  r={}  p={} {}'.format(this_roi,np.round(r,5),np.round(p,5),accent))\n",
    "    plt.xlabel('drawing: target vs. foil contrast') \n",
    "    plt.ylabel('recog: post-pre differentiation')\n",
    "    if not os.path.exists(os.path.join(proj_dir,'plots/{}/drawrecog'.format(nb_name))):\n",
    "        os.makedirs(os.path.join(proj_dir,'plots/{}/drawrecog'.format(nb_name)))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(proj_dir,'plots/{}/drawrecog/draw_recog_scatter_{}.pdf'.format(nb_name,this_roi)))\n",
    "    plt.close(fig)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some observations:\n",
    "* ROIs where we see positive relationship are: *V1*, *V2*. That is, individuals with GREATER target selectivity during drawing in these regions also show GREATER prepost differentiation.\n",
    "* ROIs where we see negative relationship are: *fusiform*, *mOFC* (maybe PRC?) That is, individuals with LESS target selectivity during drawing in these regions also show GREATER prepost differentiation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When does the relationship between target selectivity and differentiation emerge in these ROIs?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set initial parameters\n",
    "\n",
    "version = '4way'\n",
    "tag = 'logged'\n",
    "ALLDM = pd.read_csv(os.path.join(results_dir,'logistic_timeseries_drawing_neural_{}_{}.csv'.format(version,tag)))\n",
    "ALLDM = h.cleanup_df(ALLDM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bootstrapCI(x,estimator,nIter, *args):\n",
    "    u = []\n",
    "    for i in np.arange(nIter):\n",
    "        inds = np.random.RandomState(i).choice(len(x),len(x))\n",
    "        boot = x[inds]\n",
    "        u.append(estimator(boot, *args))\n",
    "        \n",
    "    p1 = len([i for i in u if i<0])/len(u) * 2\n",
    "    p2 = len([i for i in u if i>0])/len(u) * 2\n",
    "    p = np.min([p1,p2])\n",
    "    U = np.mean(u)\n",
    "    lb = np.percentile(u,2.5)\n",
    "    ub = np.percentile(u,97.5)    \n",
    "    return U,lb,ub,p\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "version = '4way'\n",
    "logged = True\n",
    "tag = 'logged' if logged else 'raw'\n",
    "roi_list = roi_list_recog\n",
    "subs = np.unique(ALLDM.subj.values)\n",
    "ivs = ['trial_num'] # ['run_num','trial_num','time_point']\n",
    "takeDiffDifference = True ## compare trained object differentiation vs. control object differentiation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffwammes/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:2746: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  **kwargs)\n"
     ]
    }
   ],
   "source": [
    "for anchored in [False]:\n",
    "    specs = ('anchored' if anchored else 'unanchored', 'logged' if logged else 'raw')\n",
    "    for this_iv in ivs:\n",
    "        for this_roi in roi_list:\n",
    "            # 1. Generate a subject-by-trial_num matrix where each cell is either `t`, `f`, or `t-f` from the \n",
    "            # output of `analysis_helpers.get_prob_timecourse` for the associated trial and subject (and roi) pairing. \n",
    "            scores = []\n",
    "            for sub in subs:\n",
    "                inds = (ALLDM['roi']==this_roi) & (ALLDM['subj']==sub)\n",
    "                t,f,c = h.get_prob_timecourse(this_iv,ALLDM[inds],version=version)\n",
    "\n",
    "                if len(scores)==0:\n",
    "                    scores = t-f\n",
    "                else:\n",
    "                    scores = np.vstack((scores,t-f))\n",
    "\n",
    "            # 2. Generate a subject_num length vector consisting of each subject's pre-post change measure \n",
    "            # in the same order as they are in the matrix.\n",
    "            if anchored:\n",
    "                recog = prepost['AnchoredTrainedDiff_{}'.format(this_roi)].values\n",
    "                recog -= prepost['AnchoredControlDiff_{}'.format(this_roi)].values if takeDiffDifference else 0\n",
    "            else:\n",
    "                recog = prepost['UnanchoredTrainedDiff_{}'.format(this_roi)].values\n",
    "                recog -= prepost['UnanchoredControlDiff_{}'.format(this_roi)].values if takeDiffDifference else 0 \n",
    "\n",
    "            # 3. The vector defined by taking the `stats.pearsonr()` between each column of the subject-by-trial_num matrix\n",
    "            # and the prepost change vector is the time course we're looking to understand for this ROI.\n",
    "            if this_roi == 'Frontal':\n",
    "                ## SEE HERE: lets decide what to do with classifier output == 0 in rare cases, ignore missing? \n",
    "                ## or add 1e-6 or smallest number in dataset so we can avoid having this catch here\n",
    "                trial_corrs = [pd.DataFrame([scores[:,i], recog]).transpose().corr()[0][1] for i in range(np.shape(scores)[1])]\n",
    "            else:\n",
    "                trial_corrs = [stats.pearsonr(scores[:,i],recog)[0] for i in range(np.shape(scores)[1])]\n",
    "\n",
    "            bootstrap = [h.corrbootstrapCI(scores[:,i], recog, 1000) for i in range(np.shape(scores)[1])]\n",
    "            lower_bound, upper_bound = [b[1] for b in bootstrap], [b[2] for b in bootstrap]                 \n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=(8,4))\n",
    "            ax.plot(trial_corrs, 'ro', label='data')\n",
    "            plt.axhline(y=0.0,linestyle='dashed')\n",
    "            plt.ylim((-1,1))\n",
    "            plt.ylabel('Correlation (t-c / prepost)')\n",
    "            plt.xlabel(this_iv)\n",
    "            plt.title('ROI: {}'.format(this_roi))\n",
    "            plt.fill_between(np.arange(len(trial_corrs)), lower_bound, upper_bound, alpha=.2)\n",
    "        \n",
    "            if not os.path.exists(os.path.join(proj_dir,'plots/{}/drawrecog'.format(nb_name))):\n",
    "                os.makedirs(os.path.join(proj_dir,'plots/{}/drawrecog'.format(nb_name)))\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(proj_dir,'plots/{}/drawrecog/trial_corrs_{}_{}_{}.pdf'.format(nb_name, this_roi, *specs)))\n",
    "            plt.close(fig)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create summary plot of either mean correlation across subjects, or mean slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logged: True; anchored: False; clf: t-f\n"
     ]
    }
   ],
   "source": [
    "version = '4way'\n",
    "ALLDM = pd.read_csv(results_dir+'logistic_timeseries_drawing_neural_{}_{}.csv'.format(version,'logged' if logged else 'raw'))\n",
    "prepost = pd.read_csv(str(results_dir)+'neural_changes_by_surfroi_and_subject.csv')\n",
    "# clf_dataframe = ALLDM, rec_dataframe = prepost, notebook = nb_name, iv = 'trial_num'\n",
    "# plotting = 'mean', roi_list, logged=[True, False], anchored=[True, False], clfmeasure=['t','f',t-f','txf']\n",
    "\n",
    "# Choose what measure to plot ['mean' or 'slope']:\n",
    "plotting = 'corr'\n",
    "\n",
    "takeDiffDifference = True\n",
    "this_iv = 'trial_num'\n",
    "roi_list = np.array(['V1','V2','LOC','IT','fusiform','parahippo', 'PRC', 'ento','hipp','mOFC'])\n",
    "\n",
    "\n",
    "def compute_clf_measure(target, foil, measure):\n",
    "    if measure == 't-f':\n",
    "        return target-foil\n",
    "    elif measure == 'txf':\n",
    "        return target+foil if logged else target*foil\n",
    "    elif measure == 't':\n",
    "        return target\n",
    "    else:\n",
    "        return foil\n",
    "    \n",
    "def scoreVSdiff(subdata, this_roi):\n",
    "    clfscores = [np.mean(c['clf']) for c in subdata]\n",
    "    diffscores = [sub['diff'] for sub in subdata]\n",
    "    \n",
    "    if this_roi == 'Frontal':\n",
    "        return pd.DataFrame([clfscores, diffscores]).transpose().corr()[0][1]\n",
    "    else:\n",
    "        return stats.pearsonr(clfscores, diffscores)[0]\n",
    "    \n",
    "def slope_scoreVSdiff(subdata, this_roi):\n",
    "    num_ivs = 20\n",
    "    diffscores = [sub['diff'] for sub in subdata]\n",
    "    clfscores = [c['clf'] for c in subdata]\n",
    "    \n",
    "    if this_roi == 'Frontal':\n",
    "        coefficients = [pd.DataFrame([[c[i] for c in clfscores], diffscores]).transpose().corr()[0][1] for i in range(num_ivs)]\n",
    "    else:\n",
    "        coefficients = [stats.pearsonr([c[i] for c in clfscores], diffscores)[0] for i in range(num_ivs)]\n",
    "    return linregress(np.arange(num_ivs),coefficients)[0]\n",
    "\n",
    "for logged in [True]:\n",
    "    for anchored in [False]:\n",
    "        for clfmeasure in ['t-f']:\n",
    "            print('logged: {}; anchored: {}; clf: {}'.format(logged, anchored, clfmeasure))\n",
    "            specs = ('anchored' if anchored else 'unanchored', 'logged' if logged else 'raw')\n",
    "            subs = np.unique(ALLDM.subj.values)\n",
    "            \n",
    "            columns = []\n",
    "            for this_roi in roi_list:\n",
    "                _scores = np.array([h.get_prob_timecourse(this_iv,ALLDM[(ALLDM['roi']==this_roi) & (ALLDM['subj']==sub)]) for sub in subs])\n",
    "                scores = [compute_clf_measure(_scores[i,0,:], _scores[i,1,:], clfmeasure) for i in range(_scores.shape[0])]\n",
    "\n",
    "                objs = [str(np.unique(ALLDM[(ALLDM['subj']==sub)].label.values)) for sub in subs]\n",
    "                if anchored:\n",
    "                    recog = prepost['AnchoredTrainedDiff_{}'.format(this_roi)].values\n",
    "                    recog -= prepost['AnchoredControlDiff_{}'.format(this_roi)].values if takeDiffDifference else 0\n",
    "                    print(recog)\n",
    "                else:\n",
    "                    recog = prepost['UnanchoredTrainedDiff_{}'.format(this_roi)].values\n",
    "                    recog -= prepost['UnanchoredControlDiff_{}'.format(this_roi)].values if takeDiffDifference else 0\n",
    "\n",
    "                columns.append([{'clf':scores[i], 'diff':recog[i], 'objs':objs[i]} for i in range(len(scores))])\n",
    "            bardf = pd.DataFrame(columns).transpose()\n",
    "            bardf.columns = roi_list\n",
    "                       \n",
    "            if plotting == 'mean':\n",
    "\n",
    "                # derive from bardf the df we want to plot and the error bars we want\n",
    "                meandf = pd.DataFrame([scoreVSdiff(np.array(bardf)[:,i], roi_list[i]) for i in range(len(roi_list))]).transpose()\n",
    "                meandf.columns = roi_list\n",
    "                error = [bootstrapCI(np.array(bardf)[:,i], scoreVSdiff, 1000, roi_list[i])[1:3] for i in range(len(roi_list))]\n",
    "                title = 'Subjectwise Relationship B/t Mean({}) & PrePost Diff'.format(clfmeasure)\n",
    "                ylab = 'Average Correlation'\n",
    "                outfig = 'mean_{}_{}_{}.png'.format(clfmeasure, *specs)\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                # derive from bardf the df we want to plot and the error bars we want\n",
    "                meandf = pd.DataFrame([slope_scoreVSdiff(np.array(bardf)[:,i], roi_list[i]) for i in range(len(roi_list))]).transpose()\n",
    "                meandf.columns = roi_list\n",
    "                error = [bootstrapCI(np.array(bardf)[:,i],slope_scoreVSdiff, 1000, roi_list[i])[1:3] for i in range(len(roi_list))]\n",
    "                title = 'Slope over Timepoints of Subjectwise Relationship B/t {} & Prepost Diff'.format(clfmeasure)\n",
    "                ylab = 'Average Slope'\n",
    "                outfig = 'slope_{}_{}_{}.png'.format(clfmeasure, *specs)\n",
    "            \n",
    "            fig = plt.figure(figsize=(17,6))\n",
    "            sns.barplot(data=meandf,palette='husl',ci=None)\n",
    "            plt.xlabel('ROIs')\n",
    "            plt.title(title) \n",
    "            plt.ylabel(ylab) \n",
    "            for i in range(len(roi_list)):\n",
    "                plt.vlines(i, error[i][0], error[i][1])\n",
    "            plt.tight_layout()\n",
    "            if not os.path.exists(os.path.join(proj_dir,'plots/{}/drawrecog'.format(nb_name))):\n",
    "                os.makedirs(os.path.join(proj_dir,'plots/{}/drawrecog'.format(nb_name)))\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(proj_dir,'plots/{}/drawrecog'.format(nb_name), outfig))\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
