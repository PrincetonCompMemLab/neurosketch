{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nilearn import image\n",
    "import nibabel as nib\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_name = '0_feature_matrices_and_metadata'\n",
    "\n",
    "curr_dir2 = os.getcwd()\n",
    "print(curr_dir2)\n",
    "curr_dir = '/Volumes/ntb/projects/sketchloop02/prototype/link'\n",
    "os.path.abspath(os.path.join(curr_dir,'..','..'))\n",
    "\n",
    "## root paths\n",
    "\n",
    "proj_dir = os.path.abspath(os.path.join(curr_dir,'..','..')) ## use relative paths\n",
    "feat_dir = os.path.abspath(os.path.join(proj_dir,'data/features')) ## use relative paths 'D:\\\\data'\n",
    "data_dir = os.path.abspath(os.path.join(proj_dir,'data'))\n",
    "reg_file = os.path.abspath(os.path.join(proj_dir,'subjects/{}_neurosketch/regressor/run_{}/{}.txt'))\n",
    "filt_func = os.path.abspath(os.path.join(proj_dir,'subjects/{}_neurosketch/analysis/firstlevel',\n",
    "                                         'glm4_recognition_run_{}.feat/filtfuncHIRES.nii.gz'))\n",
    "#roi_dir = os.path.abspath(os.path.join(proj_dir,'subjects/{}_neurosketch/analysis/firstlevel', 'surfROI'))\n",
    "roi_dir = '/Volumes/ntb/users/jwammes/sketchloop/subjects/{}_neurosketch/analysis/firstlevel/surfROI'\n",
    "\n",
    "#metadata_path = '/jukebox/ntb/projects/sketchloop02/data/features/metadata_{}_drawing.csv'\n",
    "\n",
    "subjects = ['0110171', '0110172', '0111171', '0112171', '0112172', '0112173',\n",
    "            '0113171', '0115174', '0117171', '0118171', '0118172', '0119171',\n",
    "            '0119172', '0119173', '0119174', '0120171', '0120172', '0120173',\n",
    "            '0123171', '0123173', '0124171', '0125171', '0125172', '1121161',\n",
    "            '1130161', '1202161', '1203161', '1206161', '1206162', '1206163',\n",
    "            '1207162']\n",
    "objects = ['bed', 'bench', 'chair', 'table']\n",
    "copeDict = dict(zip(objects, [1,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add helpers to python path\n",
    "import sys\n",
    "if os.path.join(curr_dir2, '..', '..', 'python') not in sys.path:\n",
    "    sys.path.append(os.path.join(curr_dir2, '..', '..', 'python'))\n",
    "\n",
    "## module definitions\n",
    "import object_evidence_analysis_helpers as utils\n",
    "reload(utils)\n",
    "utils.data_dir = data_dir\n",
    "utils.path_to_connect = os.path.join(data_dir, 'features/connect')\n",
    "#utils.roi_list_connect = roi_list_connect\n",
    "\n",
    "utils.roi_list_recog = ['V1','V2','LOC','IT','fusiform','parahippo','PRC','ento','hipp']\n",
    "utils.roi_list_recog_formatted = np.array(['V1', 'V2', 'LOC', 'FUS','PHC','IT','ENT','PRC','HC']) \n",
    "roi_list_recog = utils.roi_list_recog\n",
    "roi_list_masks = ['V1','V2','LOC_FS','IT_FS','fusiform_FS','parahippo_FS','PRC_FS','ento_FS','hipp_FS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature and metadata extraction from recognition runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject in subjects[:1]:\n",
    "    for phase in ['12', '34', '56'][:1]:\n",
    "        # initialize data columns\n",
    "        subj = [subject] * 160\n",
    "        label = []\n",
    "        run_num = [phase[0]]*80 + [phase[1]]*80\n",
    "        TR_num = []\n",
    "        \n",
    "        for rn, run in enumerate(phase):\n",
    "            # load subject's time series for this run\n",
    "            #timeseries = image.load_img('{}/{}_neurosketch/analysis/firstlevel/preproc_recognition_run_{}.feat/filtered_func_data.nii.gz'.format(subject, run))\n",
    "            timeseries = image.load_img(filt_func.format(subject, run))\n",
    "            # the required reshaping differs depending on which anatomicals are used\n",
    "            ## Will need to fix up in merged directory\n",
    "            #timeseries = timeseries.get_data().transpose((3, 0, 1, 2))\n",
    "            timeseries = timeseries.get_data().transpose((3, 2, 0, 1))\n",
    "            \n",
    "            # use information in regressor/run_x folder to make hasImage vector\n",
    "            # associated TR is just the hasImage index, converted to a float\n",
    "            Onsets = [0]*240\n",
    "            for cope in ['bed', 'bench', 'chair', 'table']:\n",
    "                with open(reg_file.format(subject, r, cope)) as f:\n",
    "                    times = [line.split(' ')[0] for line in f.read().split('\\n')[:-1]]\n",
    "                    for t in times:\n",
    "                        TR = int(float(t)/1.5)\n",
    "                        Onsets[TR] = cope\n",
    "                        \n",
    "            # wherever hasImage, we want the features\n",
    "            features = [timeseries[n+3] for n, onset in enumerate(Onsets) if onset != 0]\n",
    "            labels = [label for label in Onsets if label != 0]\n",
    "            FEATURES = np.array(features) if rn == 0 else np.vstack((FEATURES, np.array(features)))\n",
    "            LABELS = labels if rn == 0 else LABELS + labels\n",
    "        \n",
    "        for roi in roi_list_masks:\n",
    "            mask = nib.load('{}/{}.nii.gz'.format(roi_dir.format(subject), roi))\n",
    "            maskDat = mask.get_data()\n",
    "            masked = FEATURES[:, maskDat == 1]\n",
    "            #np.save('{}/recog/{}_{}_{}_featurematrix.npy'.format(feat_dir, subject, roi, phase), masked)\n",
    "\n",
    "            ## metadata\n",
    "            x = pd.DataFrame([subj, LABELS, run_num, TR_num]) # where each of those variables are lists of the same length\n",
    "            x = x.transpose()\n",
    "            x.columns = ['subj','label','run_num', 'TR_num']\n",
    "            #x.to_csv('{}/recog/metadata_{}_{}_{}csv'.format(feat_dir, subject, roi, phase))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature and metadata extraction from drawing runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating connectivity features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
