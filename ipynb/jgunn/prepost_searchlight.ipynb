{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import scipy\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from nilearn import image\n",
    "from brainiak.searchlight.searchlight import Searchlight\n",
    "from brainiak.searchlight.searchlight import Cube\n",
    "\n",
    "import analysis_helpers as helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root paths\n",
    "data_dir = '/jukebox/ntb/projects/sketchloop02/data'\n",
    "SAVE_PATH = '/jukebox/ntb/projects/sketchloop02/data/searchlight_output'\n",
    "\n",
    "# module definitions\n",
    "roi_dir = os.path.join(data_dir, 'copes/roi')\n",
    "cope_dir = os.path.join(data_dir, 'copes/recog/objectGLM')\n",
    "sub_dirs = sorted(os.listdir(roi_dir))\n",
    "helpers.roi_dir, helpers.cope_dir = roi_dir, cope_dir\n",
    "\n",
    "# null mask\n",
    "null_mask = np.ones((88, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need version of this function that gives access to affine\n",
    "def load_single_run_weights(subj,run_num,cope_num):\n",
    "    nifti_path = os.path.join(cope_dir, subj[:7] + '_run' + str(run_num) + '_cope' + str(cope_num) + '_hires.nii.gz')\n",
    "    fmri_img = image.load_img(nifti_path)\n",
    "    fmri_data = fmri_img.get_data()\n",
    "    return fmri_data, fmri_img.affine\n",
    "\n",
    "# need version of this function that resolves presence of nans in matrix\n",
    "def pairwise_distances(matrix):\n",
    "    output = np.zeros((8, 8))\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            a = matrix[i, :]\n",
    "            b = matrix[j, :]\n",
    "            notnan = np.logical_and((b != np.nan),(a != np.nan))\n",
    "            output[i,j] = scipy.spatial.distance.correlation(a[notnan], b[notnan])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define and run searchlight\n",
    "How searchlight works with brainiak:\n",
    "\n",
    "1. Initiate a searchlight object, articulating certain parameters (e.g., searchlight shape, radius, max edge length, in voxels, of the 3D block(?)).\n",
    "2. Distribute data to be searched to the searchlight object, sorting between MPI ranks (idk what MPI ranks are tbh).\n",
    "3. Broadcast data, i.e., define other variables to be available for each execution of the searchlight function.\n",
    "4. Run the searchlight, this time articulating as a parameter the function to be applied at each searchlight location.\n",
    "\n",
    "We want to perform searchlight again, but this time the objective is to perform a version of helpers.make_drawing_predictions on each searchlight mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepostRSA(subject_data, mask, sl_rad, bcast_var):\n",
    "    # first PRE\n",
    "    mat1 = np.array([subject_data[0][:, :, :, i].ravel() for i in range(4)])\n",
    "    mat2 = np.array([subject_data[0][:, :, :, i].ravel() for i in range(4,8)])\n",
    "    fAB = np.vstack((mat1,mat2)) # stack feature matrices\n",
    "    DAB = pairwise_distances(fAB, metric='correlation') # pre\n",
    "    offblock = DAB[:len(mat1),range(len(mat1),np.shape(DAB)[1])]\n",
    "\n",
    "    trained_witobj = offblock.diagonal()[:2]\n",
    "    control_witobj = offblock.diagonal()[2:]\n",
    "    trained_btwobj = np.array([offblock[:2,:2][0,1], offblock[:2,:2][1,0]])\n",
    "    control_btwobj = np.array([offblock[2:,2:][0,1],offblock[2:,2:][1,0]])\n",
    "\n",
    "    trawit_mean = np.nanmean(trained_witobj)\n",
    "    conwit_mean = np.nanmean(control_witobj)\n",
    "    trabtw_mean = np.nanmean(trained_btwobj)\n",
    "    conbtw_mean = np.nanmean(control_btwobj)\n",
    "    tradiffpre = trabtw_mean - trawit_mean\n",
    "    condiffpre = conbtw_mean - conwit_mean\n",
    "    \n",
    "    # now POST\n",
    "    mat1 = np.array([subject_data[0][:, :, :, i].ravel() for i in range(8,12)])\n",
    "    mat2 = np.array([subject_data[0][:, :, :, i].ravel() for i in range(12,16)])\n",
    "    fAB = np.vstack((mat1,mat2)) # stack feature matrices|\n",
    "    DAB = pairwise_distances(fAB, metric='correlation') # post\n",
    "    offblock = DAB[:len(mat1),range(len(mat1),np.shape(DAB)[1])]\n",
    "\n",
    "    trained_witobj = offblock.diagonal()[:2]\n",
    "    control_witobj = offblock.diagonal()[2:]\n",
    "    trained_btwobj = np.array([offblock[:2,:2][0,1], offblock[:2,:2][1,0]])\n",
    "    control_btwobj = np.array([offblock[2:,2:][0,1],offblock[2:,2:][1,0]])\n",
    "\n",
    "    trawit_mean = np.nanmean(trained_witobj)# .mean()\n",
    "    conwit_mean = np.nanmean(control_witobj)#.mean()\n",
    "    trabtw_mean = np.nanmean(trained_btwobj)#.mean()\n",
    "    conbtw_mean = np.nanmean(control_btwobj)#.mean()\n",
    "    tradiffpost = trabtw_mean - trawit_mean\n",
    "    condiffpost = conbtw_mean - conwit_mean\n",
    "    \n",
    "    return (tradiffpost-tradiffpre)-(condiffpost-condiffpre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that sets up and organizes searchlight over a set of subjects\n",
    "def searchlight_over_each(subjects, sl_rad):\n",
    "    \n",
    "    for s in subjects:\n",
    "        print(s)\n",
    "        \n",
    "        # set up searchlight object\n",
    "        sl = Searchlight(sl_rad=sl_rad, shape=Cube)\n",
    "        \n",
    "        # arrange data to be distributed to searchlight\n",
    "        # list of 4D not 3D arrays\n",
    "        subject_data = []\n",
    "        \n",
    "        for run in [3, 4, 5, 6]:\n",
    "            condorder = helpers.get_condorder(s)\n",
    "            for c in condorder:\n",
    "                weights, affine = load_single_run_weights(s, run, c)\n",
    "                subject_data.append(weights)\n",
    "\n",
    "        #subject_data = [s.reshape((88, 128, 128, 1)) for s in subject_data]\n",
    "        subject_data = [np.stack(subject_data, axis=3)]\n",
    "        \n",
    "        # distribute and broadcast needed data to searchlight\n",
    "        sl.distribute(subject_data, null_mask)\n",
    "        sl.broadcast(None)\n",
    "        \n",
    "        # run searchlight\n",
    "        subject_outputs = np.array(sl.run_searchlight(prepostRSA))\n",
    "        print(np.shape(subject_outputs.astype(np.float32)))\n",
    "        img = nib.Nifti1Image(subject_outputs.astype(np.float32), affine)\n",
    "        # store output for this subject\n",
    "        if not os.path.exists(SAVE_PATH):\n",
    "            os.makedirs(SAVE_PATH)\n",
    "        \n",
    "        localizer_tmap_filename = os.path.join(SAVE_PATH, s + 'prepost_searchlight.nii.gz')\n",
    "        nib.save(img, localizer_tmap_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run searchlight over all subjects and print time to compute results\n",
    "searchlight_over_each(sub_dirs, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
