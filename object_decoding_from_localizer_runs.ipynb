{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn import linear_model, datasets, neighbors\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import svm\n",
    "\n",
    "%matplotlib inline\n",
    "from scipy.misc import imread, imresize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import norm\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_data = '/data/jefan/neurosketch_features_3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "METAS = sorted([i for i in os.listdir(path_to_data) if i.split('.')[-1]=='csv'])\n",
    "FEATS = sorted([i for i in os.listdir(path_to_data) if i.split('.')[-1]=='npy'])\n",
    "SUBS = np.array([i.split('_')[0]+'_neurosketch' for i in FEATS])\n",
    "ROIS = np.array([i.split('_')[1] for i in FEATS])\n",
    "roi_list = np.array(['V1','LOC','fusiform','IT','occitemp'])\n",
    "sub_list = np.unique(SUBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing V1 of 0110171_neurosketch ...\n",
      "Analyzing LOC of 0110171_neurosketch ...\n",
      "Analyzing fusiform of 0110171_neurosketch ...\n",
      "Analyzing IT of 0110171_neurosketch ...\n",
      "Analyzing occitemp of 0110171_neurosketch ...\n",
      "Analyzing V1 of 0110172_neurosketch ...\n",
      "Analyzing LOC of 0110172_neurosketch ...\n",
      "Analyzing fusiform of 0110172_neurosketch ...\n",
      "Analyzing IT of 0110172_neurosketch ...\n",
      "Analyzing occitemp of 0110172_neurosketch ...\n",
      "Analyzing V1 of 0111171_neurosketch ...\n",
      "Analyzing LOC of 0111171_neurosketch ...\n",
      "Analyzing fusiform of 0111171_neurosketch ...\n",
      "Analyzing IT of 0111171_neurosketch ...\n",
      "Analyzing occitemp of 0111171_neurosketch ...\n",
      "Analyzing V1 of 0112171_neurosketch ...\n",
      "Analyzing LOC of 0112171_neurosketch ...\n",
      "Analyzing fusiform of 0112171_neurosketch ...\n",
      "Analyzing IT of 0112171_neurosketch ...\n",
      "Analyzing occitemp of 0112171_neurosketch ...\n",
      "Analyzing V1 of 0112172_neurosketch ...\n",
      "Analyzing LOC of 0112172_neurosketch ...\n",
      "Analyzing fusiform of 0112172_neurosketch ...\n",
      "Analyzing IT of 0112172_neurosketch ...\n",
      "Analyzing occitemp of 0112172_neurosketch ...\n",
      "Analyzing V1 of 0112173_neurosketch ...\n",
      "Analyzing LOC of 0112173_neurosketch ...\n",
      "Analyzing fusiform of 0112173_neurosketch ...\n",
      "Analyzing IT of 0112173_neurosketch ...\n",
      "Analyzing occitemp of 0112173_neurosketch ...\n",
      "Analyzing V1 of 0113171_neurosketch ...\n",
      "Analyzing LOC of 0113171_neurosketch ...\n",
      "Analyzing fusiform of 0113171_neurosketch ...\n",
      "Analyzing IT of 0113171_neurosketch ...\n",
      "Analyzing occitemp of 0113171_neurosketch ...\n",
      "Analyzing V1 of 0115172_neurosketch ...\n",
      "Analyzing LOC of 0115172_neurosketch ...\n",
      "Analyzing fusiform of 0115172_neurosketch ...\n",
      "Analyzing IT of 0115172_neurosketch ...\n",
      "Analyzing occitemp of 0115172_neurosketch ...\n",
      "Analyzing V1 of 0115174_neurosketch ...\n",
      "Analyzing LOC of 0115174_neurosketch ...\n",
      "Analyzing fusiform of 0115174_neurosketch ...\n",
      "Analyzing IT of 0115174_neurosketch ...\n",
      "Analyzing occitemp of 0115174_neurosketch ...\n",
      "Analyzing V1 of 0117171_neurosketch ...\n",
      "Analyzing LOC of 0117171_neurosketch ...\n",
      "Analyzing fusiform of 0117171_neurosketch ...\n",
      "Analyzing IT of 0117171_neurosketch ...\n",
      "Analyzing occitemp of 0117171_neurosketch ...\n",
      "Analyzing V1 of 0118171_neurosketch ...\n",
      "Analyzing LOC of 0118171_neurosketch ...\n",
      "Analyzing fusiform of 0118171_neurosketch ...\n",
      "Analyzing IT of 0118171_neurosketch ...\n",
      "Analyzing occitemp of 0118171_neurosketch ...\n",
      "Analyzing V1 of 0118172_neurosketch ...\n",
      "Analyzing LOC of 0118172_neurosketch ...\n",
      "Analyzing fusiform of 0118172_neurosketch ...\n",
      "Analyzing IT of 0118172_neurosketch ...\n",
      "Analyzing occitemp of 0118172_neurosketch ...\n",
      "Analyzing V1 of 0119171_neurosketch ...\n",
      "Analyzing LOC of 0119171_neurosketch ...\n",
      "Analyzing fusiform of 0119171_neurosketch ...\n",
      "Analyzing IT of 0119171_neurosketch ...\n",
      "Analyzing occitemp of 0119171_neurosketch ...\n",
      "Analyzing V1 of 0119172_neurosketch ...\n",
      "Analyzing LOC of 0119172_neurosketch ...\n",
      "Analyzing fusiform of 0119172_neurosketch ...\n",
      "Analyzing IT of 0119172_neurosketch ...\n",
      "Analyzing occitemp of 0119172_neurosketch ...\n",
      "Analyzing V1 of 0119173_neurosketch ...\n",
      "Analyzing LOC of 0119173_neurosketch ...\n",
      "Analyzing fusiform of 0119173_neurosketch ...\n",
      "Analyzing IT of 0119173_neurosketch ...\n",
      "Analyzing occitemp of 0119173_neurosketch ...\n",
      "Analyzing V1 of 0119174_neurosketch ...\n",
      "Analyzing LOC of 0119174_neurosketch ...\n",
      "Analyzing fusiform of 0119174_neurosketch ...\n",
      "Analyzing IT of 0119174_neurosketch ...\n",
      "Analyzing occitemp of 0119174_neurosketch ...\n",
      "Analyzing V1 of 0120171_neurosketch ...\n",
      "Analyzing LOC of 0120171_neurosketch ...\n",
      "Analyzing fusiform of 0120171_neurosketch ...\n",
      "Analyzing IT of 0120171_neurosketch ...\n",
      "Analyzing occitemp of 0120171_neurosketch ...\n",
      "Analyzing V1 of 0120172_neurosketch ...\n",
      "Analyzing LOC of 0120172_neurosketch ...\n",
      "Analyzing fusiform of 0120172_neurosketch ...\n",
      "Analyzing IT of 0120172_neurosketch ...\n",
      "Analyzing occitemp of 0120172_neurosketch ...\n",
      "Analyzing V1 of 0120173_neurosketch ...\n",
      "Analyzing LOC of 0120173_neurosketch ...\n",
      "Analyzing fusiform of 0120173_neurosketch ...\n",
      "Analyzing IT of 0120173_neurosketch ...\n",
      "Analyzing occitemp of 0120173_neurosketch ...\n",
      "Analyzing V1 of 0123171_neurosketch ...\n",
      "Analyzing LOC of 0123171_neurosketch ...\n",
      "Analyzing fusiform of 0123171_neurosketch ...\n",
      "Analyzing IT of 0123171_neurosketch ...\n",
      "Analyzing occitemp of 0123171_neurosketch ...\n",
      "Analyzing V1 of 0123173_neurosketch ...\n",
      "Analyzing LOC of 0123173_neurosketch ...\n",
      "Analyzing fusiform of 0123173_neurosketch ...\n",
      "Analyzing IT of 0123173_neurosketch ...\n",
      "Analyzing occitemp of 0123173_neurosketch ...\n",
      "Analyzing V1 of 0124171_neurosketch ...\n",
      "Analyzing LOC of 0124171_neurosketch ...\n",
      "Analyzing fusiform of 0124171_neurosketch ...\n",
      "Analyzing IT of 0124171_neurosketch ...\n",
      "Analyzing occitemp of 0124171_neurosketch ...\n",
      "Analyzing V1 of 0125171_neurosketch ...\n",
      "Analyzing LOC of 0125171_neurosketch ...\n",
      "Analyzing fusiform of 0125171_neurosketch ...\n",
      "Analyzing IT of 0125171_neurosketch ...\n",
      "Analyzing occitemp of 0125171_neurosketch ...\n",
      "Analyzing V1 of 0125172_neurosketch ...\n",
      "Analyzing LOC of 0125172_neurosketch ...\n",
      "Analyzing fusiform of 0125172_neurosketch ...\n",
      "Analyzing IT of 0125172_neurosketch ...\n",
      "Analyzing occitemp of 0125172_neurosketch ...\n",
      "Analyzing V1 of 1121161_neurosketch ...\n",
      "Analyzing LOC of 1121161_neurosketch ...\n",
      "Analyzing fusiform of 1121161_neurosketch ...\n",
      "Analyzing IT of 1121161_neurosketch ...\n",
      "Analyzing occitemp of 1121161_neurosketch ...\n",
      "Analyzing V1 of 1130161_neurosketch ...\n",
      "Analyzing LOC of 1130161_neurosketch ...\n",
      "Analyzing fusiform of 1130161_neurosketch ...\n",
      "Analyzing IT of 1130161_neurosketch ...\n",
      "Analyzing occitemp of 1130161_neurosketch ...\n",
      "Analyzing V1 of 1202161_neurosketch ...\n",
      "Analyzing LOC of 1202161_neurosketch ...\n",
      "Analyzing fusiform of 1202161_neurosketch ...\n",
      "Analyzing IT of 1202161_neurosketch ...\n",
      "Analyzing occitemp of 1202161_neurosketch ...\n",
      "Analyzing V1 of 1203161_neurosketch ...\n",
      "Analyzing LOC of 1203161_neurosketch ...\n",
      "Analyzing fusiform of 1203161_neurosketch ...\n",
      "Analyzing IT of 1203161_neurosketch ...\n",
      "Analyzing occitemp of 1203161_neurosketch ...\n",
      "Analyzing V1 of 1206161_neurosketch ...\n",
      "Analyzing LOC of 1206161_neurosketch ...\n",
      "Analyzing fusiform of 1206161_neurosketch ...\n",
      "Analyzing IT of 1206161_neurosketch ...\n",
      "Analyzing occitemp of 1206161_neurosketch ...\n",
      "Analyzing V1 of 1206162_neurosketch ...\n",
      "Analyzing LOC of 1206162_neurosketch ...\n",
      "Analyzing fusiform of 1206162_neurosketch ...\n",
      "Analyzing IT of 1206162_neurosketch ...\n",
      "Analyzing occitemp of 1206162_neurosketch ...\n",
      "Analyzing V1 of 1206163_neurosketch ...\n",
      "Analyzing LOC of 1206163_neurosketch ...\n",
      "Analyzing fusiform of 1206163_neurosketch ...\n",
      "Analyzing IT of 1206163_neurosketch ...\n",
      "Analyzing occitemp of 1206163_neurosketch ...\n",
      "Analyzing V1 of 1207162_neurosketch ...\n",
      "Analyzing LOC of 1207162_neurosketch ...\n",
      "Analyzing fusiform of 1207162_neurosketch ...\n",
      "Analyzing IT of 1207162_neurosketch ...\n",
      "Analyzing occitemp of 1207162_neurosketch ...\n"
     ]
    }
   ],
   "source": [
    "## take in single subjects feature matrix, take transpose\n",
    "SPLITS = []\n",
    "for sub in sub_list:\n",
    "    Splits = []\n",
    "    for roi in roi_list:\n",
    "        print 'Analyzing {} of {} ...'.format(roi, sub)\n",
    "            \n",
    "        _feat_ind = (SUBS==sub) & (ROIS==roi)        \n",
    "        assert sum(_feat_ind)==1    \n",
    "        feat_ind = np.where(_feat_ind==True)[0][0]\n",
    "\n",
    "        F = np.load(os.path.join(path_to_data,FEATS[feat_ind])).transpose()\n",
    "        assert F.shape[0]==160\n",
    "\n",
    "        ## read in that subject's metadata file\n",
    "        M = pd.read_csv(os.path.join(path_to_data,METAS[feat_ind]))\n",
    "\n",
    "        ## z-score within run\n",
    "        def normalize(X):\n",
    "            X = X - X.mean(0)\n",
    "            X = X / np.maximum(X.std(0), 1e-6)\n",
    "            return X\n",
    "\n",
    "        run1_inds = M.index[M.run_num==1]\n",
    "        run2_inds = M.index[M.run_num==2]\n",
    "\n",
    "        Fnorm = np.vstack((normalize(F[run1_inds,:]),normalize(F[run2_inds,:])))\n",
    "\n",
    "        ## divide into train/test split by run\n",
    "        F1 = Fnorm[run1_inds,:]\n",
    "        F2 = Fnorm[run2_inds,:]\n",
    "        Labels1 = M.iloc[run1_inds].label.values\n",
    "        Labels2 = M.iloc[run2_inds].label.values\n",
    "\n",
    "        splits = []\n",
    "        # fit on run1, test on run2\n",
    "        clf = linear_model.LogisticRegression(penalty='l2',C=1,random_state=1).fit(F1, Labels1)\n",
    "        score = clf.score(F2, Labels2)\n",
    "        splits.append(score)\n",
    "        # train on run2, test on run1\n",
    "        clf = linear_model.LogisticRegression(penalty='l2',C=1,random_state=1).fit(F2, Labels2)\n",
    "        score = clf.score(F1, Labels1)\n",
    "        splits.append(score)\n",
    "        Splits.append(splits)\n",
    "    SPLITS.append(Splits)\n",
    "SPLITS = np.array(SPLITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zip(roi_list, SPLITS.mean(2).mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,16))\n",
    "sns.set_context('poster')\n",
    "for roi in roi_list:\n",
    "    roi_ind = np.where(roi_list==roi)[0][0]\n",
    "    plt.subplot(2,3,roi_ind+1)\n",
    "    this_roi = SPLITS[:,roi_ind,:]\n",
    "    plt.scatter(this_roi[:,0],this_roi[:,1])\n",
    "    plt.xlabel('test on run 2')\n",
    "    plt.ylabel('test on run 1')\n",
    "    plt.title('decoding acc. {}'.format(roi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,6))\n",
    "bar_width = 0.50\n",
    "opacity = 0.8\n",
    "sem = SPLITS.mean(2).std(0)/np.sqrt(len(sub_list))\n",
    "bar_height = sem * 2\n",
    "index = np.arange(len(roi_list))\n",
    "yvals = SPLITS.mean(2).mean(0)\n",
    "plt.bar(index,\n",
    "        yvals,\n",
    "        bar_width,\n",
    "        yerr=bar_height,\n",
    "        alpha=opacity,\n",
    "        color=(0.6,0.2,0.2))\n",
    "tick = plt.xticks(index, roi_list)\n",
    "plt.axhline(y=0.25,linewidth=2, color=(0.1,0.1,0.1),linestyle='dashed')\n",
    "plt.ylim([0,0.5])\n",
    "plt.ylabel('classifier accuracy')\n",
    "# plt.xlim(0.5,1.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/jefan/sketchfeat/sketches/plots/object_decoding_accuracy_localizer_runs.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
