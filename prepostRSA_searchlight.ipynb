{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## April 10 2017\n",
    "## Judy Fan (jefan@) and Jordan Gunn (jgunn@)\n",
    "## DESIGN ## ## ## ## \n",
    "## There are four objects (bed, bench, chair, table). Participants viewed each object 20 times per run.\n",
    "## Runs 1 & 2 -- reserved to conduct searchlight\n",
    "## Runs 3 & 4 -- pretest phase \n",
    "## Four training runs involving practice drawing two of the trained objects. \n",
    "## Runs 5 & 6 -- posttest phase\n",
    "## GOAL ## ## ## ## \n",
    "## Compare similarity between Trained object representations before and after training (vs. Control) in several\n",
    "## anatomically-defined ROIs. To do this, define `representation' as cope maps generated \n",
    "## upon fitting GLM to each object for each run. Build object x voxel matrix (4xK) for each run, vertically concatenate\n",
    "## the two runs in each phase, and compute correlation matrix. Consider M = off-diagonal 4x4 block [:4,4:8].\n",
    "## Make sure the rows are sorted such that the first two are the Trained, and the last two are the Control objects.\n",
    "## Now take the the top-left 2x2 matrix within M and let's call it M-trained. The bottom-right 2x2 = M-control.\n",
    "## The diagonal elements of M-trained (A,D depicted below) reflect the representational similarity for the *same* object between runs.\n",
    "## The off diagonal elements of M-trained (B,C) reflect the similarity between different objects across runs. \n",
    "## [_A_|_B_]\n",
    "## [_C_|_D_]\n",
    "## Mean of (B,C) - Mean(A,D) = Representational distance between objects in this phase. \n",
    "## Do the above for the pretest, then for the posttest, and compare.\n",
    "\n",
    "## NOTE: On the 'sketchloop' machine, data are found in sketchloop02 directory at the same level as this 'neurosketch' \n",
    "## analysis directory, and are organized by subject. All the paths here are defined for the file organization on this \n",
    "## computer, so this code won't run as-is \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import scipy.stats as stats\n",
    "from sklearn import metrics\n",
    "import matplotlib\n",
    "matplotlib.use(\"Pdf\")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from pylab import *\n",
    "import seaborn as sns\n",
    "\n",
    "import brainiak\n",
    "import nibabel\n",
    "import nilearn\n",
    "from nilearn import image\n",
    "\n",
    "from sklearn.metrics.pairwise import pairwise_distances as pd\n",
    "from sklearn import svm\n",
    "import sklearn\n",
    "import analysis_helpers as helpers\n",
    "import _pickle as cPickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in experimental design pickle file\n",
    "# ??? What's a pickle file? How does this represent experimental design?\n",
    "with open('morph_drawing_training_design.pkl', 'rb') as f:\n",
    "    mdtd = cPickle.load(f, encoding='latin1') \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## cope numbering legend\n",
    "## cope1 = 'bed'\n",
    "## cope2 = 'bench'\n",
    "## cope3 = 'chair'\n",
    "## cope4 = 'table'\n",
    "\n",
    "cope2obj = {'cope1':'bed','cope2':'bench', 'cope3':'chair','cope4':'table'}\n",
    "obj2cope = {'bed':1,'bench':2, 'chair':3,'table':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# behavioral data from database\n",
    "import json\n",
    "with open('versionNums.json') as json_data:\n",
    "    coll = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0110171_neurosketch', '0110172_neurosketch', '0111171_neurosketch', '0112171_neurosketch', '0112172_neurosketch', '0112173_neurosketch', '0113171_neurosketch', '0115172_neurosketch', '0115174_neurosketch', '0117171_neurosketch', '0118171_neurosketch', '0118172_neurosketch', '0119171_neurosketch', '0119172_neurosketch', '0119173_neurosketch', '0119174_neurosketch', '0120171_neurosketch', '0120172_neurosketch', '0120173_neurosketch', '0123171_neurosketch', '0123173_neurosketch', '0124171_neurosketch', '0125171_neurosketch', '0125172_neurosketch', '1121161_neurosketch', '1130161_neurosketch', '1201161_neurosketch', '1202161_neurosketch', '1203161_neurosketch', '1206161_neurosketch', '1206162_neurosketch', '1206163_neurosketch', '1207162_neurosketch']\n",
      "33 subjects\n"
     ]
    }
   ],
   "source": [
    "## get list of subject directories\n",
    "proj_dir = '/home/jefan/sketchloop02/'\n",
    "contents_dir = os.listdir(proj_dir)\n",
    "\n",
    "sub_dirs = []\n",
    "for i in contents_dir:\n",
    "    try:\n",
    "        if i.split('_')[1]=='neurosketch':\n",
    "            sub_dirs.append(i)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "sub_dirs = sorted(sub_dirs)\n",
    "\n",
    "# issue with 1207161\n",
    "sub_dirs = [s for s in sub_dirs if s != '1207161_neurosketch']\n",
    "\n",
    "print(sub_dirs)\n",
    "print(str(len(sub_dirs)) + ' subjects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Analysis helper functions (see and update: analysis_helpers.py)\n",
    "\n",
    "def get_object_index(morphline,morphnum):\n",
    "    # **this is unused in the code**\n",
    "    # get numbers that correspond to each object in the \n",
    "    # list of furniture items \n",
    "    furniture_axes = ['bedChair', 'bedTable', 'benchBed', \n",
    "                      'chairBench', 'chairTable', 'tableBench']\n",
    "    car_axes = ['limoToSUV','limoToSedan','limoToSmart',\n",
    "                'smartToSedan','suvToSedan','suvToSmart']  \n",
    "    furniture_items = ['bed','bench','chair','table']\n",
    "    car_items = ['limo','sedan','smartcar','SUV']               \n",
    "    endpoints = mdr_helpers.getEndpoints(morphline)\n",
    "    morphnum = float(morphnum)\n",
    "    whichEndpoint = int(np.round(morphnum/100))\n",
    "    thing = endpoints[whichEndpoint]\n",
    "    if morphline in furniture_axes:\n",
    "        return furniture_items.index(thing)+1\n",
    "    elif morphline in car_axes:\n",
    "        return car_items.index(thing)+1    \n",
    "    \n",
    "def getEndpoints(morphline):\n",
    "    # return two components \n",
    "    if morphline=='sedanMinivan':\n",
    "        return ['sedan','minivan']\n",
    "    elif morphline=='minivanSportscar':\n",
    "        return ['minivan','sportscar']\n",
    "    elif morphline=='sportscarSUV':\n",
    "        return ['sportscar','SUV']\n",
    "    elif morphline=='SUVMinivan':\n",
    "        return ['SUV','minivan']\n",
    "    elif morphline=='sportscarSedan':\n",
    "        return ['sportscar','sedan']\n",
    "    elif morphline=='sedanSUV':\n",
    "        return ['sedan','SUV']\n",
    "    elif morphline=='bedChair':\n",
    "        return ['bed','chair']\n",
    "    elif morphline=='bedTable':\n",
    "        return ['bed','table']\n",
    "    elif morphline=='benchBed':\n",
    "        return ['bench','bed']\n",
    "    elif morphline=='chairBench':\n",
    "        return ['chair','bench']\n",
    "    elif morphline=='chairTable':\n",
    "        return ['chair','table']\n",
    "    elif morphline=='tableBench':\n",
    "        return ['table','bench']\n",
    "    elif morphline=='limoToSUV':\n",
    "        return ['limo','SUV']    \n",
    "    elif morphline=='limoToSedan':\n",
    "        return ['sedan','limo']  \n",
    "    elif morphline=='limoToSmart':\n",
    "        return ['limo','smartcar']  \n",
    "    elif morphline=='smartToSedan':\n",
    "        return ['smartcar','sedan']    \n",
    "    elif morphline=='suvToSedan':\n",
    "        return ['SUV','sedan']  \n",
    "    elif morphline=='suvToSmart':\n",
    "        return ['SUV','smartcar']  \n",
    "    else:\n",
    "        return ['A','B']          \n",
    "\n",
    "    \n",
    "def triple_sum(X):\n",
    "    # take triple sum of variable\n",
    "    return sum(sum(sum(X)))\n",
    "\n",
    "def get_mask_array(mask_path):\n",
    "    # loads mask applied to nifty (.nii.gz) file\n",
    "    # mask selects voxels to be included/discarded\n",
    "    mask_img = image.load_img(mask_path)\n",
    "    mask_data = mask_img.get_data()\n",
    "    num_brain_voxels = sum(sum(sum(mask_data==1)))\n",
    "    return mask_data, num_brain_voxels\n",
    "    \n",
    "def load_roi_mask(subj,run_num,roi):\n",
    "    # some masks already generated from anatomical atlas; \n",
    "    mask_path = proj_dir + subj +'/analysis/firstlevel/rois/' + roi + '_func_run_' + str(run_num) + '_binarized.nii.gz'        \n",
    "    mask_data, nv = get_mask_array(mask_path)\n",
    "    return mask_data\n",
    "\n",
    "def load_roi_mask_combined(subj,run_num,roi):\n",
    "    if run_num in [1,2]:\n",
    "        phase_num = '12' \n",
    "    elif run_num in [3,4]:\n",
    "        phase_num = '34'\n",
    "    elif run_num in [5,6]:\n",
    "        phase_num = '56'\n",
    "    mask_path = proj_dir + '/' + subj +'/analysis/firstlevel/rois/' + roi + '_func_combined_' + phase_num + '_binarized.nii.gz'        \n",
    "    mask_data, nv = get_mask_array(mask_path)\n",
    "    return mask_data\n",
    "\n",
    "def normalize(X):\n",
    "    mn = X.mean(0)\n",
    "    sd = X.std(0)\n",
    "    X = X - mn\n",
    "    X = X / np.maximum(sd, 1e-5)\n",
    "    return X\n",
    "\n",
    "def load_single_run_weights(subj,run_num,cope_num):\n",
    "    nifti_path = proj_dir + '/' + subj + '/analysis/firstlevel/glm4_recognition_run_' + str(run_num) + \\\n",
    "                '.feat/stats/' + 'cope' + str(cope_num) + '.nii.gz'\n",
    "    fmri_img = image.load_img(nifti_path)\n",
    "    fmri_data = fmri_img.get_data()\n",
    "    return fmri_data\n",
    "\n",
    "def apply_mask(data,mask):\n",
    "    return data[mask==1]\n",
    "\n",
    "def load_data_and_apply_mask(subj,run_num,roi,cope_num):\n",
    "    mask = load_roi_mask_combined(subj,run_num,roi)\n",
    "    vol = load_single_run_weights(subj,run_num,cope_num)\n",
    "    vec = apply_mask(vol,mask)\n",
    "    return vec\n",
    "\n",
    "def extract_obj_by_voxel_run_mat(this_sub,run_num, roi):\n",
    "    cope1 = load_data_and_apply_mask(this_sub,run_num,roi,1)\n",
    "    cope2 = load_data_and_apply_mask(this_sub,run_num,roi,2)\n",
    "    cope3 = load_data_and_apply_mask(this_sub,run_num,roi,3)\n",
    "    cope4 = load_data_and_apply_mask(this_sub,run_num,roi,4)\n",
    "    return np.vstack((cope1,cope2,cope3,cope4))\n",
    "\n",
    "def plot_phase_RSM(this_sub,roi,phase):\n",
    "    '''\n",
    "    e.g., plot_phase_RSM(this_sub,'fusiform','pre')\n",
    "    '''\n",
    "    if phase=='pre':\n",
    "        mat1 = extract_obj_by_voxel_run_mat(this_sub,3,roi)\n",
    "        mat2 = extract_obj_by_voxel_run_mat(this_sub,4,roi)\n",
    "    elif phase=='post':\n",
    "        mat1 = extract_obj_by_voxel_run_mat(this_sub,5,roi)\n",
    "        mat2 = extract_obj_by_voxel_run_mat(this_sub,6,roi)        \n",
    "    stacked = np.vstack((mat1,mat2))\n",
    "    plt.matshow(np.corrcoef(stacked))\n",
    "    plt.colorbar()\n",
    "\n",
    "    \n",
    "def extract_condition_by_voxel_run_mat(this_sub,run_num, roi):\n",
    "    versionNum = coll[this_sub]\n",
    "\n",
    "    design = [i for i in mdtd if i['version'] == int(versionNum)] # find which axes belong to which condition\n",
    "    trained = design[0]['trained']\n",
    "    near = design[0]['near']\n",
    "    far1 = design[0]['far1']\n",
    "    far2 = design[0]['far2']\n",
    "\n",
    "    Tep = getEndpoints(trained)\n",
    "    Nep = getEndpoints(near)\n",
    "    condorder = Tep + Nep\n",
    "\n",
    "    slot1 = load_data_and_apply_mask(this_sub,run_num,roi,obj2cope[condorder[0]])\n",
    "    slot2 = load_data_and_apply_mask(this_sub,run_num,roi,obj2cope[condorder[1]])\n",
    "    slot3 = load_data_and_apply_mask(this_sub,run_num,roi,obj2cope[condorder[2]])\n",
    "    slot4 = load_data_and_apply_mask(this_sub,run_num,roi,obj2cope[condorder[3]])\n",
    "    return np.vstack((slot1,slot2,slot3,slot4))\n",
    "    \n",
    "def remove_nans(array):\n",
    "    return array[~np.isnan(array)]\n",
    "\n",
    "def rmse(a):\n",
    "    return np.sqrt(np.mean(map(np.square,a)))\n",
    "\n",
    "def betwitdist(a,b,ab):\n",
    "    return ab/np.sqrt(0.5*(a**2+b**2))\n",
    "\n",
    "def norm_hist(data,bins):\n",
    "    weights = np.ones_like(data)/float(len(data))\n",
    "    plt.hist(data, bins=bins, weights=weights)\n",
    "    \n",
    "def compare_btw_wit_obj_similarity_across_runs(this_sub,phase,roi):\n",
    "    if phase=='searchlight':\n",
    "        sl_compare_btw_wit_obj_similarity_across_runs(this_sub, phase, mask)\n",
    "    elif phase=='pre':\n",
    "        mat1 = extract_condition_by_voxel_run_mat(this_sub,3,roi)\n",
    "        mat2 = extract_condition_by_voxel_run_mat(this_sub,4,roi)\n",
    "    elif phase=='post':\n",
    "        mat1 = extract_condition_by_voxel_run_mat(this_sub,5,roi)\n",
    "        mat2 = extract_condition_by_voxel_run_mat(this_sub,6,roi)     \n",
    "    fAB = np.vstack((mat1,mat2)) # stack feature matrices\n",
    "    DAB = sklearn.metrics.pairwise.pairwise_distances(fAB, metric='correlation') # square matrix, where off-diagblock is distances *between* fA and fB vectors\n",
    "    offblock = DAB[:len(mat1),range(len(mat1),shape(DAB)[1])]\n",
    "    wit_obj = DAB[:len(mat1),range(len(mat1),shape(DAB)[1])].diagonal()\n",
    "    btw_obj = np.hstack((offblock[np.triu_indices(shape(offblock)[0],k=1)],offblock[np.tril_indices(shape(offblock)[0],k=-1)]))\n",
    "    wit_mean = wit_obj.mean()\n",
    "    btw_mean = btw_obj.mean()\n",
    "    return wit_mean,btw_mean\n",
    "\n",
    "def compare_btw_wit_cond_similarity_across_runs(this_sub,phase,roi):\n",
    "\n",
    "    if phase=='pre':\n",
    "        mat1 = extract_condition_by_voxel_run_mat(this_sub,3,roi)\n",
    "        mat2 = extract_condition_by_voxel_run_mat(this_sub,4,roi)\n",
    "    elif phase=='post':\n",
    "        mat1 = extract_condition_by_voxel_run_mat(this_sub,5,roi)\n",
    "        mat2 = extract_condition_by_voxel_run_mat(this_sub,6,roi)\n",
    "\n",
    "    fAB = np.vstack((mat1,mat2)) # stack feature matrices\n",
    "    DAB = sklearn.metrics.pairwise.pairwise_distances(fAB, metric='correlation') # square matrix, where off-diagblock is distances *between* fA and fB vectors\n",
    "    offblock = DAB[:len(mat1),range(len(mat1),shape(DAB)[1])]\n",
    "\n",
    "    trained_witobj = offblock.diagonal()[:2]\n",
    "    control_witobj = offblock.diagonal()[2:]\n",
    "    trained_btwobj = np.array([offblock[:2,:2][0,1], offblock[:2,:2][1,0]])\n",
    "    control_btwobj = np.array([offblock[2:,2:][0,1],offblock[2:,2:][1,0]])\n",
    "\n",
    "    trawit_mean = trained_witobj.mean()\n",
    "    conwit_mean = control_witobj.mean()\n",
    "    trabtw_mean = trained_btwobj.mean()\n",
    "    conbtw_mean = control_btwobj.mean()\n",
    "    return trawit_mean,conwit_mean,trabtw_mean, conbtw_mean "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searchlight Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How searchlight works with brainiak:\n",
    "\n",
    "1. Initiate a searchlight object, articulating certain parameters (e.g., searchlight shape, radius, max edge length, in voxels, of the 3D block(?)).\n",
    "2. Distribute to the searchlight object, sorting between MPI ranks (?).\n",
    "3. Broadcast data, i.e., define other variables to be available for each execution of the searchlight function.\n",
    "4. Run the searchlight, this time articulating as a parameter the function to be applied at each searchlight location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import brainiak\n",
    "from brainiak.searchlight.searchlight import Searchlight\n",
    "from brainiak.searchlight.searchlight import Diamond\n",
    "\n",
    "# parameters\n",
    "sl_rad = 1\n",
    "num_copes = 4\n",
    "num_runs = 2\n",
    "null_mask = np.ones((94, 94, 72))\n",
    "\n",
    "# need this to order search correctly\n",
    "def sl_extract_condition_by_voxel_run_mat(this_sub):\n",
    "    versionNum = coll[this_sub]\n",
    "\n",
    "    design = [i for i in mdtd if i['version'] == int(versionNum)] # find which axes belong to which condition\n",
    "    trained = design[0]['trained']\n",
    "    near = design[0]['near']\n",
    "    far1 = design[0]['far1']\n",
    "    far2 = design[0]['far2']\n",
    "\n",
    "    Tep = getEndpoints(trained)\n",
    "    Nep = getEndpoints(near)\n",
    "    condorder = Tep + Nep\n",
    "    \n",
    "    return [obj2cope[condorder[0]], obj2cope[condorder[1]], obj2cope[condorder[2]], obj2cope[condorder[3]]]\n",
    "\n",
    "# function to operate over every voxel\n",
    "def searchlight_btw_wit_obj_similarity_across_runs(subject_data, mask, sl_rad, bcast_var):\n",
    "    # reshape to 3D so old code can be reused\n",
    "    for i in range(len(subject_data)):\n",
    "        shaping = shape(subject_data[i])\n",
    "        subject_data[i] = np.reshape(subject_data[i], (shaping[0], shaping[1], shaping[2]))\n",
    "    \n",
    "    # stack by cope for each run like roi-based function did, and then stack runs\n",
    "    mat1 = np.vstack((subject_data[0].flatten(),\n",
    "                     subject_data[1].flatten(),\n",
    "                     subject_data[2].flatten(),\n",
    "                     subject_data[3].flatten()))\n",
    "    mat2 = np.vstack((subject_data[4].flatten(),\n",
    "                      subject_data[5].flatten(),\n",
    "                      subject_data[6].flatten(),\n",
    "                      subject_data[7].flatten()))\n",
    "    fAB = np.vstack((mat1, mat2))\n",
    "    \n",
    "    # take pairwise distance matrix life the roi-based function did and store summary statistics\n",
    "    DAB = sklearn.metrics.pairwise.pairwise_distances(fAB, metric='correlation')\n",
    "    offblock = DAB[:len(mat1),range(len(mat1),shape(DAB)[1])]\n",
    "    wit_obj = DAB[:len(mat1),range(len(mat1),shape(DAB)[1])].diagonal()\n",
    "    btw_obj = np.hstack((offblock[np.triu_indices(shape(offblock)[0],k=1)],\n",
    "                         offblock[np.tril_indices(shape(offblock)[0],k=-1)]))\n",
    "    wit_mean = wit_obj.mean()\n",
    "    btw_mean = btw_obj.mean()\n",
    "    return wit_mean,btw_mean\n",
    "\n",
    "# first step is to organize data for distribution\n",
    "# for each subject we want a 4D array, x by y by z by 1\n",
    "# all of these need to be themselves collected into a single list\n",
    "def single_subject():\n",
    "    for s in [sub_dirs[0]]:\n",
    "        sl = Searchlight(sl_rad=sl_rad, shape=Diamond)\n",
    "\n",
    "        # arrange data to be distributed to searchlight\n",
    "        subject_data = []\n",
    "        for run in range(1, num_runs+1):\n",
    "            for cope in sl_extract_condition_by_voxel_run_mat(s):\n",
    "                subject_data.append(np.reshape(np.array(load_single_run_weights(s, run, cope)), (94, 94, 72, 1)))\n",
    "\n",
    "        # distribute and broadcast needed data to searchlight\n",
    "        sl.distribute(subject_data, null_mask)\n",
    "        sl.broadcast(None)\n",
    "\n",
    "        # run searchlight\n",
    "        subject_outputs = sl.run_searchlight(searchlight_btw_wit_obj_similarity_across_runs)\n",
    "        \n",
    "# time it takes to run a single subject:\n",
    "import timeit\n",
    "timeit.timeit(single_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# question: what produces these (nan, nan)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(636192,)\n",
      "240785\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(94, 94, 72)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = subject_outputs.flatten().tolist()\n",
    "count = 0\n",
    "for each in l:\n",
    "    if each != None:\n",
    "        if each[0] == each[0]:\n",
    "            count = count + 1\n",
    "print(shape(l))\n",
    "print(count)\n",
    "shape(subject_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for now we have just one subject to produce visualizations for\n",
    "# make a difference map\n",
    "difference = np.subtract(wit_means, btw_means)\n",
    "\n",
    "# produce a histogram of the difference distribution\n",
    "hist, bin_edges = np.histogram(np.reshape(difference, difference.size))\n",
    "plt.hist(hist, bins='auto')\n",
    "plt.title(\"Difference Distribution\")\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nan"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
