{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from nilearn import image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0110171_neurosketch', '0110172_neurosketch', '0111171_neurosketch', '0112171_neurosketch', '0112172_neurosketch', '0112173_neurosketch', '0113171_neurosketch', '0115172_neurosketch', '0115174_neurosketch', '0117171_neurosketch', '0118171_neurosketch', '0118172_neurosketch', '0119171_neurosketch', '0119172_neurosketch', '0119173_neurosketch', '0119174_neurosketch', '0120171_neurosketch', '0120172_neurosketch', '0120173_neurosketch', '0123171_neurosketch', '0123173_neurosketch', '0124171_neurosketch', '0125171_neurosketch', '0125172_neurosketch', '1121161_neurosketch', '1130161_neurosketch', '1202161_neurosketch', '1203161_neurosketch', '1206161_neurosketch', '1206162_neurosketch', '1206163_neurosketch', '1207162_neurosketch']\n",
      "32 subjects\n"
     ]
    }
   ],
   "source": [
    "## get list of subject directories\n",
    "proj_dir = '/home/jefan/sketchloop02/'\n",
    "contents_dir = os.listdir(proj_dir)\n",
    "\n",
    "sub_dirs = []\n",
    "for i in contents_dir:\n",
    "    try:\n",
    "        if i.split('_')[1]=='neurosketch':\n",
    "            sub_dirs.append(i)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "sub_dirs = sorted(sub_dirs)\n",
    "\n",
    "# issue with 1207161\n",
    "sub_dirs = [s for s in sub_dirs if s != '1207161_neurosketch']\n",
    "\n",
    "# issue with 1201161\n",
    "sub_dirs = [s for s in sub_dirs if s != '1201161_neurosketch']\n",
    "\n",
    "print(sub_dirs)\n",
    "print(str(len(sub_dirs)) + ' subjects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# analysis helper functions\n",
    "def get_mask_array(mask_path):\n",
    "    # loads mask applied to nifty (.nii.gz) file\n",
    "    # mask selects voxels to be included/discarded\n",
    "    mask_img = image.load_img(mask_path)\n",
    "    mask_data = mask_img.get_data()\n",
    "    num_brain_voxels = sum(sum(sum(mask_data==1)))\n",
    "    return mask_data, num_brain_voxels\n",
    "\n",
    "def load_roi_mask_combined(subj,run_num,roi):\n",
    "    if run_num in [1,2]:\n",
    "        phase_num = '12' \n",
    "    elif run_num in [3,4]:\n",
    "        phase_num = '34'\n",
    "    elif run_num in [5,6]:\n",
    "        phase_num = '56'\n",
    "    mask_path = proj_dir + '/' + subj +'/analysis/firstlevel/rois/' + roi + '_func_combined_' + phase_num + '_binarized.nii.gz'        \n",
    "    mask_data, nv = get_mask_array(mask_path)\n",
    "    return mask_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Performance Between Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V1\n",
      "0110171_neurosketch\n",
      "0110172_neurosketch\n",
      "0111171_neurosketch\n",
      "0112171_neurosketch\n",
      "0112172_neurosketch\n",
      "0112173_neurosketch\n",
      "0113171_neurosketch\n",
      "0115172_neurosketch\n",
      "0115174_neurosketch\n",
      "0117171_neurosketch\n",
      "0118171_neurosketch\n",
      "0118172_neurosketch\n",
      "0119171_neurosketch\n",
      "0119172_neurosketch\n",
      "0119173_neurosketch\n",
      "0119174_neurosketch\n",
      "0120171_neurosketch\n",
      "0120172_neurosketch\n",
      "0120173_neurosketch\n",
      "0123171_neurosketch\n",
      "0123173_neurosketch\n",
      "0124171_neurosketch\n",
      "0125171_neurosketch\n",
      "0125172_neurosketch\n",
      "1121161_neurosketch\n",
      "1130161_neurosketch\n",
      "1202161_neurosketch\n",
      "1203161_neurosketch\n",
      "1206161_neurosketch\n",
      "1206162_neurosketch\n",
      "1206163_neurosketch\n",
      "1207162_neurosketch\n",
      "fusiform\n",
      "0110171_neurosketch\n",
      "0110172_neurosketch\n",
      "0111171_neurosketch\n",
      "0112171_neurosketch\n",
      "0112172_neurosketch\n",
      "0112173_neurosketch\n",
      "0113171_neurosketch\n",
      "0115172_neurosketch\n",
      "0115174_neurosketch\n",
      "0117171_neurosketch\n",
      "0118171_neurosketch\n",
      "0118172_neurosketch\n",
      "0119171_neurosketch\n",
      "0119172_neurosketch\n",
      "0119173_neurosketch\n",
      "0119174_neurosketch\n",
      "0120171_neurosketch\n",
      "0120172_neurosketch\n",
      "0120173_neurosketch\n",
      "0123171_neurosketch\n",
      "0123173_neurosketch\n",
      "0124171_neurosketch\n",
      "0125171_neurosketch\n",
      "0125172_neurosketch\n",
      "1121161_neurosketch\n",
      "1130161_neurosketch\n",
      "1202161_neurosketch\n",
      "1203161_neurosketch\n",
      "1206161_neurosketch\n",
      "1206162_neurosketch\n",
      "1206163_neurosketch\n",
      "1207162_neurosketch\n",
      "IT\n",
      "0110171_neurosketch\n",
      "0110172_neurosketch\n",
      "0111171_neurosketch\n",
      "0112171_neurosketch\n",
      "0112172_neurosketch\n",
      "0112173_neurosketch\n",
      "0113171_neurosketch\n",
      "0115172_neurosketch\n",
      "0115174_neurosketch\n",
      "0117171_neurosketch\n",
      "0118171_neurosketch\n",
      "0118172_neurosketch\n",
      "0119171_neurosketch\n",
      "0119172_neurosketch\n",
      "0119173_neurosketch\n",
      "0119174_neurosketch\n",
      "0120171_neurosketch\n",
      "0120172_neurosketch\n",
      "0120173_neurosketch\n",
      "0123171_neurosketch\n",
      "0123173_neurosketch\n",
      "0124171_neurosketch\n",
      "0125171_neurosketch\n",
      "0125172_neurosketch\n",
      "1121161_neurosketch\n",
      "1130161_neurosketch\n",
      "1202161_neurosketch\n",
      "1203161_neurosketch\n",
      "1206161_neurosketch\n",
      "1206162_neurosketch\n",
      "1206163_neurosketch\n",
      "1207162_neurosketch\n",
      "LOC\n",
      "0110171_neurosketch\n",
      "0110172_neurosketch\n",
      "0111171_neurosketch\n",
      "0112171_neurosketch\n",
      "0112172_neurosketch\n",
      "0112173_neurosketch\n",
      "0113171_neurosketch\n",
      "0115172_neurosketch\n",
      "0115174_neurosketch\n",
      "0117171_neurosketch\n",
      "0118171_neurosketch\n",
      "0118172_neurosketch\n",
      "0119171_neurosketch\n",
      "0119172_neurosketch\n",
      "0119173_neurosketch\n",
      "0119174_neurosketch\n",
      "0120171_neurosketch\n",
      "0120172_neurosketch\n",
      "0120173_neurosketch\n",
      "0123171_neurosketch\n",
      "0123173_neurosketch\n",
      "0124171_neurosketch\n",
      "0125171_neurosketch\n",
      "0125172_neurosketch\n",
      "1121161_neurosketch\n",
      "1130161_neurosketch\n",
      "1202161_neurosketch\n",
      "1203161_neurosketch\n",
      "1206161_neurosketch\n",
      "1206162_neurosketch\n",
      "1206163_neurosketch\n",
      "1207162_neurosketch\n",
      "occitemp\n",
      "0110171_neurosketch\n",
      "0110172_neurosketch\n",
      "0111171_neurosketch\n",
      "0112171_neurosketch\n",
      "0112172_neurosketch\n",
      "0112173_neurosketch\n",
      "0113171_neurosketch\n",
      "0115172_neurosketch\n",
      "0115174_neurosketch\n",
      "0117171_neurosketch\n",
      "0118171_neurosketch\n",
      "0118172_neurosketch\n",
      "0119171_neurosketch\n",
      "0119172_neurosketch\n",
      "0119173_neurosketch\n",
      "0119174_neurosketch\n",
      "0120171_neurosketch\n",
      "0120172_neurosketch\n",
      "0120173_neurosketch\n",
      "0123171_neurosketch\n",
      "0123173_neurosketch\n",
      "0124171_neurosketch\n",
      "0125171_neurosketch\n",
      "0125172_neurosketch\n",
      "1121161_neurosketch\n",
      "1130161_neurosketch\n",
      "1202161_neurosketch\n",
      "1203161_neurosketch\n",
      "1206161_neurosketch\n",
      "1206162_neurosketch\n",
      "1206163_neurosketch\n",
      "1207162_neurosketch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.25624999999999998,\n",
       " 0.25429687499999998,\n",
       " 0.25117187499999999,\n",
       " 0.27109375000000002,\n",
       " 0.26171875]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train on run 1, test on run 2 using SVM or 4-way softmax (logistic regression classifier)\n",
    "# how to define training set?\n",
    "# get the 80 cope maps for run 1 per subject\n",
    "# i'll do it for the whole brain and then with ROI masks applied, compare results\n",
    "\n",
    "# this time, we only pick one instead of (presumably at +3, maybe +2) \n",
    "ROIs = ['V1','fusiform','IT','LOC', 'occitemp']\n",
    "roiscores = []\n",
    "\n",
    "for roi in ROIs:\n",
    "    print(roi)\n",
    "    actual = []\n",
    "    predicted = []\n",
    "    for subject in sub_dirs:\n",
    "        print(subject)\n",
    "        trainingX = []\n",
    "        trainingY = []\n",
    "        testX = []\n",
    "        testY = []\n",
    "        roi_mask = load_roi_mask_combined(subject, 1, roi)\n",
    "        for run in [1, 2]:\n",
    "\n",
    "            # load subject's time series for this run\n",
    "            timeseries = image.load_img(proj_dir + subject + '/analysis/firstlevel/preproc_recognition_run_' +\n",
    "                                                 str(run) + '.feat/filtered_func_data.nii.gz')\n",
    "            timeseries = timeseries.get_data().transpose((3, 0, 1, 2))\n",
    "            #timeseries = stats.zscore(timeseries, axis=0)\n",
    "            #timeseries[np.isnan(timeseries)] = 0\n",
    "            \n",
    "            # use information in regressor/run_x folder to make hasImage vector\n",
    "            hasImage = [0]*240\n",
    "            for cope in ['bed', 'bench', 'chair', 'table']:\n",
    "                with open('/home/jgunn/neurosketch/timepoints/' + subject[:7] + '_' + str(run) + '_' + cope + '.txt') as f:\n",
    "                    times = [line.split(' ')[0] for line in f.read().split('\\n')[:-1]]\n",
    "                    for t in times:\n",
    "                        tr = float(t)/1.5\n",
    "                        if cope == 'bed':\n",
    "                            hasImage[int(tr)] = 1\n",
    "                        elif cope == 'bench':\n",
    "                            hasImage[int(tr)] = 2\n",
    "                        elif cope == 'chair':\n",
    "                            hasImage[int(tr)] = 3\n",
    "                        elif cope == 'table':\n",
    "                            hasImage[int(tr)] = 4\n",
    "\n",
    "            # wherever hasImage, get associated volume and flatten it for training\n",
    "            for i, has in enumerate(hasImage): # 80 times\n",
    "                if has > 0:\n",
    "                    if run == 1:\n",
    "                        trainingX.append(timeseries[i+3][roi_mask==1])\n",
    "                        trainingY.append(has-1)\n",
    "                    else:\n",
    "                        testX.append(timeseries[i+3][roi_mask==1])\n",
    "                        testY.append(has-1)\n",
    "\n",
    "        lin_clf = LogisticRegression()\n",
    "        lin_clf.fit(trainingX, trainingY)\n",
    "        predicted = predicted + lin_clf.predict(testX).tolist()\n",
    "        actual = actual + testY\n",
    "        #scores = scores + [np.mean(cross_val_score(lin_clf, trainingX, trainingY).tolist())]\n",
    "    roiscores.append(np.mean(np.equal(actual, predicted)))\n",
    "    \n",
    "roiscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaoAAAElCAYAAAC1aab7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmYHFW9xvHvS1gDWVgVshB2BASEQBDjwia7KF6QXXZR\nUFBU0IuoVxRE5QIKRGSTRVBQMCwXkCURlCUJBEJYJIQlQNgDSdgJv/vHOU0qnZ6e6sn0TA/zfp6n\nn+mqOlV1qqe6fn1OnTpHEYGZmVmrWqi7M2BmZlaPA5WZmbU0ByozM2tpDlRmZtbSHKjMzKylOVCZ\nmVlLc6CyLiHpBEkvSXqug+s/IWnrzs5X3vanJT1SmF5L0kRJsyR9S9IoST9qxr4XlJLzJc2QdHd3\n56cVSBomKSQt3N15qUfSTyRd3N35aI+kSyV9sQnb3VnSn8uk7VGBStKY/IVcrLvz0pkkXSDpPUkr\ndndeapH0OUlPL8D6Q4GjgXUi4qNtpOkv6VRJT0maLemxPL1cR/dbVkTcFhFrFWZ9H7g1IvpFxOkR\ncVhE/Kyz9pcvoq/n43xG0imS+nRwcyOBbYDBEbFpZ+WxJ8jnZUg6prvz0hZJe0kan//X0yX9n6SR\n3Z2vsiStD2wA/L2N5d+T9ED+Ufe4pO9VLX9C0pv5+GdLurGyLCKuBtbN+6irxwQqScOATwMBfKFJ\n++jyX2CSlgS+DLwG7NPV++8iQ4GXI+KFWgslLQrcDKwLbAf0Bz4JvAR0x8V3ZWDygm6knfNpg4hY\nCtgK2As4pIPbXxl4IiJe7+T89QRfBV4B9uvujNQi6TvAqcAvgI+Qvgdn0KTrV5N8Dbgk2u4ZQqTP\nf2nSd/cISXtUpdk5IpbKr89XLbsUOLTdXEREj3gBxwP/Ak4BrinMHwE8B/QpzPsScH9+vxBwLPAY\n8DLwF2CZvGwYKfAdBDwF/DPPvzxv8zXgn8C6hW0vC1wNzATGAScAtxeWrw38g/QFegTYvZ3j2g+Y\nBhwJPFC17Cc5LxcDs4BJwJrAD4AX8nqfL6RfCRid9z0FOKSw7ALghML054CnC9NPAN8F7s/H/Wdg\ncWBJ4E3gfWB2fq1U4zgGABcCLwJPAsflz37rqvUvqLHuwcDzwFJ1PqcngK3z+02BO4BXgenA74BF\n8zIB/5s/n5n5M1svL9sBeDB/ls8A363+LIBbgDnAWzm/a9b47HYCJub9/xtYvyqfx+TP8W1g4RrH\nEsDqhenLgd8V/od/zZ/j48C3qs6HK/L5MJN0EXkr53c28NOc7pD8/38lnw8rVe37cOBR4PHCvG/k\nebOAnwGr5WObSfrOVD7fpYFrcv5m5PeDC9sfk9f/V97WjcByheUj83ZfJZ2/++f5iwG/Jn0PnwdG\nAUvUOR+WzNvfA3gHGF5YNiwf06HAs/kc+W5h+WKkAPJsfp0KLJaXPQTsVEi7cD7WjfL0ZoX83wd8\nro38Dcj/k93qHMNP8md7YT6WyVXHUbluzSKdt18qLNsfuD1/ZjPyubJ9YfkywPn5+GYAV5U5f2vk\ncSowsoHr9OnAb2t9b9tI/6nKeVh3u2Uz0N0v0hfvG8DGwLvARwrLHgO2qfriH5vfHwncCQzOJ+jv\ngUurTugL84m/RJ5/INCvcEJPLGz7svzqC6xD+rLdXvjyTAMOyCf4J0ilgnXqHNfNwMmkX1zvARtX\nnchvAdvm7V2YT8j/BhYhXZAeL6T/J3AmKcBsSPqCbZmXXUD7gepu0oVyGdIX9rBaads4jgtJ1QP9\n8uf6H+CgMuvnz/OP7Wz/gxM+nwOb5c9kWM7rUXnZtsAEYCApaH0MWDEvmw58Or9fmrkXn+rPYgxw\ncGH6g88u/09fIP1A6kP6Vf8Ecy90T5AuAkNo40JLIVDlc+g50o+lhXLejwcWBVYlXSi2LZwP7wJf\nzGmXIF+wCtveknTObUQ6f39L/gFW2Pc/8v94icK8v5NKsuuSAuzNef8DSBfJr+a0y5JqAPrm//Xl\nzHsRHEP6Pq6Z8zcGOCkvW5l00d2TdP4uC2yYl/0vKaguk7d7NXBinfNh3/z/7JPTFi+Ow/IxXUr6\nTn6c9F2onD//Q7omrAAsT7pY/ywvO55Ugqhsa0fgofx+EOnH7g75898mTy9fI3/bkb7P8/1QqfH9\n3iEfx4nAnYXlu5G+jwsBXwFeZ+65vH8+Fw7J636dFJSUl19L+rG5dP6sP1vm/K3K35L5c5zv+No4\nHgH3kq8bhe/D8/nzv5FUk1BcZ5m8j/51t10mA939Iv0Ke5f8ywx4GPh2YfkJwHn5fb/8D105Tz8E\nbFVIu2LeVuUiF8CqdfY9MKcZkP+x7wJrVe27Eqi+AtxWtf7vgR+3se2hpJJG5ct6A3Ba1Yn8j8L0\nzqRfaX0Kxxo5j0NIv6z7FdKfSC7BUC5Q7VOYPhkYVSttjePoQ/pVu05h3teAMSXX/wf5YlYnzRO0\n8csMOAq4Mr/fkhQkNwMWqkr3VM5X/6r51Z/FGNoOVGeRL2qF5Y8w90LwBHBgO8cSpJLKDNJF/QTS\nxWgE8FRV2h8A5xfOh39WLd+feQPVucDJhemlSOfssMK+t6yRn08VpicAxxSmfwOc2saxbAjMqPrs\njitMfwO4vnAsV9bYhkjf2dUK8z5JnV/awE2VPJEC34vAInl6WD6mtavO53Pz+8eAHQrLtiVVnwKs\nTgqmffP0JcDx+f0xwEVV+biBHMSr5u8NPNfOefAT4KbC9DrAm3XSTwR2KfzfpxSW9c3H/FHSNe59\nYOka26h7/lbNH5S3uXi94yik/ymplLlYYd6nSD9Y+ub//3PAwMLyRfI+htbbdk+5R/VV4MaIeClP\n/ynPozC9a25ksStwT0Q8mZetDFwp6VVJr5IC1xxSCaZiWuWNpD6STso382eSLjwAy5F+fS1cTF/1\nfmVgRGVfeX97k06eWvYl/VqbmKcvAfaStEghzfOF928CL0XEnMI0pIvRSsArETGrkP5J0slWVrFF\n3ht5u2UsRzrhnizMa2TfL5O+XKVIWlPSNZKey/+jX+Q8EBG3kKoCzwBekHS2pP551S+Tfr0+KWms\npE+W3WfBysDRVf/jIaTPv2Ja7VXnsVFELB0Rq0XEcRHxft72SlXb/iFtnKttWInC/yEiZpM+3+L/\notY2qs+z6umlACT1lfR7SU/mz/6fwMCqxiBtnUdDSEGi2vKkC9mEwnFfn+fPR9IQYAvS9wVSaXBx\nUumnqHicTzL3fzTPZ1RcFhFTSNeInSX1Jd1P+lNOtzKwW9X/ZyS1z92XgeVK3Aes/qwWr6wjab/c\n+rSyr/XI53n1uhHxRn67FOlzfiUiZtTYX5nzt+LV/LdfO8eApCNItzF2jIi3C/n6V0S8GRFvRMSJ\neZufLqxa2far1NHygUrSEsDuwGfzhek54NvABpI2AIiIB0kn2/akG9N/KmxiGqnudmDhtXhEPFNI\nE4X3ewG7kO6tDCD9OoP0q+9FUnF+cCH9kKp9ja3a11IR8fU2Dm8/YNXCcZ1COhF3KPHRVHsWWEZS\n8aQaSroXA+kXa9/CsraCZy3RzvKXSL/aV25j3+25Cdg2Nywp4yxSqXqNiOhPupjrg8ymlnobk36h\nrgl8L88fFxG7kKp8riLdH2jUNODnVf/jvhFxaSFNe59XvW0/XrXtfhFRPB/a2/azFP4P+TNdlnn/\nFx3NH6TWm2sBI/Jn/5nKrkqsO41076vaS6RguG7huAdEamxSy76ka9fV+XszlRSovlqVrvjdHEr6\nbKDqM6paBqnKcE/SdeDBHLwq+b+o6v+zZEScVCOPd5CqUDvUrFvSysAfgCOAZSNiIPAA5T/nZSQN\nbGNZe+cvAJEa6FSqcevl9UDS/bStIqK91sFRdQwfI5VmZ9ZbqeUDFekfPYd00dkwvz4G3Ma8rX3+\nRLof9RlSvXnFKODn+R+PpOUl7VJnf/1IJ9jLpAv7LyoLcknmb8BP8i/LtavycA2wpqR9JS2SX5tI\n+lj1TvKv+dVIDQMqx7VePo6GWzFFxDRSXfuJkhbPTT4PIt14h1RtsIOkZSR9lFRdVtbzwLKSBrSx\n7zmki/7PJfXLn/V3Cvtuz0WkL9BfJa0taSFJy0r6oaRaQbsfqepsdv4ffPBDIH/eI3Kp9HXSPYD3\nJS0qaW9JAyLi3bz++yXzV/QH4LC8D0laUtKOVT8QOupuYJakYyQtkUv360napIFtXAocIGnDXMPw\nC+CuiHiiE/IH6bN/E3hV0jLAjxtY9xJga0m7S1o4/483zKXJPwD/K2kFAEmDJG3bxna+Sqpm2rDw\n+jLp/F62kO5H+Xu6Lum+ceWZnUuB4/K1YDnSfaniuXoZ8HnSeVX80XsxqaS1bf7fLK7URL74wxWA\niHgtb/cMSV/M+VhE0vaSTi7xWVXuD72YP48DSNeHdkXEdOD/gDMlLZ33W/lB0ej5ex3w2bb2JWlv\n0jm2TURMrVo2VNKn8ndvcaWm68uRGtpUfDbnta6eEKi+Sqqjfyoinqu8SNU7exeK1peSDvqWQhUh\nwGmkm7Q3SppFuok6os7+LiSVzp4h3US+s2r5EaSS1nOkC+ylpMBGrnb7PKkl0rM5zS9JN7VrHdff\nI2JS1XGdBuyULwKN2pNUAnwWuJJ0b+ymvOwiUv3xE6SbmqUetMvH9TDpOKfm6oJa1QTfJAWGqaTW\nSH8Cziu5/bdJJdiHSferZpIu2ssBd9VY5bukku8s0heveCz987wZpP/jy8Cv8rJ9gSdyldVhpGrZ\nhkTEeNIN7N/lfUwh3S9YYDng70S68D5OKmmcQzrfym7jJuBHpJaD00k/hqqbCy+IU0n3HF4ifTeu\nbyBvT5FqC44mtUicSHpGB9L9nynAnfn/cxOp5DYPSZuRSkNnFL83ETE6r79nIfnYPO9m4NcRUXmG\n5wRgPKll5iTgnjyvks/ppBLR5hTOrfxjcBdSCf5F0o+r79HGdTQifkP6wXZcIf0RpNJ8XbmW6Dc5\nH8+TGoT8q+5K89qXVMvxMKnxxFF5u42ev2eTrrOCDx6On11YfgKpxD5Oc5+VGpWX9SPVfswgXU+3\nI9VuvVxYf0/Sffy6Ki1ErIMk/RL4aERUVzuYmfV4kv4E/CUi2g2wDW53Z2DfiNi93bQOVI3JVU2L\nkn6JbUIqGh/c2f9EMzNLevqT6d2hH6kabCVSkfw3tNG9iJmZLTiXqMzMrKX1hMYUZmbWizlQmbUI\nSZMlfa6L9yl5mBBrcQ5U1utp7vhFswuv+5q8zwsknVCcFxHrRsSYZu63hrrDhEjaX9Kc/JnMlHSf\npJ2q0iwm6USlIVrelPSo0vAPKqQZI+ng5h+OfRi5MYXZXAMj4r3uzkQXW5n2hwm5IyJGSlqI9AzO\nZZIGR0Sl25vLST2d7EB6bmc46bm9IcC3mpd16y1corIeTdKxSv0yzpL0oKQvFZatrtSn32tKowuX\nfsi5sI15RmEtlL4q/bGNkfQzSf/KebhRhcEeJY2U9O/8oPS0XEI5lPSw8fdzSeXqnPaDUYxzKeVU\nSc/m16nKA4bm3hCelnS0pBeUBuQ7oM4xrCRptKRXJE2RdEiefxDpgeJP5nz8tN5nkXuQuIjUa8Ia\neRtbkR5y/3JEPBAR70XEnaSx1Q6XtHqDH7nZfFyisp7uMVInl8+RhkW4WNLquXeBn5F64diC9Ozb\n8CblYS9SP5PTSN3BfBc4Vqkrqf8jjYt0BanXjCERMVHS5qQe249rY5v/TeoBfkPmDsNxHKnXCUgl\nmAGkzma3Aa6QdFUbHZFeRuonbiXyeGmSHouIcyXNIT0H2O6os0odzx5A6vGg0qnrNqQumubp6DYi\n7lIaFXorUu8HZh3mEpX1aBFxeUQ8GxHvR8SfSYP/Ve61VDrKXSki3oqI29vZ3Eua26v0dxvIxvkR\n8Z+IeJPU5+GGef5epGEcLo2IdyPi5ZjbU3579gb+JyJeiIgXSX3b7VtY/m5e/m5EXEca/qVWl0ND\nSEMtHJM/g4mkUlQj/UluptTL9lukgfr2ibmjNS9H6qqplunM29u3WYc4UFmPpvpDIXyf1FPz3blF\n3YHtbG65Qo/Sv24gG40Oa1FGm0NRZC9X3U9ra1iWzhj+5c7ce/fSpH4zi8M0vETbQ7SsmJebLRAH\nKuux1M5QCLmz0kMiYiXSgIlnduCeyYIMj9LWsBbQ4HAdzD8URVntDf9SWqSxrb4O7CvpE3n2TaQx\n2IpDaiBpBClQ39KBPJvNw4HKerK6QyFI2k1zh2CYkdM2OrTHROAzSkMWDCCNUlpWzWEt8rLnSUO9\nt6W9oShKKTH8S6Pbe4VUdXh8nr6J1Dv5XyWtqzT8xWZ5+2dFxKMd2Y9ZkQOV9VglhkLYBLhLaViC\n0cCR1WPmlNjHP0hDPdxPGqL9mgbWrTesxbnAOrnKslaHxnWHomhQveFfOuJU0thP6+fpLwO3kob8\nmE0KUueShn4xW2Du68/MzFqaS1RmZtbSWiZQSdpO0iP5gcRjayxfW9Idkt6ubjrc3rpmZtZztUTV\nX36Q8D+khwefBsYBe+Z7EJU0K5BaQX0RmFFpPlxmXTMz67lapUS1KTAlIqZGxDukJ+l3KSbIDz6O\nIz3o2NC6ZmbWc7VKF0qDSM+cVDwNjOjsdXMfa4cCLLnkkhuvvfbajefUzKwXmzBhwksRsXxX7rNV\nAlWXiIizgbMBhg8fHuPHj+/mHJmZ9SySnmw/Vedqlaq/Z0hPsVcMpvyT8wuyrpmZtbhWCVTjgDUk\nrSJpUWAP0gOazV7XzMxaXEtU/UXEe5KOAG4A+gDnRcRkSYfl5aMkfZT0pH5/4H1JRwHrRMTMWut2\nz5GYmVlna4nm6d3B96jMzBonaUJENGtst5paperPzMysJgcqMzNraQ5UZmbW0hyozMyspTlQmZlZ\nS3OgMjOzluZAZWZmLc2ByszMWpoDlZmZtTQHKjMza2kOVGZm1tIcqMzMrKU5UJmZWUtzoDIzs5bm\nQGVmZi3NgcrMzFqaA5WZmbU0ByozM2tpDlRmZtbSHKjMzKylOVCZmVlLKxWoJK0saev8fglJ/Zqb\nLTMzs6TdQCXpEOAK4Pd51mDgqmZmyszMrKJMiepw4FPATICIeBRYoZmZMjMzqygTqN6OiHcqE5IW\nBqJ5WTIzM5urTKAaK+mHwBKStgEuB65ubrbMzMySMoHqWOBFYBLwNeA64LhmZsrMzKxi4RJplgDO\ni4g/AEjqk+e90cyMmZmZQbkS1c2kwFSxBHBTc7JjZmY2rzKBavGImF2ZyO/7Ni9LZmZmc5UJVK9L\n2qgyIWlj4M3mZcnMzGyuMveojgIul/QsIOCjwFeamiszM7Os3UAVEeMkrQ2slWc9EhHvNjdbZmZm\nSZkSFcAmwLCcfiNJRMSFTcuVmZlZ1m6gknQRsBowEZiTZwfgQGVmZk1XpkQ1HFgnIprabZKk7YDT\ngD7AORFxUtVy5eU7kJ7h2j8i7snLvg0cTAqgk4ADIuKtZubXzMy6RplWfw+QGlA0TX6I+Axge2Ad\nYE9J61Ql2x5YI78OBc7K6w4CvgUMj4j1SIFuj2bm18zMuk6ZEtVywIOS7gbersyMiC90Yj42BaZE\nxFQASZcBuwAPFtLsAlyYS3Z3ShooacW8bGFSX4Tvkp7xerYT82ZmZt2oTKD6SbMzAQwCphWmnwZG\nlEgzKCLGS/o18BTp+a4bI+LGWjuRdCipNMbQoUM7KetmZtZMZZqnj+2KjHSUpKVJpa1VgFdJz3zt\nExEXV6eNiLOBswGGDx/uoUrMzHqAMiP8biZpnKTZkt6RNEfSzE7OxzPAkML04DyvTJqtgccj4sX8\nfNffgM07OX9mZtZNyjSm+B2wJ/AoqUPag0kNHzrTOGANSatIWpTUGGJ0VZrRwH5KNgNei4jppCq/\nzST1zS0DtwIe6uT8mZlZNykTqIiIKUCfiJgTEecD23VmJiLiPeAI4AZSkPlLREyWdJikw3Ky64Cp\nwBTgD8A38rp3AVcA95Capi9Ert4zM7Oer0xjijdyKWeipJOB6ZQMcI2IiOtIwag4b1ThfQCHt7Hu\nj4Efd3aezMys+5UJOPuSnk06AniddJ/oy83MlJmZWUWZVn9P5rdvAj9tbnbMzMzmVabV306S7pX0\niqSZkmY1odWfmZlZTWXuUZ0K7ApManZ/f2ZmZtXK3KOaBjzgIGVmZt2hTInq+8B1ksYyb19/pzQt\nV2ZmZlmZQPVzYDawOLBoc7NjZmY2rzKBaqU8fIaZmVmXK3OP6jpJn296TszMzGooE6i+Dlwv6U03\nTzczs65Wt+ovd/K6bkQ81UX5MTMzm0fdElVukn5tF+XFzMxsPmUaU9wjaZOIGNdeQkmLAzsBnwZW\nInW79ABwbURMXqCcmplZr1QmUI0A9pb0JKlTWpEKW+sXE0n6KSlIjQHuAl4gNWlfEzgpB7GjI+L+\nzsu+mZl92JUJVNuW3NbdebiNWk6RtAIwtOS2zMzMgJK9p0vagFSdB3BbRNxXI13de1kR8QKplGVm\nZlZamd7TjwQuAVbIr4slfbNGuvUL7xeRdJyk0ZJ+IalvZ2bazMx6jzLPUR0EjIiI4yPieGAz4JAa\n6S4ovD8JWB34DbAEMKpGejMzs3aVuUclYE5hek6eVytdxVbAJhHxrqR/AvNVFZqZmZVRJlCdD9wl\n6co8/UXg3BrpBkj6EqmUtkREvAupeaAkDxFiZmYd0magkrRKRDweEadIGgOMzIsOiIh7a6wyFvhC\nfv9vSR+JiOclfRR4qVNzbWZmvUa9EtUVwMaSbo6IrYB76m0oIg5oY/5zpKpAMzOzhtULVAtJ+iGw\npqTvVC+sNXCipP7A8hHxWNX89f2gr5mZdUS9Vn97kBpOLAz0q/Gah6TdgYeBv0qaLGmTwuILOivD\nZmbWu7RZooqIRyT9CngqIi4tsa0fAhtHxHRJmwIXSfpBRFxJ7VaCZmZm7arb6i8i3pd0NFAmUPWJ\niOl5vbslbQFcI2kI4FZ/ZmbWIWUe+L1J0nclDZG0TOVVI90sSatVJnLQ+hywC7Bu52TXzMx6mzLP\nUX0l/z28MC+AVavSfZ2qKr6ImCVpO2D3DufQzMx6tTKd0q5SZkO1OqrN898l9RVoZmbWsDKd0vbN\nHcyenafXkLRTIzuprGtmZtaoMveozgfeATbP088AJzS4n983mN7MzAwoF6hWi4iTgUrffW/QYHPz\niJjQgbyZmZmVClTvSFqC3MQ8t+x7uzqRpD9I+nitDUhaUtKBkvZeoNyamVmvU6bV30+A64Ehki4B\nPgXsXyPdGcCPcrB6AHgRWBxYA+gPnIcbVZiZWYPKtPq7UdIE0oCJAo6MiPl6Q4+IicDukpYChgMr\nAm8CD0XEI+3tJzdjPw3oA5wTESdVLVdevgPwBrB/RNyTlw0EzgHWI5X8DoyIO9rbp5mZtb56w3ys\nQOoWaXVgEnBiRMxsb4MRMRsY00gmJPUhlci2AZ4GxkkaHREPFpJtTyqdrQGMAM7KfyEFsOsj4r8k\nLQr0bWT/ZmbWuurdo7oQeB34LbAUcHoT87EpMCUipkbEO8BlpB4tinYBLozkTmCgpBUlDQA+Qx7M\nMSLeiYhXm5hXMzPrQvWq/laMiP/O72+QVHc8qgU0CJhWmH6auaWlemkGAe+R7oedL2kDYAKpevL1\n6p1IOhQ4FGDo0KGdlnkzM2ueuq3+JC1d6NuvT9V0XZK6qvptYWAj4KyI+ASpFHhsrYQRcXZEDI+I\n4csvv3wXZc/MzBZEvUA1gFQ6qbz6k0b5nQCMb2slSZtLepA0NhWSNpB0Zjv5eAYYUpgenOeVSfM0\n8HRE3JXnX0EKXGZm9iFQbzyqYR3c5v8C2wKj83buk/SZdtYZB6whaRVS8NkD2KsqzWjgCEmXkaoF\nX6sMKyJpmqS1cuvCrYAHMTOzD4Uyz1E1LCKmpdbkH5jTTvr3JB0B3EBqnn5eREyWdFhePgq4jtQ0\nfQqpefoBhU18E7gkt/ibWrXMzMx6sGYEqmmSNgdC0iLAkcBD7a0UEdeRglFx3qjC+2DeoUaK6SaS\nnt0yM7MPmTJdKDXqMFJAGUSqxtuQNgKMmZlZe+qWqPKDuJMjYu2yG8y9VrhPPzMz6xR1S1QRMQd4\nRFLph44k/TF3aVSZXlrSeQuQRzMz68XK3KNaGpgs6W7SM0oARMQX2ki/frFniIiYIekTC5ZNMzPr\nrcoEqh81uM2FJC0dETMA8sPBTWldaGZmH35lek8fK2llYI2IuCn3ONGnziq/Ae6QdDmpt/X/An7e\nKbk1M7Nep91AJekQUv94ywCrkVrzjSI9WDufiLgwDwuyRZ61a1Uv6GZmZqWVqZI7nNS7+V0AEfFo\nHgKknoeBGZXtSxoaEU8tSEbNzKx3KhOo3o6Idyo9TUhamDwsfS2Svgn8GHie1COFcvr1Fzi3ZmbW\n65QJVGMl/RBYQtI2wDeAq+ukPxJYKyJe7owMmplZ71amZ4pjSeM9TQK+Rurm6Lg66acBry141szM\nzMq1+nsf+EN+lTEVGCPpWuDtwnZO6VAOzcysV2szUEn6S0TsLmkSNe5JRURb95yeyq9F88vMzKzD\n6pWojsp/d2pkgxHx045nx8zMbF71AtU1pJFyT4iIfctuUNLywPeBdYHFK/MjYsuOZtLMzHqveoFq\nUUl7AZtL2rV6YUT8rY31LgH+TCqJHQZ8ldQYw8zMrGH1AtVhpOE6BgI7Vy0LoK1AtWxEnCvpyIgY\nS2rePm7Bs2pmZr1Rm4EqIm4Hbpc0PiLObWCb7+a/0yXtCDxL6n7JzMysYfVa/W0ZEbcAMxqs+jtB\n0gDgaOC3QH/g252RWTMz633qVf19FriF+av9oE7VX0Rck9++xtyOac3MzDqkXtXfj/PfAxrZYG71\ndwgwrLj9iDiwY1k0M7PerN0ulCQdKam/knMk3SPp83VW+TswALgJuLbwMjMza1iZTmkPjIjTJG0L\nLAvsC1wE3NhG+r4RcUxnZdDMzHq3Mp3SKv/dAbgwIiYX5tVyjaQdFjhnZmZmlCtRTZB0I7AK8ANJ\n/YD3qxNJmkVqZCHgh5LeJjVVFxAR0b/zsm1mZr1FmUB1ELAhMDUi3pC0DDBfA4uI6NfZmTMzMytT\n9fdJ4JEUGAkqAAAR3UlEQVSIeFXSPqSxqOYbb0rStpL+q8b8L+cBF83MzBpWJlCdBbwhaQPSQ7yP\nARfWSHc8MLbG/LHA/3Q4h2Zm1quVCVTvRUQAuwC/i4gzgFrVfItFxHydz0bES8CSC5ZNMzPrrcrc\no5ol6QfAPsBnJC0ELFIjXX9JC0fEe8WZkhYBlljwrJqZWW9UpkT1FdKQ8gdFxHPAYOBXNdL9DfiD\npA9KT5KWAkbRdk/rZmZmdbUbqCLiuYg4JSJuy9NPRUSte1THAc8DT0qaIGkC8DhpLKrjOjPTZmbW\ne7Rb9SdpM1Iv6B8DFgX6ALMjYkAxXa7yO1bST4HV8+wpEfFm52bZzMx6kzL3qH4H7AFcDgwH9gPW\nbCtxDkyTOiV3ZmbW65W5R0VETAH6RMSciDgf2K652TIzM0vKBKo3JC0KTJR0sqRvl1yvIZK2k/SI\npCmSjq2xXJJOz8vvl7RR1fI+ku6VdE31umZm1nOVCTj7ku5LHQG8DgwBvtxW4hxQ9pF0fJ4eKmnT\nejuQ1Ac4A9geWAfYU9I6Vcm2B9bIr0NJDyIXHQk8VOJ4zMysBynT6u/JiHgzImZGxE8j4ju5KrAt\nZ5K6XdozT88iBaF6NiU1vJgaEe8Al5EeMC7ahdR7e0TEncBASSsCSBoM7Aic097xmJlZz9JmYwpJ\nk0i9odcUEeu3sWhERGwk6d6cbkauOqxnEDCtMP00MKJEmkHAdOBU4PvU7jHjA5IOJZXGGDp0aDtZ\nMjOzVlCv1d9OHdzmu7kqL+CDoennGxaks0jaCXghIiZI+ly9tBFxNnA2wPDhw9sMwmZm1jrqVf0t\nAgzOVX8fvEg9U9QLcKcDVwIrSPo5cDvwi3by8Qzp3lfF4DyvTJpPAV+Q9ASpynBLSRe3sz8zM+sh\n6gWqU4GZNebPzMtqiohLSNVwJ5Kq5b4YEZe3k49xwBqSVsnVhHsAo6vSjAb2y401NgNei4jpEfGD\niBgcEcPyerdExD7t7M/MzHqIeiWjj0TEfA/uRsQkScPaWknS6cBluZf1UiLiPUlHADeQWhieFxGT\nJR2Wl48CrgN2AKYAb1Bj8EYzM/vwqReoBtZZVq839AnAcZLWIlUBXhYR49vLSERcRwpGxXmjCu8D\nOLydbYwBxrS3LzMz6znqVf2Nl3RI9UxJB5OCUU0R8ceI2AHYBHgE+KWkRxc4p2Zm1ivVK1EdBVwp\naW/mBqbhpI5pv1Ri26sDawMr4wdxzcysg9oMVBHxPLC5pC2A9fLsayPilnoblHQyKZA9BvwZ+FlE\nvNpJ+TUzs16m3d7TI+JW4NYGtvkY8Mk8BL2ZmdkCKTPMR0Mi4veSviDpM3nW2Ii4urP3Y2ZmvUOb\njSkkLdaRDUo6kdRB7IP59S1J7T3wa2ZmVlO9Vn93AEi6qMFt7ghsExHnRcR5pLGrOtodk5mZ9XL1\nqv4WlbQXqUHFrtULI+JvddYdCLyS3w+ok87MzKyueoHqMGBvUtDZuWpZAG0FqhOBeyXdCgj4DDDf\nQIhmZmZl1Guefjtwu6TxEXFu2Q1GxKWSxpAe+A3gmIh4boFzamZmvVKZVn8XSfoWqWQEMBYYFRHv\n1lnnk8BIUqBamNSVkpmZWcPKBKozSUN+nJmn9yUNA39wrcSSziT1SnFpnvU1SVtHRN1++szMzGop\nE6g2iYgNCtO3SLqvTvotgY/lTmSR9Edg8gLk0czMerF6zdMr5kharTIhaVVgTp30U4DiOO9D8jwz\nM7OGlSlRfQ+4VdJUUiu+lakxFpSkq0n3pPoBD0m6O0+PAO7utBybmVmvUqavv5slrQGslWc9EhFv\n10j663qb6UjmzMzMSvX1lwPT/e2kGVtrvqSRwJ7APxvOnZmZ9Xqd3iktgKRPAHsBuwGPA39txn7M\nzOzDr9MClaQ1SSWnPYGXSGNRKSK26Kx9mJlZ79Nuqz9JN5eZBzxMapq+U0SMjIjfUr91oJmZWbva\nLFFJWhzoCywnaWlSiz+A/sCgGqvsCuxBaiF4PXBZYR0zM7MOqVf19zXgKGAlYAJzg85M4HfViSPi\nKuAqSUsCu+R1V5B0FnBlRNzYmRk3M7PeQbkDibYTSN/M1XiNbzyVxHYDvhIRW3VkG80yfPjwGD9+\nfHdnw8ysR5E0ISKGd+U+yzxH9VtJmwPDiukj4sIS684Azs4vMzOzhrUbqPIIv6sBE5nbOCKAdgOV\nmZnZgirTPH04sE60V0doZmbWBGU6pX0A+GizM2JmZlZLmRLVcsCDuZPZD/r4i4gvNC1XZmZmWZlA\n9ZNmZ8LMzKwtZVr91exs1szMrCuUafU3i7nDdCxKGpb+9Yjo38yMmZmZQbkSVb/Ke0ki9TqxWTMz\nZWZmVlGm1d8HIrkK2LZJ+TEzM5tHmaq/XQuTC5Geq3qraTkyMzMrKFOi2rnw2haYRar+61SStpP0\niKQpko6tsVySTs/L75e0UZ4/RNKtkh6UNFnSkZ2dNzMz6z5l7lEd0OxMSOoDnAFsAzwNjJM0OiIe\nLCTbHlgjv0YAZ+W/7wFHR8Q9kvoBEyT9o2pdM+sEw469truz0CmeOGnH7s6CNaDMwImDJV0p6YX8\n+qukwZ2cj02BKRExNSLeIY1lVV1q2wW4MN8nuxMYKGnFiJgeEfcARMQs4CFqj5dlZmY9UJmqv/OB\n0aRxqVYCrs7zOtMgYFph+mnmDzbtppE0DPgEcFetnUg6VNJ4SeNffPHFBcyymZl1hTKBavmIOD8i\n3suvC4Dlm5yvhklaCvgrcFREzKyVJiLOjojhETF8+eVb7hDMzKyGMoHqZUn7SOqTX/sAL3dyPp4B\nhhSmB+d5pdJIWoQUpC6JiL91ct7MzKwblQlUBwK7A88B04H/Ajq7gcU4YA1Jq0haFNiDVN1YNBrY\nL7f+2wx4LSKm54eQzwUeiohTOjlfZmbWzcq0+nsSaGpP6RHxnqQjgBuAPsB5ETFZ0mF5+SjgOmAH\nYArwBnOD5aeAfYFJkibmeT+MiOuamWczM+saZR74XQX4JvMPRd+pwSsHluuq5o0qvA/g8Brr3Q6o\nM/NiZmato8wwH1eRqtauBt5vbnbMzMzmVSZQvRURpzc9J2ZmZjWUCVSnSfoxcCPzjvB7T9NyZWZm\nlpUJVB8nNVbYkrlVf5GnzczMmqpMoNoNWDV3bWRmZtalyjxH9QAwsNkZMTMzq6VMiWog8LCkccx7\nj6qpz1aZmZlBuUD146bnwszMrA1leqYYW5yWNBLYExhbew0zM7POU6ZEhaRPAHuRGlY8TuoA1szM\nrOnaDFSS1iSVnPYEXgL+DCgituiivJmZmdUtUT0M3AbsFBFTACR9u0tyZWZmltULVLuShtu4VdL1\npOHh3fmrmfVKw469truz0GmeOGnH7s5CQ9p8jioiroqIPYC1gVuBo4AVJJ0l6fNdlUEzM+vd2n3g\nNyJej4g/RcTOpFF17wWOaXrOzMzMKNczxQciYkZEnB0RWzUrQ2ZmZkUNBSozM7Ou5kBlZmYtzYHK\nzMxamgOVmZm1NAcqMzNraQ5UZmbW0hyozMyspTlQmZlZSys1zIfNy31+mZl1HZeozMyspTlQmZlZ\nS3OgMjOzluZ7VNYw36Mzs67kEpWZmbU0ByozM2tpDlRmZtbSHKjMzKylOVCZmVlLc6AyM7OW1jLN\n0yVtB5wG9AHOiYiTqpYrL98BeAPYPyLuKbOuWWdx03yzrtcSJSpJfYAzgO2BdYA9Ja1TlWx7YI38\nOhQ4q4F1zcysh2qJQAVsCkyJiKkR8Q5wGbBLVZpdgAsjuRMYKGnFkuuamVkP1SpVf4OAaYXpp4ER\nJdIMKrkuAJIOJZXGAGZLemQB8twVlgNeauYO9Mtmbn2BNP3YoXcfv4+9JfWE837lTspGaa0SqLpE\nRJwNnN3d+ShL0viIGN7d+egOvfnYoXcfv4+9dx57Pa0SqJ4BhhSmB+d5ZdIsUmJdMzProVrlHtU4\nYA1Jq0haFNgDGF2VZjSwn5LNgNciYnrJdc3MrIdqiRJVRLwn6QjgBlIT8/MiYrKkw/LyUcB1pKbp\nU0jN0w+ot243HEYz9JhqyibozccOvfv4few2D0VEd+fBzMysTa1S9WdmZlaTA5WZmbU0B6puJulW\nSdtWzTtK0lmSrpf0qqRruit/jZD0LUkPSbqkwfXOqfQmImm3vI1bm5PL1iRptqSPS5qYX69Iejy/\nv6m789dZJM1uY/6hkh7Or7sljSwsW0TSSZIelXSPpDskbd91uW4OSf/Of4dJ2qu789PKWqIxRS93\nKaml4g2FeXsA3yc1ve8LfK0b8tUR3wC2joinG1kpIg4uTB4EHBIRt5dZV9LCEfFeI/trVRExCdgQ\nQNIFwDURcUW3ZqoLSNqJdI6PjIiXJG0EXCVp04h4DvgZsCKwXkS8LekjwGe7McudIiI2z2+HAXsB\nf+q+3LQ2l6i63xXAjrlpPZKGASsBt0XEzcCs7staeZJGAasC/yfpNUnfLSx7IP9qXFLStZLuy/O+\nkpePkTRc0vHASOBcSb+StLik8yVNknSvpC1y+v0ljZZ0C3CzpM9JGivp75Km5l/fe+df5pMkrdYN\nH4mVdwzwvYh4CSB3Nv1H4HBJfYFDgG9GxNt5+fMR8Zduy20m6Tv5PH5A0lF53n6S7s/n+EV53kck\nXZnn3Sdp8zy/Uro8Cfh0Lj1/W1KffP6Py9v6Wk5f6jyXdIGkUZLGS/pP/iHQo7lE1c0i4hVJd5M6\n1f07qTT1l+hhzTEj4jClXuy3AI5oI9l2wLMRsSOApAFV2/gfSVsC342I8ZKOTrPj45LWBm6UtGZO\nvhGwfv78PgdsAHwMeAWYSupFf1NJRwLfBI7q1AO2zrQuMKFq3njgq8DqwFMRMbPLc1WHpI1Jj8iM\nAATcJWkccByweS4ZLpOTnw6MjYgvKXWivVTV5o4lnfM75W0fSnpOdBNJiwH/knRjTlv2PB9G6gd1\nNeBWSatHxFud/DF0GZeoWkOl+o/899JuzEszTQK2kfRLSZ+OiNfaST8SuBggIh4GngQqgeofEfFK\nIe24iJief3U/BlS+2JNIX1qzzjQSuDIiXo+I2cDfgOHA5YWSYeX83JI82kNEzClx3n+e1LnBROAu\nYFnSqBFQ/jz/S0S8HxGPkgLa2h0/1O7nQNUa/g5slevm+0ZE9a/LnuY95j23FgeIiP+QSkKTgBNy\nVV9HvV41/Xbh/fuF6fdxzUGrexDYuGrexsBk0gP+QyX17/JcdR+Rqjo3zK9VIqISkMqe59U1Mj2q\nhqaaA1ULyL/IbgXO48NRmnqCFJDIwXeV/H4l4I2IuBj4VSVNHbcBe+d11wSGAq3e47017mTgl5KW\nBZC0IbA/cGZEvAGcC5xWuI+7vKTduiuz2W3AFyX1lbQk8CVSdeVuheOoVP3dDHw9z+tTXeVNug/d\nrzB9A/B1SYvkddbM+2jEbpIWyvetVqWHf2/8S7N1XApcydwqQCTdRiqyLyXpaeCgiLihjfVbyV9J\nVReTSVUX/8nzPw78StL7wLvkL28dZwJnSZpEKqXtn1t9NSnb1gX65nO54pSIOEXSIODfkoJ04d4n\n9+UJ6b7PCcCDkt4ilaYXpDS+wCLiHqWWmXfnWedExL8k/RwYK2kOcC8p4B4JnC3pIGAO6by/o7C5\n+4E5ku4DLiCNVj4MuEfpZH8R+GKDWXwq560/cFhPvj8F7kLJzOxDRR/CRxtc9WdmZi3NJSozM2tp\nLlGZmVlLc6AyM7OW5kBlZmYtzYHKrBtImpP7dntA0tWSBhaWrSvpFkmPKPUY/qPcTLnSz+Hvui/n\nZl3Pgcqse7yZex1Yj9Rv2+EAkpYARgMnRcRapL7dNif1TG/WKzlQmXW/O4BB+f1ewL8qXebknhmO\nIHVcatYrOVCZdaPcm/ZWpFIU1OhJPCIeI/VO0pv6uzP7gAOVWfdYIveO/RzwEeAf3Zwfs5blQGXW\nPd6MiA2BlUm9ZR+e58/Xk7ikVYHZrTYmk1lXcaAy60b5HtS3gKMlLQxcAoyUtDV80LjidFIP42a9\nkgOVWTeLiHtJPWjvGRFvArsAx0l6hDR21zjATdKt13Jff2Zm1tJcojIzs5bmQGVmZi3NgcrMzFqa\nA5WZmbU0ByozM2tpDlRmZtbSHKjMzKyl/T8Dl0nfPv08mwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f916049bac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.25625   ,  0.25429687,  0.25117187,  0.27109375,  0.26171875])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.bar(np.arange(5), np.array(roiscores) - .25)\n",
    "plt.xticks(np.arange(5), ROIs)\n",
    "plt.ylabel('Amount of Classifier Performance\\nAbove Chance (.25)')\n",
    "plt.xlabel('ROI')\n",
    "plt.ylim(ymax=.1)\n",
    "plt.title('Average Amount of Classifier Performance Above Chance (.25)\\nas Function of ROI')\n",
    "plt.show()\n",
    "np.array(roiscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import brainiak\n",
    "import os\n",
    "import json\n",
    "import seaborn as sns\n",
    "import _pickle as cPickle\n",
    "import matplotlib.pyplot as plt\n",
    "import analysis_helpers as helpers\n",
    "from nilearn import image\n",
    "from numpy import shape\n",
    "from brainiak.searchlight.searchlight import Searchlight\n",
    "from brainiak.searchlight.searchlight import Diamond\n",
    "from sklearn.metrics.pairwise import pairwise_distances as pd\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load in experimental design pickle file\n",
    "with open('morph_drawing_training_design.pkl', 'rb') as f:\n",
    "    mdtd = cPickle.load(f, encoding='latin1') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## cope numbering legend\n",
    "## cope1 = 'bed'\n",
    "## cope2 = 'bench'\n",
    "## cope3 = 'chair'\n",
    "## cope4 = 'table'\n",
    "\n",
    "cope2obj = {'cope1':'bed','cope2':'bench', 'cope3':'chair','cope4':'table'}\n",
    "obj2cope = {'bed':1,'bench':2, 'chair':3,'table':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# behavioral data from database\n",
    "with open('versionNums.json') as json_data:\n",
    "    coll = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0110171_neurosketch', '0110172_neurosketch', '0111171_neurosketch', '0112171_neurosketch', '0112172_neurosketch', '0112173_neurosketch', '0113171_neurosketch', '0115172_neurosketch', '0115174_neurosketch', '0117171_neurosketch', '0118171_neurosketch', '0118172_neurosketch', '0119171_neurosketch', '0119172_neurosketch', '0119173_neurosketch', '0119174_neurosketch', '0120171_neurosketch', '0120172_neurosketch', '0120173_neurosketch', '0123171_neurosketch', '0123173_neurosketch', '0124171_neurosketch', '0125171_neurosketch', '0125172_neurosketch', '1121161_neurosketch', '1130161_neurosketch', '1202161_neurosketch', '1203161_neurosketch', '1206161_neurosketch', '1206162_neurosketch', '1206163_neurosketch', '1207162_neurosketch']\n",
      "32 subjects\n"
     ]
    }
   ],
   "source": [
    "## get list of subject directories\n",
    "proj_dir = '/home/jefan/sketchloop02/'\n",
    "contents_dir = os.listdir(proj_dir)\n",
    "\n",
    "sub_dirs = []\n",
    "for i in contents_dir:\n",
    "    try:\n",
    "        if i.split('_')[1]=='neurosketch':\n",
    "            sub_dirs.append(i)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "sub_dirs = sorted(sub_dirs)\n",
    "\n",
    "# issue with 1207161\n",
    "sub_dirs = [s for s in sub_dirs if s != '1207161_neurosketch']\n",
    "\n",
    "# issue with 1201161\n",
    "sub_dirs = [s for s in sub_dirs if s != '1201161_neurosketch']\n",
    "\n",
    "print(sub_dirs)\n",
    "def print(str(len(sub_dirs)) + ' subjects')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0110171_neurosketch\n",
      "2015.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-8fc0cc7d364d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# load subject's time series for this run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         timeseries = image.load_img(proj_dir + subject + '/analysis/firstlevel/preproc_recognition_run_' +\n\u001b[0;32m---> 16\u001b[0;31m                                              str(run) + '.feat/filtered_func_data.nii.gz')\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mtimeseries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimeseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jgunn/.local/lib/python3.6/site-packages/nilearn/image/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(img, wildcards, dtype)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0mthat\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mhas\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0maffine\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m     \"\"\"\n\u001b[0;32m--> 903\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcheck_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwildcards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwildcards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jgunn/.local/lib/python3.6/site-packages/nilearn/_utils/niimg_conversions.py\u001b[0m in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;31m# Otherwise, it should be a filename or a SpatialImage, we load it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0mniimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_niimg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_ndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mniimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jgunn/.local/lib/python3.6/site-packages/nilearn/_utils/niimg.py\u001b[0m in \u001b[0;36mload_niimg\u001b[0;34m(niimg, dtype)\u001b[0m\n\u001b[1;32m    114\u001b[0m                         + short_repr(niimg))\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_target_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mniimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jgunn/anaconda3/lib/python3.6/site-packages/nibabel/spatialimages.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, caching)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_cache\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcaching\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'fill'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jgunn/anaconda3/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masanyarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \"\"\"\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jgunn/anaconda3/lib/python3.6/site-packages/nibabel/arrayproxy.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# Read array and scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unscaled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_read_scaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jgunn/anaconda3/lib/python3.6/site-packages/nibabel/arrayproxy.py\u001b[0m in \u001b[0;36mget_unscaled\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    138\u001b[0m                                        \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                                        \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m                                        mmap=self._mmap)\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jgunn/anaconda3/lib/python3.6/site-packages/nibabel/volumeutils.py\u001b[0m in \u001b[0;36marray_from_file\u001b[0;34m(shape, in_dtype, infile, offset, order, mmap)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'readinto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mdata_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mn_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m         \u001b[0mneeds_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jgunn/anaconda3/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jgunn/anaconda3/lib/python3.6/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jgunn/anaconda3/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m             \u001b[0muncompress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconsumed_tail\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconsumed_tail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mask={}\n",
    "roi = 'IT'\n",
    "for subject in sub_dirs:\n",
    "    print(subject)\n",
    "    trainingX = []\n",
    "    trainingY = []\n",
    "    testX = []\n",
    "    testY = []\n",
    "    \n",
    "    roi_mask = load_roi_mask_combined(subject, 1, roi)\n",
    "    print(np.sum(roi_mask))\n",
    "    for run in [1, 2]:\n",
    "\n",
    "        # load subject's time series for this run\n",
    "        timeseries = image.load_img(proj_dir + subject + '/analysis/firstlevel/preproc_recognition_run_' +\n",
    "                                             str(run) + '.feat/filtered_func_data.nii.gz')\n",
    "        timeseries = timeseries.get_data().transpose((3, 0, 1, 2))\n",
    "        \n",
    "        # use information in regressor/run_x folder to make hasImage vector\n",
    "        hasImage = [0]*240\n",
    "        for cope in ['bed', 'bench', 'chair', 'table']:\n",
    "            with open('/home/jgunn/neurosketch/timepoints/' + subject[:7] + '_' + str(run) + '_' + cope + '.txt') as f:\n",
    "                times = [line.split(' ')[0] for line in f.read().split('\\n')[:-1]]\n",
    "                for t in times:\n",
    "                    tr = float(t)/1.5\n",
    "                    if cope == 'bed':\n",
    "                        hasImage[int(tr)] = 1\n",
    "                    elif cope == 'bench':\n",
    "                        hasImage[int(tr)] = 2\n",
    "                    elif cope == 'chair':\n",
    "                        hasImage[int(tr)] = 3\n",
    "                    elif cope == 'table':\n",
    "                        hasImage[int(tr)] = 4\n",
    "        \n",
    "        # wherever hasImage, get associated volume and flatten it for training\n",
    "        for i, has in enumerate(hasImage): # 80 times\n",
    "            if has > 0:\n",
    "                if run == 1:\n",
    "                    trainingX.append(timeseries[i+3][roi_mask==1])\n",
    "                    trainingY.append(has-1)\n",
    "                else:\n",
    "                    testX.append(timeseries[i+3][roi_mask==1])\n",
    "                    testY.append(has-1)\n",
    "                    \n",
    "    lin_clf = LogisticRegression()\n",
    "    rfecv = RFECV(estimator=lin_clf, step=.02, scoring='accuracy')\n",
    "    rfecv.fit(trainingX, trainingY)\n",
    "    mask[subject] = rfecv.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Analysis helper functions (see and update: analysis_helpers.py)\n",
    "def rfecv_masked(vol, subject, roi_mask):\n",
    "    print(np.sum(roi_mask))\n",
    "    return vol[roi_mask==1][mask[subject]]\n",
    "\n",
    "def getEndpoints(morphline):\n",
    "    # return two components \n",
    "    if morphline=='sedanMinivan':\n",
    "        return ['sedan','minivan']\n",
    "    elif morphline=='minivanSportscar':\n",
    "        return ['minivan','sportscar']\n",
    "    elif morphline=='sportscarSUV':\n",
    "        return ['sportscar','SUV']\n",
    "    elif morphline=='SUVMinivan':\n",
    "        return ['SUV','minivan']\n",
    "    elif morphline=='sportscarSedan':\n",
    "        return ['sportscar','sedan']\n",
    "    elif morphline=='sedanSUV':\n",
    "        return ['sedan','SUV']\n",
    "    elif morphline=='bedChair':\n",
    "        return ['bed','chair']\n",
    "    elif morphline=='bedTable':\n",
    "        return ['bed','table']\n",
    "    elif morphline=='benchBed':\n",
    "        return ['bench','bed']\n",
    "    elif morphline=='chairBench':\n",
    "        return ['chair','bench']\n",
    "    elif morphline=='chairTable':\n",
    "        return ['chair','table']\n",
    "    elif morphline=='tableBench':\n",
    "        return ['table','bench']\n",
    "    elif morphline=='limoToSUV':\n",
    "        return ['limo','SUV']    \n",
    "    elif morphline=='limoToSedan':\n",
    "        return ['sedan','limo']  \n",
    "    elif morphline=='limoToSmart':\n",
    "        return ['limo','smartcar']  \n",
    "    elif morphline=='smartToSedan':\n",
    "        return ['smartcar','sedan']    \n",
    "    elif morphline=='suvToSedan':\n",
    "        return ['SUV','sedan']  \n",
    "    elif morphline=='suvToSmart':\n",
    "        return ['SUV','smartcar']  \n",
    "    else:\n",
    "        return ['A','B']\n",
    "\n",
    "def get_mask_array(mask_path):\n",
    "    # loads mask applied to nifty (.nii.gz) file\n",
    "    # mask selects voxels to be included/discarded\n",
    "    mask_img = image.load_img(mask_path)\n",
    "    mask_data = mask_img.get_data()\n",
    "    num_brain_voxels = sum(sum(sum(mask_data==1)))\n",
    "    return mask_data, num_brain_voxels\n",
    "\n",
    "def load_roi_mask_combined(subj,run_num,roi):\n",
    "    if run_num in [1,2]:\n",
    "        phase_num = '12' \n",
    "    elif run_num in [3,4]:\n",
    "        phase_num = '34'\n",
    "    elif run_num in [5,6]:\n",
    "        phase_num = '56'\n",
    "    mask_path = proj_dir + '/' + subj +'/analysis/firstlevel/rois/' + roi + '_func_combined_' + phase_num + '_binarized.nii.gz'        \n",
    "    mask_data, nv = get_mask_array(mask_path)\n",
    "    return mask_data\n",
    "\n",
    "def load_single_run_weights(subj,run_num,cope_num):\n",
    "    nifti_path = proj_dir + '/' + subj + '/analysis/firstlevel/glm4_recognition_run_' + str(run_num) + \\\n",
    "                '.feat/stats/' + 'cope' + str(cope_num) + '.nii.gz'\n",
    "    fmri_img = image.load_img(nifti_path)\n",
    "    fmri_data = fmri_img.get_data()\n",
    "    return fmri_data, fmri_img.affine\n",
    "\n",
    "def get_condorder(this_sub):\n",
    "    versionNum = coll[this_sub]\n",
    "\n",
    "    design = [i for i in mdtd if i['version'] == int(versionNum)] # find which axes belong to which condition\n",
    "    trained = design[0]['trained']\n",
    "    near = design[0]['near']\n",
    "\n",
    "    Tep = getEndpoints(trained)\n",
    "    Nep = getEndpoints(near)\n",
    "    condorder = Tep + Nep\n",
    "\n",
    "    return (obj2cope[condorder[0]],\n",
    "            obj2cope[condorder[1]],\n",
    "            obj2cope[condorder[2]],\n",
    "            obj2cope[condorder[3]])\n",
    "\n",
    "def apply_mask(data,mask):\n",
    "    return data[mask==1]\n",
    "\n",
    "def load_data_and_apply_mask(subj,run_num,roi,cope_num,k):\n",
    "    vol = load_single_run_weights(subj,run_num,cope_num)[0]\n",
    "    mask = load_roi_mask_combined(subj,run_num,roi)\n",
    "    vec = rfecv_masked(vol,subj,mask)\n",
    "    return vec\n",
    "\n",
    "def extract_condition_by_voxel_run_mat(this_sub,run_num, roi,k):\n",
    "    versionNum = coll[this_sub]\n",
    "\n",
    "    design = [i for i in mdtd if i['version'] == int(versionNum)] # find which axes belong to which condition\n",
    "    trained = design[0]['trained']\n",
    "    near = design[0]['near']\n",
    "    far1 = design[0]['far1']\n",
    "    far2 = design[0]['far2']\n",
    "\n",
    "    Tep = getEndpoints(trained)\n",
    "    Nep = getEndpoints(near)\n",
    "    condorder = Tep + Nep\n",
    "\n",
    "    slot1 = load_data_and_apply_mask(\n",
    "        this_sub,run_num,roi,obj2cope[condorder[0]],k)\n",
    "    slot2 = load_data_and_apply_mask(\n",
    "        this_sub,run_num,roi,obj2cope[condorder[1]],k)\n",
    "    slot3 = load_data_and_apply_mask(\n",
    "        this_sub,run_num,roi,obj2cope[condorder[2]],k)\n",
    "    slot4 = load_data_and_apply_mask(\n",
    "        this_sub,run_num,roi,obj2cope[condorder[3]],k)\n",
    "    return np.vstack((slot1,slot2,slot3,slot4))\n",
    "\n",
    "def compare_btw_wit_cond_similarity_across_runs(this_sub,phase,roi,k):\n",
    "    \n",
    "    if phase=='pre':\n",
    "        mat1 = extract_condition_by_voxel_run_mat(this_sub,3,roi,k)\n",
    "        mat2 = extract_condition_by_voxel_run_mat(this_sub,4,roi,k)\n",
    "    elif phase=='post':\n",
    "        mat1 = extract_condition_by_voxel_run_mat(this_sub,5,roi,k)\n",
    "        mat2 = extract_condition_by_voxel_run_mat(this_sub,6,roi,k)\n",
    "\n",
    "    fAB = np.vstack((mat1,mat2)) # stack feature matrices\n",
    "    # square matrix, where off-diagblock is distances *between* \n",
    "    # fA and fB vectors\n",
    "    DAB = pd(fAB, metric='correlation')\n",
    "    offblock = DAB[:len(mat1),range(len(mat1),shape(DAB)[1])]\n",
    "\n",
    "    trained_witobj = offblock.diagonal()[:2]\n",
    "    control_witobj = offblock.diagonal()[2:]\n",
    "    trained_btwobj = np.array([offblock[:2,:2][0,1], offblock[:2,:2][1,0]])\n",
    "    control_btwobj = np.array([offblock[2:,2:][0,1],offblock[2:,2:][1,0]])\n",
    "\n",
    "    trawit_mean = trained_witobj.mean()\n",
    "    conwit_mean = control_witobj.mean()\n",
    "    trabtw_mean = trained_btwobj.mean()\n",
    "    conbtw_mean = control_btwobj.mean()\n",
    "    return trawit_mean,conwit_mean,trabtw_mean, conbtw_mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IT\n",
      "0110171_neurosketch\n",
      "1901.0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 1901 but corresponding boolean dimension is 2015",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-a5cc895968ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msub_dirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mtrawit_mean_pre\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconwit_mean_pre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrabtw_mean_pre\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconbtw_mean_pre\u001b[0m \u001b[0;34m=\u001b[0m         \u001b[0mcompare_btw_wit_cond_similarity_across_runs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'pre'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mroi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mtrawit_mean_post\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconwit_mean_post\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrabtw_mean_post\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconbtw_mean_post\u001b[0m \u001b[0;34m=\u001b[0m         \u001b[0mcompare_btw_wit_cond_similarity_across_runs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mroi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-47ce495a15ce>\u001b[0m in \u001b[0;36mcompare_btw_wit_cond_similarity_across_runs\u001b[0;34m(this_sub, phase, roi, k)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'pre'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mmat1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_condition_by_voxel_run_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_sub\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mroi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mmat2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_condition_by_voxel_run_mat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_sub\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mroi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-47ce495a15ce>\u001b[0m in \u001b[0;36mextract_condition_by_voxel_run_mat\u001b[0;34m(this_sub, run_num, roi, k)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     slot1 = load_data_and_apply_mask(\n\u001b[0;32m--> 111\u001b[0;31m         this_sub,run_num,roi,obj2cope[condorder[0]],k)\n\u001b[0m\u001b[1;32m    112\u001b[0m     slot2 = load_data_and_apply_mask(\n\u001b[1;32m    113\u001b[0m         this_sub,run_num,roi,obj2cope[condorder[1]],k)\n",
      "\u001b[0;32m<ipython-input-77-47ce495a15ce>\u001b[0m in \u001b[0;36mload_data_and_apply_mask\u001b[0;34m(subj, run_num, roi, cope_num, k)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mvol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_single_run_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrun_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcope_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_roi_mask_combined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrun_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mroi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfecv_masked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msubj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-47ce495a15ce>\u001b[0m in \u001b[0;36mrfecv_masked\u001b[0;34m(vol, subject, roi_mask)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrfecv_masked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroi_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroi_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mvol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mroi_mask\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubject\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgetEndpoints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmorphline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 1901 but corresponding boolean dimension is 2015"
     ]
    }
   ],
   "source": [
    "### Now compute for all subjects (N=32), and for every ROIs\n",
    "\n",
    "k = 0\n",
    "Tradiffpre = []\n",
    "Condiffpre = []\n",
    "Tradiffpost = []\n",
    "Condiffpost = []\n",
    "\n",
    "ROIs = [roi]\n",
    "\n",
    "for roi in ROIs:\n",
    "    print(roi)    \n",
    "    _Tradiffpre = []\n",
    "    _Condiffpre = []\n",
    "    _Tradiffpost = []\n",
    "    _Condiffpost = []\n",
    "        \n",
    "    for s in sub_dirs:\n",
    "        print(s)\n",
    "        trawit_mean_pre,conwit_mean_pre, trabtw_mean_pre,conbtw_mean_pre = \\\n",
    "        compare_btw_wit_cond_similarity_across_runs(s,'pre',roi,k)\n",
    "        trawit_mean_post,conwit_mean_post, trabtw_mean_post,conbtw_mean_post = \\\n",
    "        compare_btw_wit_cond_similarity_across_runs(s,'post',roi,k)\n",
    "        \n",
    "        _Tradiffpre.append(trabtw_mean_pre - trawit_mean_pre)\n",
    "        _Condiffpre.append(conbtw_mean_pre - conwit_mean_pre)\n",
    "\n",
    "        _Tradiffpost.append(trabtw_mean_post - trawit_mean_post)\n",
    "        _Condiffpost.append(conbtw_mean_post - conwit_mean_post)\n",
    "        \n",
    "    _Tradiffpre,_Condiffpre,_Tradiffpost,_Condiffpost = map(np.array, \\\n",
    "                                                               [_Tradiffpre,_Condiffpre,_Tradiffpost,_Condiffpost])\n",
    "        \n",
    "    if len(Tradiffpre)==0:\n",
    "        Tradiffpre = _Tradiffpre\n",
    "        Condiffpre = _Condiffpre\n",
    "        Tradiffpost = _Tradiffpost\n",
    "        Condiffpost = _Condiffpost\n",
    "    else:\n",
    "        Tradiffpre = np.vstack((Tradiffpre,_Tradiffpre))\n",
    "        Condiffpre = np.vstack((Condiffpre,_Condiffpre))\n",
    "        Tradiffpost = np.vstack((Tradiffpost,_Tradiffpost))\n",
    "        Condiffpost = np.vstack((Condiffpost,_Condiffpost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## save out so you can import later and share\n",
    "if shape(Tradiffpre)==(len(ROIs),len(sub_dirs)): ## ONLY save out if you've actually finished the analysis above\n",
    "    with open(\"prepost_differentiation_by_condition.pkl\", 'wb')  as _f:\n",
    "        cPickle.dump([Tradiffpost,Tradiffpre,Condiffpost,Condiffpre], _f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## load in saved pkl\n",
    "with open('prepost_differentiation_by_condition.pkl', 'rb') as f:\n",
    "    prepost_diff = cPickle.load(f, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = np.dstack((Tradiffpre,Condiffpre))\n",
    "Diffpre = tmp.mean(2)\n",
    "\n",
    "tmp = np.dstack((Tradiffpost,Condiffpost))\n",
    "Diffpost = tmp.mean(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "sns.set_context('poster')\n",
    "\n",
    "means_pre = Diffpre.mean(1)\n",
    "std_pre = Diffpre.std(1)/np.sqrt(shape(Diffpre)[1])\n",
    "\n",
    "means_post = Diffpost.mean(1)\n",
    "std_post = Diffpost.std(1)/np.sqrt(shape(Diffpost)[1])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "n_groups = 6 # num ROIs\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35\n",
    "\n",
    "opacity = 0.8\n",
    "error_config = {'ecolor': '0.3'}\n",
    "\n",
    "## plot means as bars\n",
    "tcolor = (0.4,0.4,0.4)\n",
    "rects1 = plt.bar(index, means_pre, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color=(0.4,0.4,0.4),\n",
    "                 yerr=std_pre,\n",
    "                 error_kw=error_config,\n",
    "                 label='Pre')\n",
    "\n",
    "ccolor = (0.7,0.7,0.7)\n",
    "rects2 = plt.bar(index + bar_width, means_post, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color=(0.7,0.7,0.7),\n",
    "                 yerr=std_post,\n",
    "                 error_kw=error_config,\n",
    "                 label='Post')\n",
    "\n",
    "\n",
    "plt.xlabel('ROIs')\n",
    "plt.ylabel('Btw vs. W/in-Obj Distance')\n",
    "plt.title('Sensitivity to differences between object representations')\n",
    "plt.xticks(index + bar_width / 2, ('V1','fusiform','IT','LOC','occitemp', 'searchlight'))\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "save_out = 1\n",
    "if save_out:\n",
    "    helpers.save('plots/object_discriminability_by_roi_group_mean', ext='pdf', close=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Tradifflearn = Tradiffpost-Tradiffpre\n",
    "Condifflearn = Condiffpost-Condiffpre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ROIs = ['V1','fusiform','IT','LOC','occitemp', 'searchlight']\n",
    "print(Tradifflearn.std(1)/np.sqrt(shape(Tradifflearn)[1]))\n",
    "print(Condifflearn.mean(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Generate summary plot (main analysis)\n",
    "\n",
    "plot_indiv_subs = 1\n",
    "\n",
    "sns.set_style('white')\n",
    "sns.set_context('poster')\n",
    "means_trained = Tradifflearn.mean(1)\n",
    "std_trained = Tradifflearn.std(1)/np.sqrt(shape(Tradifflearn)[1])\n",
    "\n",
    "means_control = Condifflearn.mean(1)\n",
    "std_control = Condifflearn.std(1)/np.sqrt(shape(Condifflearn)[1])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "\n",
    "n_groups = 6 # num ROIs\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.35\n",
    "\n",
    "opacity = 0.8\n",
    "error_config = {'ecolor': '0.3'}\n",
    "\n",
    "## plot means as bars\n",
    "tcolor = (0.8,0.4,0.4)\n",
    "rects1 = plt.bar(index, means_trained, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color=(0.8,0.4,0.4),\n",
    "                 yerr=std_trained,\n",
    "                 error_kw=error_config,\n",
    "                 label='Trained')\n",
    "\n",
    "ccolor = (0.4,0.4,0.4)\n",
    "rects2 = plt.bar(index + bar_width, means_control, bar_width,\n",
    "                 alpha=opacity,\n",
    "                 color=(0.4,0.4,0.4),\n",
    "                 yerr=std_control,\n",
    "                 error_kw=error_config,\n",
    "                 label='Control')\n",
    "\n",
    "if plot_indiv_subs:\n",
    "    ## now plot individual subjects as dots\n",
    "    def generate_concat_tiled(array,reps):        \n",
    "        inds = []\n",
    "        for i in index:\n",
    "            inds.append(np.tile(i,reps))\n",
    "        return np.reshape(np.array(inds),(1,reps*len(array)))\n",
    "\n",
    "    tindex = generate_concat_tiled(index,len(Tradifflearn[0]))\n",
    "    tsubdists = np.reshape(Tradifflearn,(1,shape(Tradifflearn)[0]*shape(Tradifflearn)[1]))\n",
    "    plt.scatter(tindex,tsubdists,s=25,alpha=0.2,color=tcolor)\n",
    "\n",
    "    cindex = generate_concat_tiled(index,len(Condifflearn[0]))+bar_width\n",
    "    csubdists = np.reshape(Condifflearn,(1,shape(Condifflearn)[0]*shape(Condifflearn)[1]))\n",
    "    plt.scatter(cindex,csubdists,s=25,alpha=0.2,color=ccolor)\n",
    "\n",
    "plt.xlabel('ROIs')\n",
    "plt.ylabel('Change in Representational DISTANCE')\n",
    "plt.title('Effect of Training on Representational DISTANCE')\n",
    "plt.xticks(index + bar_width / 2, ('V1','fusiform','IT','LOC','occitemp', 'searchlight'))\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "save_out = 1\n",
    "if save_out:\n",
    "    if plot_indiv_subs:\n",
    "        helpers.save('plots/differentiation_by_roi_indiv_sub', ext='pdf', close=False, verbose=True)\n",
    "    else:\n",
    "        helpers.save('plots/differentiation_by_roi_group_mean', ext='pdf', close=False, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
